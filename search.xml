<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>C++中栈和堆的区别</title>
    <url>/2019/12/24/93b6f39e/</url>
    <content><![CDATA[<h3 id="预备知识"><a href="#预备知识" class="headerlink" title="预备知识"></a>预备知识</h3><p>一个由C&#x2F;C++编译的程序占用的内存分为以下几个部分</p>
<ul>
<li><strong>栈</strong>（stack) 由编译器自动分配释放，存放函数的参数值，局部变量的值等。其操作方式类似于数据结构中的栈</li>
<li><strong>堆</strong>（heap) 由程序员分配释放， 若程序员不释放，程序结束时可能由OS回收。其与数据结构中的堆不相同，分配的方式类似于链表。</li>
<li><strong>全局区</strong>（静态区，static）全局变量和静态变量的存储是放在一块的，初始化的全局变量在一块区域，未初始化的全局变量和未初始化的静态变量在相邻的另一块区域。</li>
<li><strong>文字常量区</strong> 常量字符串的存储位置。程序结束后由系统释放</li>
<li><strong>程序代码区</strong> 存放函数体的二进制代码</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">//main.cpp</span><br><span class="line">int a = 0; 全局初始化区</span><br><span class="line">char *p1; 全局未初始化区</span><br><span class="line">main()&#123;</span><br><span class="line">int b; 栈</span><br><span class="line">char s[] = &quot;abc&quot;; // 注意：abc 分配在静态存储区，不是栈上</span><br><span class="line"></span><br><span class="line">char *p1; //栈</span><br><span class="line">char *p2; //栈</span><br><span class="line">char *p3 = &quot;123456&quot;; //123456\0在常量区，p3在栈上。</span><br><span class="line"></span><br><span class="line">static int c =0； 全局（静态）初始化区</span><br><span class="line"></span><br><span class="line">// 堆区。</span><br><span class="line">p1 = (char *)malloc(10); // c</span><br><span class="line">// 两种方法的区别</span><br><span class="line">// https://stackoverflow.com/questions/3902011/whats-the-difference-between-new-char10-and-new-char10</span><br><span class="line">p2 = new char[10]; // c++</span><br><span class="line">p2 = new char(10); // c++</span><br><span class="line">strcpy(p1, &quot;123456&quot;); // 123456\0放在常量区，编译器可能会将它与p3所指向的&quot;123456&quot;优化成一个地方。</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>注意在上面的示例中，指针p1,p2本身是存储在栈中的，但是其所指的地址是指向堆的。这一点要分清楚。</strong></p>
<h3 id="申请后系统的响应"><a href="#申请后系统的响应" class="headerlink" title="申请后系统的响应"></a>申请后系统的响应</h3><ul>
<li><strong>栈</strong> (stack)： 只要栈的剩余空间大于所申请空间，系统将为程序提供内存，否则将报异常提示栈溢出。</li>
<li><strong>堆</strong> （heap): 首先应该知道操作系统有一个记录空闲内存地址的链表，当系统收到程序的申请时，会遍历该链表，寻找第一个空间大于所申请空间的堆结点，然后将该结点从空闲结点链表中删除，并将该结点的空间分配给程序，另外，对于大多数系统，会在这块内存空间中的首地址处记录本次分配的大小，这样，代码中的<code>delete</code>语句才能正确的释放本内存空间。另外，由于找到的堆结点的大小不一定正好等于申请的大小，系统会自动的将多余的那部分重新放入空闲链表中</li>
</ul>
<h3 id="申请大小的限制"><a href="#申请大小的限制" class="headerlink" title="申请大小的限制"></a>申请大小的限制</h3><ul>
<li><strong>栈</strong> (stack)： 在Windows下,栈是向低地址扩展的数据结构，是一块连续的内存的区域。这句话的意思是栈顶的地址和栈的最大容量是系统预先规定好的，在WINDOWS下，栈的大小是2M（也有的说是1M，总之是一个编译时就确定的常数），如果申请的空间超过栈的剩余空间时，将提示overflow。因此能从栈获得的空间较小。</li>
<li><strong>堆</strong> （heap): 堆是向高地址扩展的数据结构，是不连续的内存区域。这是由于系统是用链表来存储的空闲内存地址的，自然是不连续的，而链表的遍历方向是由低地址向高地址。堆的大小受限于计算机系统中有效的虚拟内存。由此可见，堆获得的空间比较灵活，也比较大。</li>
</ul>
<h3 id="申请效率的比较"><a href="#申请效率的比较" class="headerlink" title="申请效率的比较"></a>申请效率的比较</h3><ul>
<li><strong>栈</strong> (stack)： 栈由系统自动分配，速度较快。但程序员是无法控制的。</li>
<li><strong>堆</strong> （heap): 堆是由new分配的内存，一般速度比较慢，而且容易产生内存碎片,不过用起来最方便。</li>
</ul>
<h3 id="堆和栈中的存储内容"><a href="#堆和栈中的存储内容" class="headerlink" title="堆和栈中的存储内容"></a>堆和栈中的存储内容</h3><ul>
<li><strong>栈</strong> (stack)： 在函数调用时，第一个进栈的是主函数的下一条指令（函数调用语句的下一条可执行语句）的地址，然后是函数的各个参数，在大多数的C编译器中，参数是由右往左入栈的，然后是函数中的局部变量。注意静态变量是不入栈的。当本次函数调用结束后，局部变量先出栈，然后是参数，最后栈顶指针指向最开始存的地址，也就是主函数中的下一条指令，程序由该点继续运行。</li>
<li><strong>堆</strong> （heap): 一般是在堆的头部用一个字节存放堆的大小。堆中的具体内容有程序员安排。</li>
</ul>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>堆和栈的区别可以总结为一下几点：</p>
<ul>
<li><strong>管理方式</strong>不同: 对于栈来讲，是由编译器自动管理，无需我们手工控制；对于堆来说，释放工作由程序员控制，容易产生memory leak。</li>
<li><strong>空间大小</strong>不同: 一般来讲在32位系统下，堆内存可以达到4G的空间，从这个角度来看堆内存几乎是没有什么限制的。但是对于栈来讲，一般都是有一定的空间大小的，例如，在VC6下面，默认的栈空间大小是1M（好像是，记不清楚了）, 可以修改。</li>
<li><strong>能否产生碎片</strong>不同： 对于堆来讲，频繁的new&#x2F;delete势必会造成内存空间的不连续，从而造成大量的碎片，使程序效率降低。对于栈来讲，则不会存在这个问题， 因为栈是先进后出的队列，他们是如此的一一对应，以至于永远都不可能有一个内存块从栈中间弹出，在他弹出之前，在他上面的后进的栈内容已经被弹出。</li>
<li><strong>生长方向</strong>不同：对于堆来讲，生长方向是向上的，也就是向着内存地址增加的方向；对于栈来讲，它的生长方向是向下的，是向着内存地址减小的方向增长。</li>
<li><strong>分配方式</strong>不同：堆都是动态分配的，没有静态分配的堆。栈有2种分配方式：静态分配和动态分配。静态分配是编译器完成的，比如局部变量的分配。动态分配由alloca函数进行分配，但是栈的动态分配和堆是不同的，他的动态分配是由编译器进行释放，无需我们手工实现。</li>
<li><strong>分配效率</strong>不同：栈是机器系统提供的数据结构，计算机会在底层对栈提供支持：分配专门的寄存器存放栈的地址，压栈出栈都有专门的指令执行，这就决定了栈的效率比较高。堆则是C&#x2F;C++函数库提供的，它的机制是很复杂的，例如为了分配一块内存，库函数会按照一定的算法（具体的算法可以参考数据结构&#x2F;操作系统）在堆 内存中搜索可用的足够大小的空间，如果没有足够大小的空间（可能是由于内存碎片太多），就有可能调用系统功能去增加程序数据段的内存空间，这样就有机会分 到足够大小的内存，然后进行返回。显然，堆的效率比栈要低得多。</li>
</ul>
<h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference:"></a>Reference:</h3><p><a href="https://blog.csdn.net/wo17fang/article/details/52244238">https://blog.csdn.net/wo17fang/article/details/52244238</a></p>
]]></content>
      <categories>
        <category>c++编程基础</category>
      </categories>
      <tags>
        <tag>c++</tag>
        <tag>栈</tag>
        <tag>堆</tag>
      </tags>
  </entry>
  <entry>
    <title>Cgo实践</title>
    <url>/2024/04/18/c5b97df7/</url>
    <content><![CDATA[<h1 id="什么是cgo"><a href="#什么是cgo" class="headerlink" title="什么是cgo"></a>什么是cgo</h1><p>一句话概括，cgo是golang提供的一种能力。借用这种能力，能够使得开发者在golang代码中调用c++&#x2F;c语言的库（代码逻辑）,甚至是在c++&#x2F;c语言中调用golang的能力。</p>
<h1 id="如何调用"><a href="#如何调用" class="headerlink" title="如何调用"></a>如何调用</h1><p>golang调用c++&#x2F;c语言的方式可以粗略分为三种：1）代码调用，2）动态编译（通过运行时动态链接）3）静态编译。下面介绍一些实战例子。</p>
<p><a href="https://github.com/hideonInternet/cgo_playload">代码链接</a></p>
<h2 id="代码调用"><a href="#代码调用" class="headerlink" title="代码调用"></a>代码调用</h2><h3 id="直接调用"><a href="#直接调用" class="headerlink" title="直接调用"></a>直接调用</h3><p>通过代码调用，是最简洁明了的一种方式，可以看下面的例子</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">// code_c.go</span><br><span class="line">package main</span><br><span class="line"></span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">/*</span><br><span class="line"></span><br><span class="line">#include &lt;stdio.h&gt;</span><br><span class="line"></span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">int Call()&#123;</span><br><span class="line"></span><br><span class="line">printf(&quot;hello cgo\n&quot;);</span><br><span class="line"></span><br><span class="line">return 0;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">*/</span><br><span class="line"></span><br><span class="line">import &quot;C&quot;</span><br><span class="line"></span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">func main() &#123;</span><br><span class="line"></span><br><span class="line">C.Call()</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


<p>我们使用<code>import &quot;C&quot;</code>表明引入了C虚拟包，然后紧贴上面若干行，可以用注释的方式，直接引入c语言代码。执行上面的代码，可以在控制台看到正常输出。</p>
<p>那么能否直接调用c++的代码呢，比方说使用STL之类的能力。答案是不行的，有兴趣的可能看下<code>code_cpp</code>文件夹下的代码，尝试编译运行一下，看下报错信息如何。</p>
<h3 id="通过文件调用"><a href="#通过文件调用" class="headerlink" title="通过文件调用"></a>通过文件调用</h3><p>在介绍完直接通过代码方式调用后，很自然的就会想知道：如何代码逻辑复杂了，能否通过文件的方式调用呢？通过引入头文件的方式调用c&#x2F;c++的函数。<code>cgo</code>也提供了这种能力，可以移步<code>file_c</code>目录下查看具体的调用方法。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">├── file_c.c</span><br><span class="line">├── file_c.go</span><br><span class="line">├── file_c.h</span><br><span class="line">└── Makefile</span><br></pre></td></tr></table></figure>
<p>可以看到我们有一组头文件及其函数实现和golang的调用逻辑。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">// file_c.go</span><br><span class="line">package main</span><br><span class="line"></span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">/*</span><br><span class="line"></span><br><span class="line">#include &quot;file_c.h&quot;</span><br><span class="line"></span><br><span class="line">*/</span><br><span class="line"></span><br><span class="line">import &quot;C&quot;</span><br><span class="line"></span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">func main() &#123;</span><br><span class="line"></span><br><span class="line">C.Call()</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>可以看到，在go文件里，通过<code>include</code>的方式引入头文件，就可以调用这个头文件里所定义的函数了。特别地，当头文件位于其他文件目录下时，例如：<code>extlib</code>，也可以通过<code>CFLAGS</code>、<code>CXXFLAGS</code>或<code>CPPFLAGS</code>来定义该头文件的位置。具体调用方式可以参考<code>static</code>里的代码。</p>
<p>这里要特别注意一个<code>bad case</code></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">.</span><br><span class="line">├── file_c.cpp</span><br><span class="line">├── file_c.go</span><br><span class="line">├── file_c.h</span><br><span class="line">└── Makefile</span><br></pre></td></tr></table></figure>

<p>我只将<code>file_c.c</code>改为<code>file_c.cpp</code>，其内容不做任何改变，就会出现如下报错：<br><img src="/images/work/cgo/3850519281.png"></p>
<p>报错信息的意思基本是指：在链接阶段，没有找到<code>_cgo_xxxxx</code>这个函数。这是因为使用cgo编译c&#x2F;c++文件时，golang会根据文件名后缀选择不同的编译器，而gcc编译器和g++编译器在编译阶段生成的目标文件符号名称是不同的。所以导致的链接失败。因此，我们要用<code>extern &quot;C&quot;</code>关键字来修饰头文件，以此来满足两者符号名称一致。</p>
<p>为什么仅支持c语言的编译规范呢，我在网上找到了如下的解释：</p>
<pre><code>CGO 是 C 语言和 Go 语言之间的桥梁，原则上无法直接支持 C++ 的类。CGO 不支持 C++ 语法的根本原因是 C++ 至今为止还没有一个二进制接口规范 (ABI)。一个 C++ 类的构造函数在编译为目标文件时如何生成链接符号名称、方法在不同平台甚至是 C++ 的不同版本之间都是不一样的。
</code></pre>
<p>如果需要调用c++的某些特性或者依赖库，必须要使用c语言封装一层胶水层。具体实现可以参考<code>file_cpp_good</code>目录下的代码。</p>
<h2 id="引入函数库"><a href="#引入函数库" class="headerlink" title="引入函数库"></a>引入函数库</h2><p>通过代码调用的方式是最基础的一种方法来使用cgo，但是实际情况下，我们需要更加复杂的c&#x2F;c++逻辑，这时候通过代码的方式就不是那么的合适。同时，绝大多数情况下，我们使用的SDK只提供了库文件和头文件。所以在这种场景下，我们就需要使用引入函数库的方式来使用cgo。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#cgo LDFLAGS: -L$&#123;SRCDIR&#125;/../extlib/ -lcomm</span><br><span class="line">#cgo CFLAGS: -I/../extlib/</span><br></pre></td></tr></table></figure>

<p>通过定义库文件和头文件的引入路径来引入。</p>
<h3 id="动态编译"><a href="#动态编译" class="headerlink" title="动态编译"></a>动态编译</h3><p>动态编译故名思意就是在运行时动态链接进进程的内存当中。其好处就是可以避免引入多个库时的符号冲突问题。但是其弊端也是十分明显的，可移植性有些差。</p>
<h3 id="静态编译"><a href="#静态编译" class="headerlink" title="静态编译"></a>静态编译</h3><p>与动态编译相反，静态编译就是在链接阶段，直接讲静态库链接到二进制中。这样做的好吃时移植性好，如果不涉及跨平台的话，只需要一个二进制文件可以直接拉起服务。坏处是产出物占用磁盘空间大。</p>
<p>在编写代码上，两者的方法基本上通用的。差异在执行逻辑上：采用动态编译时，需要提前将所依赖的动态库拷贝进系统路径里或者在运行时指明动态库的具体路径，否则会因找不到动态库文件报错。</p>
<h2 id="性能比较"><a href="#性能比较" class="headerlink" title="性能比较"></a>性能比较</h2><p>我手搓了一下在纯计算逻辑上，使用c、cgo和golang三者在性能比较。结果如下截图所示：</p>
<p><img src="/images/work/cgo/performance.png"></p>
<p>具体计算逻辑是计算菲波那切数。可以明显看出来，使用cgo和c名没有明显的差异。在计算第50位数字时，只是略微慢了300ms左右。而使用纯golang时，耗时陡增至76s，慢了足足有43s。</p>
<p>跑一下benchmark验证一下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">goos: linux</span><br><span class="line">goarch: amd64</span><br><span class="line">pkg: performance/cgo</span><br><span class="line">cpu: Intel(R) Xeon(R) Platinum 8255C CPU @ 2.50GHz</span><br><span class="line">BenchmarkCgoFibonacci</span><br><span class="line">BenchmarkCgoFibonacci-2              544           2236085 ns/op               0 B/op          0 allocs/op</span><br><span class="line">BenchmarkCgoFibonacci-2              531           2217419 ns/op               0 B/op          0 allocs/op</span><br><span class="line">BenchmarkCgoFibonacci-2              548           2187116 ns/op               0 B/op          0 allocs/op</span><br><span class="line">BenchmarkCgoFibonacci-2              520           2178817 ns/op               0 B/op          0 allocs/op</span><br><span class="line">BenchmarkCgoFibonacci-2              550           2428741 ns/op               0 B/op          0 allocs/op</span><br><span class="line">PASS</span><br><span class="line">ok      performance/cgo 7.196s</span><br><span class="line">goos: linux</span><br><span class="line">goarch: amd64</span><br><span class="line">pkg: performance/golang</span><br><span class="line">cpu: Intel(R) Xeon(R) Platinum 8255C CPU @ 2.50GHz</span><br><span class="line">BenchmarkFibonacci</span><br><span class="line">BenchmarkFibonacci-2         225           5121532 ns/op               0 B/op          0 allocs/op</span><br><span class="line">BenchmarkFibonacci-2         235           5008128 ns/op               0 B/op          0 allocs/op</span><br><span class="line">BenchmarkFibonacci-2         236           4970322 ns/op               0 B/op          0 allocs/op</span><br><span class="line">BenchmarkFibonacci-2         241           4969721 ns/op               0 B/op          0 allocs/op</span><br><span class="line">BenchmarkFibonacci-2         232           4992128 ns/op               0 B/op          0 allocs/op</span><br><span class="line">PASS</span><br><span class="line">ok      performance/golang      8.463s</span><br><span class="line">make: Leaving directory &#x27;/home/ubuntu/cgo_playload/performance&#x27;</span><br></pre></td></tr></table></figure>

<p>可以看到，纯计算场景下，使用<code>cgo</code>确实要比使用<code>golang</code>要快很多。那么涉及系统调用呢？</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">goos: linux</span><br><span class="line">goarch: amd64</span><br><span class="line">pkg: performance/cgo</span><br><span class="line">cpu: Intel(R) Xeon(R) Platinum 8255C CPU @ 2.50GHz</span><br><span class="line">BenchmarkReadWriteCgoCalls</span><br><span class="line">BenchmarkReadWriteCgoCalls-2      412370              2858 ns/op              64 B/op          3 allocs/op</span><br><span class="line">BenchmarkReadWriteCgoCalls-2      421786              2841 ns/op              64 B/op          3 allocs/op</span><br><span class="line">BenchmarkReadWriteCgoCalls-2      425576              2789 ns/op              64 B/op          3 allocs/op</span><br><span class="line">BenchmarkReadWriteCgoCalls-2      416859              2785 ns/op              64 B/op          3 allocs/op</span><br><span class="line">BenchmarkReadWriteCgoCalls-2      401479              2927 ns/op              64 B/op          3 allocs/op</span><br><span class="line">PASS</span><br><span class="line">ok      performance/cgo 7.093s</span><br><span class="line">goos: linux</span><br><span class="line">goarch: amd64</span><br><span class="line">pkg: performance/golang</span><br><span class="line">cpu: Intel(R) Xeon(R) Platinum 8255C CPU @ 2.50GHz</span><br><span class="line">BenchmarkReadWriteNetCalls</span><br><span class="line">BenchmarkReadWriteNetCalls-2      411382              3768 ns/op              16 B/op          1 allocs/op</span><br><span class="line">BenchmarkReadWriteNetCalls-2      385462              2816 ns/op              16 B/op          1 allocs/op</span><br><span class="line">BenchmarkReadWriteNetCalls-2      398431              2799 ns/op              16 B/op          1 allocs/op</span><br><span class="line">BenchmarkReadWriteNetCalls-2      402884              2882 ns/op              16 B/op          1 allocs/op</span><br><span class="line">BenchmarkReadWriteNetCalls-2      403792              3103 ns/op              16 B/op          1 allocs/op</span><br><span class="line">PASS</span><br><span class="line">ok      performance/golang      7.082s</span><br></pre></td></tr></table></figure>

<p>可以看到运行速度基本没有差别，但是因为使用<code>cgo</code>时，多了一步从<code>golang</code>拷贝到c语言里的过程。所以使用cgo时，应该需要考虑内存拷贝的耗时。</p>
<h1 id="内部原理"><a href="#内部原理" class="headerlink" title="内部原理"></a>内部原理</h1><p>为了查看<code>cgo</code>是如何调用c语言库，可以在<code>code/code_c</code>目录下执行<code>make analysis</code>得到编译的中间文件，具体产物可以如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">├── _cgo_export.c</span><br><span class="line">├── _cgo_export.h</span><br><span class="line">├── _cgo_flags</span><br><span class="line">├── _cgo_gotypes.go</span><br><span class="line">├── _cgo_main.c</span><br><span class="line">├── _cgo_.o</span><br><span class="line">├── code_c.cgo1.go</span><br><span class="line">└── code_c.cgo2.c</span><br></pre></td></tr></table></figure>

<p>首先查看<code>code_c.cgo1.go</code>里</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">// Code generated by cmd/cgo; DO NOT EDIT.</span><br><span class="line">//line /home/ubuntu/cgo_playload/code/code_c/code_c.go:1:1</span><br><span class="line">package main</span><br><span class="line">/*</span><br><span class="line">#include &lt;stdio.h&gt;</span><br><span class="line">int Call()&#123;</span><br><span class="line">printf(&quot;hello cgo\n&quot;);</span><br><span class="line">return 0;</span><br><span class="line">&#125;</span><br><span class="line">*/</span><br><span class="line"></span><br><span class="line">import _ &quot;unsafe&quot;</span><br><span class="line">func main() &#123;</span><br><span class="line">( /*line :14:2*/_Cfunc_Call /*line :14:7*/)()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>可以看到<code>_Cfunc_Call</code>，这个函数的定义在<code>_cgo_gotypes.go</code>中。</p>
<p><code>go:linkname</code>是<code>golang</code>提供的一种特殊的指令，通过这种声明<code>go:linkname &lt;localname&gt; &lt;importpath.name&gt;</code>，可以指示编译器使用 importpath.name 作为源代码中声明为 localname 的变量或函数的目标文件符号名称。特别地，可以用来使用某些包内的不可以导出函数（变量）。在下面这个例子中,<code>_cgo_runtime_cgocall</code>这个函数就把指定未<code>runtime.cgocall</code>的别名，所以在调用<code>_cgo_runtime_cgocall</code>时，实际是在调用后者。</p>
<p><code>go:cgo_import_static &lt;local&gt;</code>是<code>golang</code>提供的一种特殊的指令，它可以允许<code>&lt;local&gt;</code>作为一个未定义的引用被链接，它假设<code>&lt;local&gt;</code>的定义存在于其他目标文件中。在下面这个例子中，<code>_cgo_e80b8e4145b4_Cfunc_Call</code>就被定义在了<code>code_c.cgo2.c</code>文件中。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">//go:cgo_import_static _cgo_e80b8e4145b4_Cfunc_Call</span><br><span class="line">//go:linkname __cgofn__cgo_e80b8e4145b4_Cfunc_Call _cgo_e80b8e4145b4_Cfunc_Call</span><br><span class="line">var __cgofn__cgo_e80b8e4145b4_Cfunc_Call byte</span><br><span class="line">var _cgo_e80b8e4145b4_Cfunc_Call = unsafe.Pointer(&amp;__cgofn__cgo_e80b8e4145b4_Cfunc_Call)</span><br><span class="line"></span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">//go:cgo_unsafe_args</span><br><span class="line">func _Cfunc_Call() (r1 _Ctype_int) &#123;</span><br><span class="line">_cgo_runtime_cgocall(_cgo_e80b8e4145b4_Cfunc_Call, uintptr(unsafe.Pointer(&amp;r1)))</span><br><span class="line">if _Cgo_always_false &#123;</span><br><span class="line">&#125;</span><br><span class="line">return</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>可以看到其中调用<code>_cgo_runtime_cgocall</code>，参数<code>uintptr(unsafe.Pointer(&amp;r1))</code>就是<code>_cgo_e80b8e4145b4_Cfunc_Call</code>函数的入参。</p>
<p>查看<code>cgocall</code>的实现，其中最关键的就算三条语句：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">// 声明要进入系统调用</span><br><span class="line">entersyscall()</span><br><span class="line">// 调用C</span><br><span class="line">asmcgocall(fn, arg)</span><br><span class="line">// 退出系统调用</span><br><span class="line">exitsyscall()</span><br></pre></td></tr></table></figure>

<p>执行<code>entersyscall</code>后，会将协程<code>g</code>的状态扭转为<code>_Psyscall</code>，并且为了不阻塞本地队列中其他<code>g</code>的执行，会将处理器<code>p</code>会为本地队列中其他剩余的<code>g</code>找一个空闲的<code>m</code>。这里需要注意，通过<code>cgo</code>调用的逻辑被阻塞阻了或者执行时间过长，可能会生成很多线程。而golang并不会回收系统线程，所以最终可能会导致oom。</p>
<p><code>asmcgocall</code>的作用主要是两个</p>
<ul>
<li>切换协程栈到<code>g0</code></li>
<li>执行c函数调用</li>
</ul>
<p>这里解释一下为啥要切换到<code>g0</code>，众所周知，golang的协程初始只有分配了2k的栈大小，后续视实际情况，进行扩容。而每次扩容，都会修改栈上分配的变量、函数内存地址。而c语言的栈大小是固定的，首次分配后，就不会再变化了。所以一定要切换成<code>g0</code>。</p>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p>【1】<a href="https://chai2010.cn/advanced-go-programming-book/ch2-cgo/index.html">cgo编程</a><br>【2】<a href="https://go.dev/src/cmd/cgo/doc.go">编译指令</a><br>【3】<a href="https://github.com/changkun/cgo-benchmarks">性能对比</a><br>【4】<a href="https://go.dev/src/runtime/cgocall.go">cgocall</a><br>【5】<a href="https://golang.design/under-the-hood/zh-cn/part3tools/ch11compile/cgo/#-go--c">cgocall2</a></p>
]]></content>
      <tags>
        <tag>c++</tag>
        <tag>golang基础</tag>
      </tags>
  </entry>
  <entry>
    <title>Golang调度</title>
    <url>/2024/05/13/6c3b919f/</url>
    <content><![CDATA[<h1 id="GMP调度模型演进"><a href="#GMP调度模型演进" class="headerlink" title="GMP调度模型演进"></a>GMP调度模型演进</h1><h2 id="线程、进程切换"><a href="#线程、进程切换" class="headerlink" title="线程、进程切换"></a>线程、进程切换</h2><p>最初的操作系统是单进程的，及多个进程排队执行。在这种情况，若遇到前序进程因为某些原因阻塞，则后面的进程长时间获取不到时间片，则会陷于饥饿状态。后面人们为了解决这个问题，就涉及许多调度算法，例如多级轮转队列等，来让不同的进程抢占时间片。但后面人们发现，不同进程之间的切换成本太高了（需要保存寄存器地址，和栈现场等）。于是线程概念由此诞生。</p>
<p>相较于进程，线程有着更小的栈内存，这意味着创建、切换和销毁成本更低。但是由于线程的切换还是发生在内核态，仍然需要内核调用，切换成本包含：</p>
<p>1）一个内核线程的大小通常达到1M，因为需要分配内存来存放用户栈和内核栈的数据；</p>
<p>2）在一个线程执行系统调用（发生 IO 事件如网络请求或读写文件）不占用 CPU 时，需要及时让出 CPU，交给其他线程执行，这时会发生线程之间的切换；</p>
<p>3）线程在 CPU 上进行切换时，需要保持当前线程的上下文，将待执行的线程的上下文恢复到寄存器中，还需要向操作系统内核申请资源；</p>
<p>在高并发的情况下，大量线程的创建、使用、切换、销毁会占用大量的内存，并浪费较多的 CPU 时间在非工作任务的执行上，导致程序并发处理事务的能力降低。</p>
<p>![[thread_switch.png]]</p>
<h2 id="用户态线程（用户态协程）"><a href="#用户态线程（用户态协程）" class="headerlink" title="用户态线程（用户态协程）"></a>用户态线程（用户态协程）</h2><p>为了解决传统内核级的线程的创建、切换、销毁开销较大的问题，Go 语言将线程分为了两种类型：内核级线程 M （Machine），轻量级的用户态的协程 Goroutine，至此，Go 语言调度器的三个核心概念出现了两个：</p>
<p>  <strong>M</strong>： Machine的缩写，代表了内核线程 OS Thread，CPU调度的基本单元；</p>
<p>  <strong>G</strong>： Goroutine的缩写，用户态、轻量级的协程，一个 G 代表了对一段需要被执行的 Go 语言程序的封装；每个 Goroutine 都有自己独立的栈存放自己程序的运行状态；分配的栈大小 2KB，可以按需扩缩容；<br>  ![[1v1.png]]</p>
]]></content>
      <tags>
        <tag>golang基础</tag>
        <tag>gmp</tag>
      </tags>
  </entry>
  <entry>
    <title>Protobuf序列化和扩展实践</title>
    <url>/2023/11/19/905b18a5/</url>
    <content><![CDATA[<h1 id="Protobuffer基本介绍"><a href="#Protobuffer基本介绍" class="headerlink" title="Protobuffer基本介绍"></a>Protobuffer基本介绍</h1><h1 id="序列化方式"><a href="#序列化方式" class="headerlink" title="序列化方式"></a>序列化方式</h1><h1 id="Option扩展"><a href="#Option扩展" class="headerlink" title="Option扩展"></a>Option扩展</h1>]]></content>
      <categories>
        <category>序列化方法</category>
      </categories>
      <tags>
        <tag>后台基础</tag>
      </tags>
  </entry>
  <entry>
    <title>Hello World</title>
    <url>/2019/03/08/4a17b156/</url>
    <content><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p>
<span id="more"></span>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/deployment.html">Deployment</a></p>
]]></content>
  </entry>
  <entry>
    <title>C++中浅拷贝和深拷贝</title>
    <url>/2019/12/24/da5b8819/</url>
    <content><![CDATA[<p>C++中类的拷贝有两种：深拷贝，浅拷贝：当出现类的等号赋值(即：a&#x3D;b)时，即会调用拷贝函数</p>
<h3 id="深拷贝和浅拷贝的区别"><a href="#深拷贝和浅拷贝的区别" class="headerlink" title="深拷贝和浅拷贝的区别"></a>深拷贝和浅拷贝的区别</h3><ul>
<li>在未显示定义拷贝构造函数–（默认为浅拷贝），它能够完成成员的一一复制。当数据成员中没有指针时，浅拷贝是可行的。但当数据成员中有指针时，如果采用简单的浅拷贝，则两个对象的数据成员中的指针变量将指向同一个地址。当其中一个对象结束调用时，调用析构函数，指针所指的内存被释放，但是此时另要给对象中的指针还指向那被释放的内存块，这就导致指针悬挂现象。</li>
</ul>
<blockquote>
<p><strong>拷贝构造函数</strong>是一种特殊的构造函数，它在创建对象时，是使用同一类中之前创建的对象来初始化新创建的对象。拷贝构造函数通常用于：<br>    - 通过使用另一个同类型的对象来初始化新创建的对象。<br>    - 复制对象把它作为参数传递给函数。<br>    - 复制对象，并从函数返回这个对象。<br>构造拷贝函数最常见的形式：</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">// https://www.runoob.com/cplusplus/cpp-copy-constructor.html</span><br><span class="line">classname (const classname &amp;obj) &#123;</span><br><span class="line">   // 构造拷贝函数的主体</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li><strong>深拷贝与浅拷贝的区别就在于深拷贝会在堆内存中另外申请空间来储存数据，从而也就解决了指针悬挂的问题。简而言之，当数据成员中有指针时，必须要用深拷贝。</strong></li>
</ul>
<h3 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">// 浅拷贝， 成员变量中没有动态分配的资源</span><br><span class="line">class A &#123; </span><br><span class="line">public: </span><br><span class="line">	A(int _data) : data(_data)&#123;&#125; </span><br><span class="line">	A()&#123;&#125;</span><br><span class="line">private: </span><br><span class="line">	int data;</span><br><span class="line"> &#125;;</span><br><span class="line">int main() &#123; </span><br><span class="line">	A a(5);</span><br><span class="line">    b = a; // 仅仅是数据成员之间的赋值 </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>假设我们成员变量中有指针指向堆(heap)的时候，因为堆的空间属于动态分配。若使用浅拷贝，则两个指针变量是指向同一块堆内存区域。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">class A </span><br><span class="line">&#123; </span><br><span class="line">public: </span><br><span class="line">	A(int _size) : size(_size)</span><br><span class="line">	&#123;</span><br><span class="line">		data = new int[size];</span><br><span class="line">	&#125; // 假如其中有一段动态分配的内存 </span><br><span class="line">	A()&#123;&#125;;</span><br><span class="line">	 ~A()</span><br><span class="line">	&#123;</span><br><span class="line">		delete [] data;</span><br><span class="line">	&#125; // 析构时释放资源</span><br><span class="line">private: </span><br><span class="line">	int* data;</span><br><span class="line">	int size; </span><br><span class="line">&#125;</span><br><span class="line">int main() </span><br><span class="line">&#123; </span><br><span class="line">	A a(5), b = a; // 注意这一句 </span><br><span class="line">    /*</span><br><span class="line">    b.size = a.size;</span><br><span class="line">    b.data = a.data; // 注意这里，就会出现上面这种情况。</span><br><span class="line">    */</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>这时候就需要深拷贝</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">A(const A&amp; _A) : size(_A.size)&#123;</span><br><span class="line">	data = new int[size];</span><br><span class="line">&#125; // 深拷贝</span><br></pre></td></tr></table></figure>

<h3 id="new和不用new创建类对象区别"><a href="#new和不用new创建类对象区别" class="headerlink" title="new和不用new创建类对象区别"></a>new和不用new创建类对象区别</h3><ul>
<li>new创建的类对象需要指针接受，一处初始化，多处使用。对象使用完需delete销毁。</li>
<li>new创建类对象直接使用堆空间，而局部不用new定义类对象则使用栈空间</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ClassName* a = new ClassNet();</span><br><span class="line">delete a // 需要显式调用delete删除a所指内存</span><br><span class="line"></span><br><span class="line">ClassName a; //不用new， 直接使用类定义声明，由于是存储在栈中，使用完后不需要手动释放。</span><br></pre></td></tr></table></figure>

<ul>
<li>new对象指针可以作为函数返回值，函数形参。</li>
</ul>
<h3 id="实例"><a href="#实例" class="headerlink" title="实例###"></a>实例###</h3><p>关于深拷贝的使用，可以参考<a href="https://leetcode.com/problems/copy-list-with-random-pointer/">leetcode 138</a>题</p>
]]></content>
      <categories>
        <category>c++编程基础</category>
      </categories>
      <tags>
        <tag>c++</tag>
        <tag>浅拷贝，深拷贝</tag>
      </tags>
  </entry>
  <entry>
    <title>Ubuntu18.04装机</title>
    <url>/2019/03/24/30a4c30f/</url>
    <content><![CDATA[<h2 id="MatlabR2016b"><a href="#MatlabR2016b" class="headerlink" title="MatlabR2016b##"></a>MatlabR2016b##</h2><ul>
<li>前期准备：</li>
</ul>
<p><strong>R2016b_glnxa64_dvd1.iso</strong>，<strong>R2016b_glnxa64_dvd2.iso</strong>，<strong>Matlab 2016b Linux64 Crack.rar</strong></p>
<ul>
<li>具体流程：</li>
</ul>
<p>1.挂在ISO文件，尽量挂在空间大点的盘上,并开始安装</p>
<pre><code><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mkdir matlabISO</span><br><span class="line">sudo mount -t auto -o loop R2016b_glnxa64_dvd1.iso matlabISO/</span><br><span class="line">这里不用加sudo, 如果加了，会使安装的matlab运行时只能让root用户使用，并且新建的文件普通用户也没有访问权限</span><br><span class="line">同时网上有说不能进入matlabISO里去执行install</span><br><span class="line">matlabISO/install</span><br></pre></td></tr></table></figure>
</code></pre>
<p>2.选择<strong>使用文件安装密钥</strong>，同时可以<strong>Matlab 2016b Linux64 Crack.rar</strong>中获得安装密钥，接着就是默认安装</p>
<p>3.安装到80%左右时，会提示挂载dvd2镜像</p>
<pre><code><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">注意这里路径别写错，同时要挂载到同一个文件目录下</span><br><span class="line">sudo mount -t auto -o loop R2016b_glnxa64_dvd2.iso matlabISO/</span><br></pre></td></tr></table></figure>
</code></pre>
<p>4.激活Matlab</p>
<pre><code><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">对文件赋予权限</span><br><span class="line">sudo chmod -R 777 llicense_standalone.lic</span><br><span class="line">cd your/matlab/path/bin</span><br><span class="line">sh matlab</span><br><span class="line">这时会弹出对话框，选择不联网方式激活，并且加载Matlab 2016b Linux64 Crack.rar中的license_standalone.lic</span><br><span class="line">将Matlab 2016b Linux64 Crack.rar/glnxa64/bin/glnxa64中的四个文件复制到Matlab中对应位置</span><br><span class="line">sudo cp lib* your/matlab/path/bin/glnxa64/</span><br></pre></td></tr></table></figure>
</code></pre>
<p>   5.设置matlab快捷方式</p>
<pre><code>    sudo gedit /usr/share/application Matlab.desktop

    在打开的Matlab.desktop中输入一下内容

     [Desktop Entry]
    Encoding=UTF-8
    Name=Matlab 2016b
    Comment=MATLAB
    Exec=/your/matlab/path/bin/matlab
    Icon=/your/matlab/path/toolbox/shared/dastudio/resources/MatlabIcon.png
    Terminal=true
    StartupNotify=true
    Type=Application
    Categories=Application;
</code></pre>
<h2 id="Pycharm"><a href="#Pycharm" class="headerlink" title="Pycharm##"></a>Pycharm##</h2><ul>
<li>前期准备</li>
</ul>
<p>*** pycharm-professional-2018.3.5.tar.gz***</p>
<ul>
<li>安装流程</li>
</ul>
<p>1.放到合适的目录，提取压缩包</p>
<p>2.进入你的压缩路径，运行安装脚本</p>
<pre><code><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd your/unpack/path/pycharm/bin</span><br><span class="line">注意不要加sudo</span><br><span class="line">sh ./pycharm.sh</span><br></pre></td></tr></table></figure>
</code></pre>
<p>3.激活码激活</p>
<p>4.快捷图片</p>
<pre><code>与Matlab操作一致
</code></pre>
<h2 id="sougou拼音"><a href="#sougou拼音" class="headerlink" title="sougou拼音##"></a>sougou拼音##</h2><ul>
<li>前期准备</li>
</ul>
<p><em><strong>sogoupinyin_2.2.0.0108_amd64.deb</strong></em></p>
<ul>
<li>安装流程</li>
</ul>
<p>1.安装fcitx</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo apt-get install fcitx-bin</span><br><span class="line">sudo apt-get install fcitx-table</span><br></pre></td></tr></table></figure>

<p>2.配置fcitx</p>
<p>搜索<code>语言支持</code>，将<code>键盘输入法系统</code>设置为fcitx</p>
<p><img src="/images/others/sougou.png"></p>
<p>3.安装<em><strong>sogoupinyin_2.2.0.0108_amd64.deb</strong></em>,并重启电脑</p>
<p>4.点击Ubuntu右上角的键盘，点击<code>设置</code>，将出入搜狗拼音其余输入法删除</p>
<p><img src="/images/others/sougou2.png"></p>
<h2 id="cuda"><a href="#cuda" class="headerlink" title="cuda##"></a>cuda##</h2><ul>
<li>安装流程</li>
</ul>
<p>1.安装所需依赖项</p>
<pre><code><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo apt-get install freeglut3-dev build-essential </span><br><span class="line">sudo apt-get install libx11-dev libxmu-dev libxi-dev </span><br><span class="line">sudo apt-get install libgl1-mesa-glx libglu1-mesa libglu1-mesa-dev</span><br></pre></td></tr></table></figure>
</code></pre>
<p>2.安装CUDA</p>
<pre><code><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">进入cuda目录</span></span><br><span class="line">cd brl/cuda</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">安装cuda</span></span><br><span class="line">sudo sh cuda_9.0.176_384.81_linux.run --override</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">当你输入上面这条命令时，终端界面会让你输入一些选择，需要注意的有下面两点：</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">1、是否要安装显卡驱动--选择否</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">2、决定安装位置--根据自身情况选择安装位置（下面四个补丁也要安装在这个位置上）</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">3、除了1以外所有的选择，全部选是（Y）</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">安装cuda的补丁1</span></span><br><span class="line">sudo sh cuda_9.0.176.1_linux.run</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">安装cuda的补丁2</span></span><br><span class="line">sudo sh cuda_9.0.176.2_linux.run</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">安装cuda的补丁3</span></span><br><span class="line">sudo sh cuda_9.0.176.3_linux.run</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">安装cuda的补丁4</span></span><br><span class="line">sudo sh cuda_9.0.176.4_linux.run</span><br></pre></td></tr></table></figure>

安装完整之后因为没有安装它提示的驱动，所以会提示安装不完整
</code></pre>
<p>3.添加环境变量</p>
<p>这里需要注意，当你安装CUDA时，会问你是否更新（创建）软连接，若你是第一次安装CUDA或者你想代替你当前使用的CUDA版本，就要选Y。安装程序就会帮你创建<code>/usr/local/cuda/bin</code>链接到你的CUDA安装位置，若电脑中存在多个CUDA版本时，理论上只要删除这个软连接，再新建一个指向你想使用的CUDA上即可</p>
<pre><code><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo gedit ~/.bashrc</span><br><span class="line">在打开的文件中输入</span><br><span class="line">export  PATH=/usr/local/cuda/bin$&#123;PATH:+:$&#123;PATH&#125;&#125;</span><br><span class="line">export  LD_LIBRARY_PATH=/usr/local/cuda/lib64$&#123;LD_LIBRARY_PATH:+:$&#123;LD_LIBRARY_PATH&#125;&#125;</span><br><span class="line">另开终端输入</span><br><span class="line">source ~/.bashrc</span><br></pre></td></tr></table></figure>
</code></pre>
<h2 id="cudnn"><a href="#cudnn" class="headerlink" title="cudnn##"></a>cudnn##</h2><p>cudnn就相当于一个插件，可以随时更换，只要删除老的Cudnn文件即可</p>
<ul>
<li>安装流程</li>
</ul>
<p>1.解压cuDnn</p>
<p>2.复制其中文件到你想要使用CUDA中</p>
<pre><code><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">这里就是cuda,因为你解压缩以后的文件名就是cuda</span></span><br><span class="line">sudo cp cuda/include/cudnn.h /usr/local/cuda/include/ #*****</span><br><span class="line">sudo cp cuda/lib64/libcudnn* /usr/local/cuda/lib64/ -d</span><br><span class="line">sudo chmod a+r /usr/local/cuda/include/cudnn.h</span><br><span class="line">sudo chmod a+r /usr/local/cuda/lib64/libcudnn*</span><br></pre></td></tr></table></figure>
</code></pre>
<p>3.进入CUDA更新软连接</p>
<pre><code><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">由于/usr/local/cuda与你使用的CUDA建立了软连接，所以当你更新这里面的文件时，其他位置的CUDA也会进行相应更新</span><br><span class="line">cd /usr/local/cuda/lib64/</span><br><span class="line">sudo chmod +r libcudnn.so.7.3.0</span><br><span class="line">sudo ln -sf libcudnn.so.7.3.0 libcudnn.so.7</span><br><span class="line">sudo ln -sf libcudnn.so.7 libcudnn.so</span><br><span class="line">sudo ldconfig</span><br><span class="line">sudo ldconfig /usr/local/cuda/lib64/</span><br><span class="line"></span><br><span class="line">根据cudnn的版本不同libcudnn.so.7.3.0中的数字部分需要修改</span><br></pre></td></tr></table></figure>
</code></pre>
]]></content>
      <categories>
        <category>常用</category>
      </categories>
      <tags>
        <tag>Ubuntu</tag>
      </tags>
  </entry>
  <entry>
    <title>仿射变换及其变换矩阵的理解</title>
    <url>/2020/01/09/8152e3be/</url>
    <content><![CDATA[<h3 id="仿射变换：平移、旋转、放缩、剪切、反射"><a href="#仿射变换：平移、旋转、放缩、剪切、反射" class="headerlink" title="仿射变换：平移、旋转、放缩、剪切、反射"></a>仿射变换：平移、旋转、放缩、剪切、反射</h3><p>仿射变换包括如下所有变换，以及这些变换任意次序次数的组合：</p>
<p><img src="/images/others/transform/VKWszD.png"></p>
<p><strong>平移</strong>（translation）和<strong>旋转</strong>（rotation）顾名思义，两者的组合称之为<strong>欧式变换</strong>（Euclidean transformation）或<strong>刚体变换</strong>（rigid transformation）</p>
<p><strong>放缩</strong>（scaling）可进一步分为uniform scaling和non-uniform scaling，前者每个坐标轴放缩系数相同（各向同性），后者不同；如果放缩系数为负，则会叠加上<strong>反射</strong>（reflection）——reflection可以看成是特殊的scaling</p>
<p><strong>刚体变换</strong>+uniform scaling 称之为，<strong>相似变换</strong>（similarity transformation），即平移+旋转+各向同性的放缩</p>
<p><strong>剪切变换</strong>（shear mapping）将所有点沿某一指定方向成比例地平移，语言描述不如上面图示直观。各种变换间的关系如下面的venn图所示</p>
<p><img src="/images/others/transform/venn.png"></p>
<h3 id="变换矩阵形式"><a href="#变换矩阵形式" class="headerlink" title="变换矩阵形式"></a>变换矩阵形式</h3><p>没有平移或者平移量为0的所有仿射变换可以用如下变换矩阵描述：</p>
<p>$\left[ \begin{array}{l}{x’} \\ {y’}\end{array}\right]&#x3D;\left[ \begin{array}{ll}{a} &amp; {b} \\ {c} &amp; {d}\end{array}\right] \left[ \begin{array}{l}{x} \\ {y}\end{array}\right]$</p>
<p>不同变换对应的a,b,c,d约束不同，排除了平移变换的所有仿射变换为<strong>线性变换</strong>（linear transformation），其涵盖的变换如上面的venn图所示，其特点是<strong>原点位置不变，多次线性变换的结果仍是线性变换</strong>。</p>
<p>为了涵盖平移，引入齐次坐标，在原有2维坐标的基础上，增广1个维度，如下所示：</p>
<p>$\left[ \begin{array}{l}{x^{\prime}} \\ {y^{\prime}} \\ {1}\end{array}\right] &#x3D;\left[ \begin{array}{lll}{a} &amp; {b} &amp; {c}\\ {d} &amp; {e} &amp; {f} \end{array}\right] \left[ \begin{array}{l}{x} \\ {y} \\ {1}\end{array}\right]$</p>
<p>所以，仿射变换的变换矩阵统一用 $\left[ \begin{array}{lll}{a} &amp; {b} &amp; {c}\\ {d} &amp; {e} &amp; {f}\end{array}\right]$ 来描述，不同基础变换的$a,b,c,d,e,f$约束不同，因此，放射变换总共有6个自由度。如下所示：</p>
<p><img src="/images/others/transform/explanation.png"></p>
<p>此外，旋转和平移相乘得到刚体变换的变换矩阵，如下，有3个自由度$(\theta, t_x, t_y)$，这里旋转方向为逆时针方向，因此与上图中的正负号不同，</p>
<p>$\left[ \begin{array}{ccc}{\cos (\theta)} &amp; {-\sin (\theta)} &amp; {t_{x}} \\ {\sin (\theta)} &amp; {\cos (\theta)} &amp; {t_{y}}\end{array}\right] \left[ \begin{array}{l}{x} \\ {y} \\ {1}\end{array}\right]&#x3D;\left[ \begin{array}{c}{x^{\prime}} \\ {y^{\prime}} \\ {1}\end{array}\right]$</p>
<p>再乘上uniform scaling得到相似变换，有4个自由度（$s, \theta, t_x, t_y$），如下：</p>
<p>$\left[ \begin{array}{ccc}{s\cos (\theta)} &amp; {-s\sin (\theta)} &amp; {t_{x}} \\ {s\sin (\theta)} &amp; {s\cos (\theta)} &amp; {t_{y}}\end{array}\right] \left[ \begin{array}{l}{x} \ {y} \\ {1}\end{array}\right]&#x3D;\left[ \begin{array}{c}{x^{\prime}} \\ {y^{\prime}} \\ {1}\end{array}\right]$</p>
<h3 id="变换矩阵的理解与记忆"><a href="#变换矩阵的理解与记忆" class="headerlink" title="变换矩阵的理解与记忆"></a>变换矩阵的理解与记忆</h3><p><img src="/images/others/transform/coord.png"></p>
<p>坐标系由坐标<strong>原点</strong>和<strong>基向量</strong>决定，坐标<strong>原点</strong>和<strong>基向量</strong>确定了，坐标系也就确定了。</p>
<p>对于坐标系中的位置$(x,y)$，其相对坐标原点在$[1,0]$方向上的投影为$x$，在$[0,1]$方向上的投影为$y$这里投影的意思是过$(x,y)$做坐标轴的平行线与坐标轴的交点到原点的距离，即$(x,y)$实际为：</p>
<p>$\left[ \begin{array}{l}{x} \\ {y}\end{array}\right] &#x3D; x\left[ \begin{array}{l}{1} \\ {0}\end{array}\right] + y\left[ \begin{array}{l}{0} \\ {1}\end{array}\right]  &#x3D; \left[ \begin{array}{ll}{1} &amp; {0} \\ {0} &amp; {1}\end{array}\right] \left[ \begin{array}{l}{x} \\ {y}\end{array}\right]$</p>
<p>当坐标系变化，坐标系中的点也跟着变化，但点相对新坐标系（$x′−y′坐标系$）的位置不变仍为$(x,y)$，以旋转变换为例，新坐标轴的基向量则变为$[cos(θ),sin(θ)]$和$[−sin(θ),cos(θ)]$，所以点变化到新位置为：</p>
<p>$\left[ \begin{array}{l}{x’} \\ {y’}\end{array}\right] &#x3D; x\left[ \begin{array}{l}{\cos (\theta)} \\ { \sin (\theta)}\end{array}\right] + y\left[ \begin{array}{r}{- \sin (\theta)} \\ { \cos (\theta)}\end{array}\right]  &#x3D; \left[ \begin{array}{lr}{\cos (\theta)} &amp; {-\sin (\theta)} \\ {\sin (\theta)} &amp; {\cos (\theta)}\end{array}\right] \left[ \begin{array}{l}{x} \\ {y}\end{array}\right]$</p>
<p>所以，我们可以得出以下结论：</p>
<ul>
<li><p>所有变换矩阵只需关注一点：坐标系的变化，即<strong>基向量和原点的变化</strong>， 在仿射变换矩阵$\left[ \begin{array}{lll}{a} &amp; {b} &amp; {c}\\ {d} &amp; {e} &amp; {f} \\ 0 &amp; {0} &amp; {1}\end{array}\right]$中， $\left[ \begin{array}{l}{a} \\ {d}\end{array}\right]$和$\left[ \begin{array}{l}{b} \\ {e}\end{array}\right]$为新的基向量，$\left[ \begin{array}{l}{c} \\ {f}\end{array}\right]$为新的坐标原点，先变化基向量，再变化坐标原点。</p>
</li>
<li><p>坐标系变化到哪里，坐标系中的所有点（这里表示的是相对点）也跟着做同样的变化。</p>
</li>
</ul>
<p><img src="/images/others/transform/conclusion.png"></p>
<h3 id="变换矩阵的参数估计"><a href="#变换矩阵的参数估计" class="headerlink" title="变换矩阵的参数估计"></a>变换矩阵的参数估计</h3><h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><ul>
<li><a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2004/10/tr-2004-92.pdf">Image Alignment and Stitching: A Tutorial</a></li>
<li><a href="https://wiki2.org/en/Affine_transformation">wiki: Affine transformation</a></li>
<li><a href="https://www.ics.uci.edu/~majumder/VC/new-lectures/geom.pdf">Geometric Transformation</a></li>
<li><a href="https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-837-computer-graphics-fall-2012/lecture-notes/MIT6_837F12_Lec03.pdf">Coordinates and Transformations</a></li>
<li><a href="http://www.cs.tau.ac.il/~dcor/Graphics/cg-slides/trans3d.pdf">Transformations</a></li>
<li><a href="https://courses.cs.washington.edu/courses/csep576/11sp/pdf/Transformations.pdf">Geometric Transformations</a></li>
<li><a href="https://www.cnblogs.com/shine-lee/p/www.cs.cornell.edu/courses/cs664/2008sp/handouts/cs664-5-image-geom.pdf">Image Geometry</a></li>
<li><a href="https://www.cnblogs.com/shine-lee/p/10950963.html">仿射变换及其变换矩阵的理解</a></li>
</ul>
]]></content>
      <categories>
        <category>三维基础</category>
        <category>变换矩阵</category>
      </categories>
  </entry>
  <entry>
    <title>C++-共享内存初探</title>
    <url>/2024/04/11/a96749da/</url>
    <content><![CDATA[<h1 id="共享内存基础"><a href="#共享内存基础" class="headerlink" title="共享内存基础"></a>共享内存基础</h1><p>维基百科对共享内存定义如下：</p>
<pre><code>In computer science, shared memory is memory that may be simultaneously accessed by multiple programs with an intent to provide communication among them or avoid redundant copies. Shared memory is an efficient means of passing data between programs. Depending on context, programs may run on a single processor or on multiple separate processors.
</code></pre>
<p>从定义中可以看到相关关键技术：多进程（线程），并发，沟通。因此脑海有一个大概的概念，多个进程，共享同一片内存空间，高效地进行数据交换，并通过一些例如信号量的方式来避免冲突产生。</p>
<h1 id="共享内存的生命周期"><a href="#共享内存的生命周期" class="headerlink" title="共享内存的生命周期"></a>共享内存的生命周期</h1><p>首先说结论，共享内存的生命周期是独立于所有与其相关的进程。换句话说，在进程内如果不主动回收这块内存空间，及时进程退出后，这块空间仍然的独立存在的。这种特性与常见的栈内存、堆内存不同。正因为这个特性使得很多本地缓存都选择放在共享内存中，当进程因为各种原因（coredump，热更新。。。）重启后，仍然能通过某种方式读取到原有数据，从而达到不影响用户（上游）使用（调用）的目的，保障服务质量。</p>
<h1 id="创建共享内存"><a href="#创建共享内存" class="headerlink" title="创建共享内存"></a>创建共享内存</h1><p>主流的共享内存创建方法有两种<code>System V</code>和<code>POSIX</code>。</p>
<h2 id="System-V"><a href="#System-V" class="headerlink" title="System V"></a>System V</h2><p>System V在1983年有AT&amp;T提出的商业化Unix版本，其定义了若干共享内存的创建、绑定和销毁接口</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 创建key</span></span><br><span class="line"><span class="function"><span class="type">key_t</span> <span class="title">ftok</span><span class="params">(<span class="type">const</span> <span class="type">char</span> *_pathname_, <span class="type">int</span> _proj_id_)</span></span>;</span><br><span class="line"><span class="comment">// 分配共享内存</span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">shmget</span><span class="params">(<span class="type">key_t</span> _key_, <span class="type">size_t</span> _size_, <span class="type">int</span> _shmflg_)</span></span>;</span><br><span class="line"><span class="comment">// 将分配的物理内存ID绑定到调用进程的地址空间上</span></span><br><span class="line"><span class="function"><span class="type">void</span> *<span class="title">shmat</span><span class="params">(<span class="type">int</span> _shmid_, <span class="type">const</span> <span class="type">void</span> *_Nullable _shmaddr_, <span class="type">int</span>** _shmflg_)</span></span>;</span><br><span class="line"><span class="comment">// 解绑</span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">shmdt</span><span class="params">(<span class="type">const</span> <span class="type">void</span> *_shmaddr_)</span></span>;</span><br><span class="line"><span class="comment">// 控制函数，可以用IPC_RMID命令来标记共享内存处于回收状态（只有创建进程或者拥有进程可以标记）</span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">shmctl</span><span class="params">(<span class="type">int</span> _shmid_, <span class="type">int</span> _cmd_, <span class="keyword">struct</span> shmid_ds *_buf_)</span></span>;</span><br></pre></td></tr></table></figure>


<h2 id="POSIX"><a href="#POSIX" class="headerlink" title="POSIX"></a>POSIX</h2><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 创建共享内存</span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">shm_open</span><span class="params">(<span class="type">const</span> <span class="type">char</span> *_name_, <span class="type">int</span> _oflag_, <span class="type">mode_t</span> _mode_)</span></span>;</span><br><span class="line"><span class="comment">// 给指定_fd__分配指定长度内存</span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">ftruncate</span><span class="params">(<span class="type">int</span> _fd_, <span class="type">off_t</span> _length_)</span></span>;</span><br><span class="line"><span class="comment">// 将_addr_地址开始的_length_长度的内存映射到调用进程的地址空间上</span></span><br><span class="line"><span class="function"><span class="type">void</span> *<span class="title">mmap</span><span class="params">(<span class="type">void</span> _addr_[._length_], <span class="type">size_t</span> _length_, <span class="type">int</span> _prot_, <span class="type">int</span> _flags_, <span class="type">int</span> _fd_, <span class="type">off_t</span> _offset)</span></span>;</span><br><span class="line"><span class="comment">// 解绑</span></span><br><span class="line"><span class="function">nt <span class="title">munmap</span><span class="params">(<span class="type">void</span> _addr_[._length_], <span class="type">size_t</span> _length_)</span></span>;</span><br><span class="line"><span class="comment">// 回收共享内存</span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">shm_unlink</span><span class="params">(<span class="type">const</span> <span class="type">char</span> *_name_)</span></span>;</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>c++编程基础</category>
      </categories>
      <tags>
        <tag>共享内存</tag>
      </tags>
  </entry>
  <entry>
    <title>分布式事务概述</title>
    <url>/2023/11/18/a71c0f42/</url>
    <content><![CDATA[<h1 id="什么是事务"><a href="#什么是事务" class="headerlink" title="什么是事务"></a>什么是事务</h1><p>事务通常被看作是一系列<strong>数据交换</strong>（例如修改数据库）操作的集合，其目的在于保证数据的一致性。在<code>mysql</code>中，可以通过</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">begin</span><br><span class="line">commit/rollback</span><br></pre></td></tr></table></figure>
<p>来限定若干条SQL语句的执行结果：所有语句要么全部成功，要么全部失败。早起事务仅用来表达对单一数据库资源的管理，所以通常也被称为<code>本地事务</code>。但随着分布式系统的普及，<code>分布式事务</code>也频繁的出现在人们的视野里。</p>
<p>在介绍分布式事务前，首先需要回顾的是：如何保证本地事务的可靠性？这就不得不提到<code>ACID</code>规范</p>
<ul>
<li>Atomicity（原子性）：一个事务（transaction）中的所有操作，或者全部完成，或者全部不完成，不会结束在中间某个环节。事务在执行过程中发生错误，会被回滚（Rollback）到事务开始前的状态，就像这个事务从来没有执行过一样。即，事务不可分割、不可约简。</li>
<li>Consistency（一致性）：在事务开始之前和事务结束以后，数据库的完整性没有被破坏。这表示写入的资料必须完全符合所有的预设约束、触发器、级联回滚等。</li>
<li>Isolation（隔离性）：数据库允许多个并发事务同时对其数据进行读写和修改的能力，隔离性可以防止多个事务并发执行时由于交叉执行而导致数据的不一致。事务隔离分为不同级别，包括未提交读（Read uncommitted）、提交读（read committed）、可重复读（repeatable read）和串行化（Serializable）。</li>
<li>Durability（持久性）：事务处理结束后，对数据的修改就是永久的，即便系统故障也不会丢失。</li>
</ul>
<p>通过严格遵守<code>ACID</code>规范，我们能够保证在操作单一数据库时的数据完整性。但是如果数据的流转涉及多数据节点，多节点之间通过网络请求交换数据，如果在复杂的网络条件下，保障不同数据节点之间数据的正确交换呢？<code>分布式事务</code>因此应运而生。</p>
<h1 id="分布式事务"><a href="#分布式事务" class="headerlink" title="分布式事务"></a>分布式事务</h1><h2 id="理论基础"><a href="#理论基础" class="headerlink" title="理论基础"></a>理论基础</h2><h3 id="CAP理论"><a href="#CAP理论" class="headerlink" title="CAP理论"></a>CAP理论</h3><p>分布式事务的作用是保证数据在分布式系统中的正确交换。而CAP理论可以说是分布式系统中的基石。</p>
<ul>
<li>Consistency （一致性）：所有节点在同一时间的数据完全一致。</li>
<li>Availability (可用性)：服务在正常响应时间内一直可用。</li>
<li>Partition Tolerance（分区容忍性）：分布式系统在遇到某节点或网络分区故障的时候，仍然能够对外提供满足一致性或可用性的服务。</li>
</ul>
<p>CAP三种特性已经被证明不可以同时满足，所以需要更具不同的场景，选择抛弃其中一项。</p>
<ul>
<li>CA：在不允许分区的情况下，自然就不存在节点之间数据不一致的情况。并且只要服务不宕机，就能正常响应。</li>
<li>CP：在抛弃可用性的情况下，各节点之间的数据保持强一致性。节点之间数据同步效率受诸多外界干扰，如丢包，阻塞等，最终会导致可用性降低。</li>
<li>AP：在不考虑一致性的情况下，可用性能够得到保证，但是用户访问不同节点返回的数据不同，这在大多数应用场景下是不能容忍的。</li>
</ul>
<h3 id="BASE理论"><a href="#BASE理论" class="headerlink" title="BASE理论"></a>BASE理论</h3><p>所谓均衡存于万物之间，既然可用性和一致性不能同时满足，那么能不能退而共存呢？这就不得不提到BASE理论。</p>
<ul>
<li>Basically Available （基本可用性）：出现故障时，不要求所有节点都必须可以，可以牺牲部分可用性，如非关键路径停止服务、延迟提高。</li>
<li>Soft State（软状态）：不要求所有节点间数据时刻保持完全一致状态，允许过渡态存在。</li>
<li>Eventually Consistency（最终一致性）：所有节点数据最终会收敛一直。</li>
</ul>
<p>BASE理论通过对各节点间数据一致性的妥协，换取系统可用性的提升。</p>
<h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><p>CAP理论和BASE理论从不同角度定义了如何保证分布式系统的可用性，我们可以根据不同业务场景的特性，选择不同的模型。例如，在金融场景下，不同节点间的数据一致性要求是极为高的，那么可以选择CP或者CA来保证一个强一致性；而在积分兑换场景，为了保证用户的体验，可以选择BASE理论，来保证顾客的使用体验，只要所有节点数据能够最终收敛达到一致性。</p>
<h2 id="强一致性"><a href="#强一致性" class="headerlink" title="强一致性"></a>强一致性</h2><p>单机场景下的强一致性实现较为容易，那么如何在分布式系统下实现强一致性呢？</p>
<h3 id="两阶段提交协议（2-phase-commit"><a href="#两阶段提交协议（2-phase-commit" class="headerlink" title="两阶段提交协议（2 phase commit)"></a>两阶段提交协议（2 phase commit)</h3><p>2PC的目的在于：保证在分布式系统当中，多节点数据间的一致性。为了达到这个目的，需要引入一个协调者（coordinator）来统一控制所有节点（participant）的行为。</p>
<p>正是引入了一个协调者的角色，所有参与者才能共进退，达到一致性的目的。</p>
<p><img src="/images/work/distribution/20230303224938.png"></p>
<p>第一阶段：voting phase 投票阶段</p>
<p>事务协调者给每个参与者发送Prepare消息，每个参与者要么直接返回失败(如权限验证失败)，要么在本地执行事务，写本地的redo和undo日志，但不提交，并且<strong>锁住需要的资源</strong>，到达一种“万事俱备，只欠东风”的状态。</p>
<pre><code>参与者写入本地redo日志是十分必要的操作。若协调者发出commit指令后，若参与者宕机，redo日志可以供参与者恢复后，反查协调者是commit或者abort。
</code></pre>
<p>第二阶段：commit phase 提交阶段</p>
<p>如果协调者收到了参与者的失败消息或者超时，直接给每个参与者发送回滚(Rollback)消息；否则，发送提交(Commit)消息；参与者根据协调者的指令执行提交或者回滚操作，释放所有事务处理过程中使用的锁资源。(注意:必须在最后阶段释放锁资源)</p>
<p>看起来2PC协议非常理想，但现实却十分骨感：</p>
<p><strong>1. 单点故障问题</strong>  </p>
<p>协调者在两段提交中具有举足轻重的作用，协调者等待参与者回复时可以有超时机制，允许参与者宕机，但参与者等待协调者指令时无法做超时处理。一旦协调者宕机，所有参与者都会受到影响。如果协调者一直没有恢复，没有正常发送 Commit 或者 Rollback 的指令，那所有参与者都必须一直等待。<strong>注意，此时参与这占有的资源是锁住的</strong>。</p>
<p><strong>2. 同步阻塞问题</strong>  </p>
<p>执行过程中，所有参与节点都是事务阻塞型的。当参与者占有资源时，其他第三方节点访问公共资源不得不处于阻塞状态。也就是说从投票阶段到提交阶段完成这段时间，资源是被锁住的。这回极大的影响系统的可用性。</p>
<p><strong>3. 数据一致性问题</strong>  </p>
<p>当因为网络问题，提交指令没有到达所有的参与者，那么由于协调者在指令发出前（后）已经标记了事务已完成，但是参与者们并没有收到指令而最终提交操作，这将造成严重的数据不一致问题。<br>同时，假设某个协调者宕机未恢复，这也会使参与者间的数据出现不一致的情况。</p>
<h3 id="三阶段提交协议（3-phase-commit"><a href="#三阶段提交协议（3-phase-commit" class="headerlink" title="三阶段提交协议（3 phase commit)"></a>三阶段提交协议（3 phase commit)</h3><blockquote>
<p>计算机科学里所有的问题，都可以通过加一层中间层解决，如果解决不了，就加两层</p>
</blockquote>
<p>为了解决2PC中存在的问题，3PC协议被创造了出来，主要的改动有两点：</p>
<ul>
<li><p>引入超时机制：在2PC中，参与者的Commit&#x2F;Abort操作仅由协调者发出的指令决定，这导致如果没有收到指令，参与者将一直持有资源，阻塞等待。超时机制的引入，意味着参与者可以在不同的阶段，自行决定是Commit&#x2F;Abort，极大的提升了可用性。</p>
</li>
<li><p>拆分第一阶段：将2PC的投票阶段，拆分为问询、预提交两个阶段。目的在于改善2PC持有资源时间过长的阻塞问题。3PC的问询极端仅仅是让参与者判断是否能够正常进行事务，并不涉及资源的持有。</p>
</li>
</ul>
<p><img src="/images/work/distribution/20230305141726.png"></p>
<p>尽管3PC协议在一定程度上，改善了2PC协议的同步阻塞和超时问题。但是，对于因Abort请求丢失而造成的数据不一致问题，同样无能为力。同时因为其实现上的复杂性，在选择分布式事务解决方案时，大家更倾向于选择2PC</p>
<h3 id="XA"><a href="#XA" class="headerlink" title="XA"></a>XA</h3><p>PC 两阶段提交协议本身只是一个通用协议，不提供具体的工程实现的规范和标准，在工程实践中为了统一标准，减少行业内不必要的对接成本，需要制定标准化的处理模型及接口标准，国际开放标准组织 Open Group 定义了分布式事务处理模型 <strong>DTP</strong>（Distributed Transaction Processing）Model，现在 <strong>XA 已经成为 2PC 分布式事务提交的事实标准</strong>，很多主流数据库如 Oracle、MySQL 等都已经实现 XA。</p>
<p><img src="/images/work/distribution/20230305143010.png"></p>
<p>它定义了三大组件：</p>
<ul>
<li><strong>AP(<em>Application Program</em>)<strong>：应用程序，一般指事务的</strong>发起者</strong>（比如数据库客户端或者访问数据库的程序），定义事务对应的操作（比如更新操作 UPDATE table SET xxx WHERE xxx）</li>
<li><strong>RMs(<em>Resource Managers</em>)<strong>：资源管理器，是分布式事务的</strong>参与者</strong>，管理共享资源，并提供访问接口，供外部程序来访问共享资源，比如数据库、打印服务等，另外 RM 还应该具有事务提交或回滚的能力。</li>
<li><strong>TM(<em>Transaction Manager</em>)<strong>：事务管理器，是分布式事务的</strong>协调者</strong>，管理全局事务，与每个RM进行通信，协调事务的提交和回滚，并协助进行故障恢复。</li>
</ul>
<p>一般来讲，执行一次分布式事务的流程：</p>
<ol>
<li>配置TM，将RM注册到TM</li>
<li>AP从TM获取资源管理器的代理，获取TM所管理的RM的连接（Conn）</li>
<li>AP向TM发起全局事务</li>
<li>TM将XID通知到各RM</li>
<li>AP通过Conn直接对RM进行操作</li>
<li>AP结束全局事务</li>
<li>TM会通知RM全局事务结束</li>
<li>开始二阶段提交</li>
</ol>
<p>在mysql，开启XA事务的语法如下，需要注意的是分布式事务和本地事务是互斥的，即你无法在一个分布式事务里，继续开始本地事务：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">// 开启xa事务</span><br><span class="line">XA start &lt;xid&gt; </span><br><span class="line">// DML语句，即SQL增删改查语句 </span><br><span class="line">select * from t_student where id = 1;</span><br><span class="line">// 终止XA事务</span><br><span class="line">XA end &lt;xid&gt; </span><br><span class="line">// 预提交事务, 这一步是有返回值的</span><br><span class="line">XA prepare &lt;xid&gt;</span><br><span class="line">// 提交 </span><br><span class="line">XA commit &lt;xid&gt;</span><br><span class="line">// 回滚</span><br><span class="line">XA rollback &lt;xid&gt;</span><br></pre></td></tr></table></figure>

<h2 id="最终一致性"><a href="#最终一致性" class="headerlink" title="最终一致性"></a>最终一致性</h2><p>上面介绍了如何在分布式事务中，实现系统各节点之间数据的强一致性。但是在如今的大多数业务场景下，为了保证服务能够承担更大的TPS，我们接受各节点数据的短暂不一致，只要求数据的<strong>最终一致性</strong>。</p>
<h3 id="TCC"><a href="#TCC" class="headerlink" title="TCC"></a>TCC</h3><p>TCC（Try-Confirm-Cancel）方案的设计思路与2PC极为相似，主要区别体现在两点：</p>
<ul>
<li>锁定资源：TCC<strong>基本上</strong>不涉及资源的锁定，这极大的提升了服务的性能。TCC采取的<strong>尝试</strong>策略，每次执行前，尝试扣除资源，<strong>这既保障了不同事务间的隔离性</strong>，也提升了性能。</li>
<li>应用层实现：TCC是业务自己通过一定的规则，实现的事务（可以类比用户态线程和内核态线程）。这在一定程度上保障的事务实现的灵活性，业务可以根据不同的场景，定制化的实现不同程度的数据一致性。</li>
</ul>
<p>TCC最大的缺点，就是它对业务的入侵性极强，上一节提到，2PC的事实标准是XA协议，其中定义了TM，RM。TM通过Commit&#x2F;Abort接口管理RM的提交和回滚。而采取TCC方案的业务，也需要提供</p>
<ul>
<li>Try接口：尝试进行资源扣除</li>
<li>Commit接口：资源事实扣除</li>
<li>Cancel：清理残留事务信息</li>
</ul>
<p>这使得很多业务，尤其是老业务，改造难度很大。</p>
<h3 id="SAGA"><a href="#SAGA" class="headerlink" title="SAGA"></a>SAGA</h3><blockquote>
<p>a long story about Scandinavian history, written in the Old Norse language in the Middle Ages, mainly in Iceland<br> –Cambridge Dictionary</p>
</blockquote>
<p>SAGA通常被用来解决一系列子事务组成的<strong>长</strong>事务，基本协议如下：</p>
<ul>
<li>每个 Saga 事务由一系列幂等的有序子事务(sub-transaction) T1，T2，…，Ti，…，Tn组成。</li>
<li>每个 Ti 都有对应的幂等补偿动作C1，C2，…，Ci，…，Cn，补偿动作用于撤销 T1，T2，…，Ti，…，Tn造成的结果。</li>
</ul>
<p>SAGA内部又可以细分为两个实现方式</p>
<ul>
<li>向前恢复（Forward Recovery）：假设Ti失败，它会重复尝试Ti直到成功，并重复执行该策略，直至Tn完成。</li>
<li>向后恢复（Backward Recovery）：假设Ti失败，他会对Ti-1 … T1调用Ci-1 … C1进行恢复。</li>
</ul>
<p>SAGA弥补了TCC的缺点（需要提供三个协议接口），但也失去了事务间的隔离性。</p>
<h3 id="本地状态事务表"><a href="#本地状态事务表" class="headerlink" title="本地状态事务表"></a>本地状态事务表</h3><p>本地事务状态表方案的大概处理流程是：</p>
<ol>
<li>在调用方请求外部系统前将待执行的事务流程及其状态信息存储到数据库中，<strong>依赖数据库本地事务的原子特性保证本地事务和调用外部系统事务的一致性</strong>，这个存储事务执行状态信息的表称为本地事务状态表。</li>
<li>在将事务状态信息存储到DB后，调用方才会开始继续后面流程，同步调用外部系统，并且每次调用成功后会更新相应的子事务状态，某一步失败时则中止执行。</li>
<li>同时在后台运行一个定时任务，定期扫描事务状态表中未完成的子事务，并重新发起调用，或者执行回滚，或者在失败重试指定次数后触发告警让人工介入进行修复。</li>
</ol>
<p><img src="/images/work/distribution/20230305152625.png"></p>
<p>本地状态事务表最核心的理念就是将事务状态的写入操作与业务数据的修改操作合为同一个事务，要不全部成功（分布式事务开始），要不全部失败（分布式事务结束）。</p>
<p>由于状态表的引入，各个子事务的完成情况可以直接查表获得，但是这也要求各个<strong>子系统要保证接口的幂等性</strong>，防止重入问题。</p>
<h3 id="可靠消息队列"><a href="#可靠消息队列" class="headerlink" title="可靠消息队列"></a>可靠消息队列</h3><p>可靠消息队列方案是指当事务发起方执行完成本地事务后并发出一条消息，事务参与方（消息消费者）一定能够接收到消息并处理事务成功，此方案强调的是只要消息发给事务参与方，则最终事务要达到一致。</p>
<p>由于引入的中间间，那么可靠消息队列方案必须要考虑以下问题：</p>
<ul>
<li>本地事务与消息发送的原子性问题：要求事务发起方在本地事务执行成功后消息必须发出去，否则就丢弃消息</li>
<li>事务参与方接收消息的可靠性：要求事务参与方必须能够从消息队列接收到消息，如果接收消息失败可以重复接收消息</li>
<li>消息重复消费的问题：要解决消息重复消费的问题就要实现事务参与方的方法幂等性。</li>
</ul>
<p>为此消息队列组件必须提供以下能力：</p>
<ul>
<li>记录消息消费状态</li>
<li>提供翻查消息生产方，本地事务的完成情况。</li>
<li>两阶段提交能力</li>
<li>保证消息投递、消费的顺序性</li>
</ul>
<p><img src="/images/work/distribution/20230305154548.png"></p>
<h3 id="小结-1"><a href="#小结-1" class="headerlink" title="小结"></a>小结</h3><p>TCC很好理解，就是业务层面实现的XA协议，灵活性高，但是对业务入侵性很大。对于老业务和第三方业务，改造难度大，可能不太适用TCC。SAGA对一些有多个子事务组成的场景更加友好，可以通过编排或OSS等方式管理子事务的提交与回滚。<br>个人认为，本地事务表和可靠消息队列的差别不大，本质上都需要通过一张<strong>事务表</strong>来管理所有事务的执行。唯一的差异性体现在，后者引入了消息队列，使其具备了消息队列的一些优点，例如削峰，解耦和异步。当然也不可避免的带来服务成本的提升。</p>
]]></content>
      <categories>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>后台基础</tag>
      </tags>
  </entry>
  <entry>
    <title>射线相交检测</title>
    <url>/2020/03/16/b0dc2a0f/</url>
    <content><![CDATA[<h3 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h3><p>我们可以将也给射线写成:$R &#x3D; O + Dt$，其中，$O$为射线的起始点，$D$为射线的方向。同时我们可以利用重心坐标公式，将一个三角面片上的点，用其三个角的坐标所表示：$P_t &#x3D; (1-u-v)V_0 + uV_1 + vV_2$</p>
<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" 
    src="\images\others\rayintersection\bari.png">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">bari</div>
</center>

<p>基于以上公式，我们可以将求射线与面片的交点坐标，转换为求解：</p>
<p>$O+Dt &#x3D; (1-u-v)V_0 + uV_1 + vV_2 \tag{1}$</p>
<p>整理公式（1）我们可以得到：</p>
<p>$\begin{bmatrix} v_1 - v_0 \\ v_2 - v_0 \\ -D \end{bmatrix}^T \begin{bmatrix} u \\ v \\ t\end{bmatrix} &#x3D; \begin{bmatrix} O- V_0\end{bmatrix}^T \tag{2}$</p>
<p>我们也可以参考引用[1]，通过克莱姆法则来继续化简公式减少计算量。但由于我的项目是在数据预处理阶段来进行此过程，就没考虑性能问题。</p>
<h3 id="Code"><a href="#Code" class="headerlink" title="Code"></a>Code</h3><p>具体代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">%matplotlib notebook</span><br><span class="line"><span class="keyword">from</span> mpl_toolkits.mplot3d <span class="keyword">import</span> axes3d</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># 判断是否相交</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">isCross</span>(<span class="params">tri, ray, isPlot=<span class="literal">False</span></span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        tir: 3*3代表三角面片</span></span><br><span class="line"><span class="string">        ray: 2*3代表射线</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    v0 = tri[<span class="number">0</span>]</span><br><span class="line">    v1 = tri[<span class="number">1</span>]</span><br><span class="line">    v2 = tri[<span class="number">2</span>]</span><br><span class="line">    o = ray[<span class="number">0</span>]</span><br><span class="line">    d = ray[<span class="number">1</span>]</span><br><span class="line">    hasCrossPoint = <span class="literal">True</span></span><br><span class="line">    A = np.stack(((v1-v0).T, (v2- v0).T, (-d).T), axis=<span class="number">1</span>)</span><br><span class="line">    detA = np.linalg.det(A)</span><br><span class="line">    b = (o - v0).T</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> detA &lt; <span class="number">0</span>:</span><br><span class="line">        b = -<span class="number">1</span> * b</span><br><span class="line">        detA = -detA</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> detA &lt; <span class="number">1e-5</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;平行，不相交\n&#x27;</span>)</span><br><span class="line">        hasCrossPoint = <span class="literal">False</span></span><br><span class="line">       </span><br><span class="line">    x = np.linalg.solve(A, b)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> x[<span class="number">0</span>] &lt; <span class="number">1e-5</span> <span class="keyword">or</span> (x[<span class="number">0</span>] + x[<span class="number">1</span>]) &gt; <span class="number">1</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;无相交点\n&#x27;</span>)</span><br><span class="line">        hasCrossPoint = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> hasCrossPoint:</span><br><span class="line">        crossP = np.around((<span class="number">1</span>-x[<span class="number">0</span>]-x[<span class="number">1</span>]) * v0 + x[<span class="number">0</span>]*v1 + x[<span class="number">1</span>] * v2)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;相交点为：[&#123;&#125;,&#123;&#125;,&#123;&#125;]\n&#x27;</span>.<span class="built_in">format</span>(crossP[<span class="number">0</span>],crossP[<span class="number">1</span>],crossP[<span class="number">2</span>]))    </span><br><span class="line">    <span class="keyword">if</span> isPlot:</span><br><span class="line">        <span class="comment"># 打开画图窗口1，在三维空间中绘图</span></span><br><span class="line">        fig = plt.figure(<span class="number">1</span>)</span><br><span class="line">        ax = fig.gca(projection=<span class="string">&#x27;3d&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 将数组中的前两个点进行连线</span></span><br><span class="line">        figure = ax.plot(ray[:, <span class="number">0</span>], ray[:, <span class="number">1</span>], ray[:, <span class="number">2</span>], c=<span class="string">&#x27;r&#x27;</span>, zorder=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 画出三角面片</span></span><br><span class="line">        ax.plot_trisurf(tri[:,<span class="number">0</span>], tri[:,<span class="number">1</span>], tri[:,<span class="number">2</span>], linewidth=<span class="number">0.2</span>, antialiased=<span class="literal">True</span>, zorder=<span class="number">2</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 画出相交点</span></span><br><span class="line">        <span class="keyword">if</span> hasCrossPoint:</span><br><span class="line">            crossP1 = np.expand_dims(crossP, axis=<span class="number">0</span>)</span><br><span class="line">            ax.plot(crossP1[:,<span class="number">0</span>], crossP1[:,<span class="number">1</span>], crossP1[:,<span class="number">2</span>], <span class="string">&#x27;o&#x27;</span>, color=<span class="string">&#x27;tab:brown&#x27;</span> ,markersize=<span class="number">10</span>)   </span><br><span class="line">        plt.show()</span><br><span class="line">    <span class="keyword">return</span></span><br><span class="line"></span><br><span class="line">o = np.array([<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>])</span><br><span class="line">d = np.array([<span class="number">150</span>, <span class="number">260</span>, <span class="number">450</span>])</span><br><span class="line">d2 = np.array([<span class="number">30</span>, <span class="number">100</span>, <span class="number">300</span>])</span><br><span class="line"></span><br><span class="line">ray = np.stack((o, d), axis=<span class="number">0</span>)</span><br><span class="line">ray2 = np.stack((o, d2), axis=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">v0 = np.array([<span class="number">30</span>, <span class="number">80</span>, <span class="number">60</span>])</span><br><span class="line">v1 = np.array([<span class="number">100</span>, <span class="number">70</span>, <span class="number">80</span>])</span><br><span class="line">v2 = np.array([<span class="number">70</span>, <span class="number">120</span>, <span class="number">400</span>])</span><br><span class="line"></span><br><span class="line">tri = np.stack((v0, v1, v2), axis=<span class="number">0</span>)</span><br><span class="line">isCross(tri, ray, <span class="literal">True</span>) <span class="comment"># 相交点为：[51.0,89.0,154.0]</span></span><br><span class="line">isCross(tri, ray2, <span class="literal">True</span>) <span class="comment"># 无相交点</span></span><br></pre></td></tr></table></figure>

<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" 
    src="\images\others\rayintersection\cross1.png">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">ray的效果图</div>
</center>

<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" 
    src="\images\others\rayintersection\cross2.png">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">ray2的效果图</div>
</center>

<h3 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h3><p><a href="https://www.cnblogs.com/graphics/archive/2010/08/09/1795348.html">[1]、射线和三角形的相交检测-C++实现</a></p>
]]></content>
      <categories>
        <category>图形学基础</category>
      </categories>
      <tags>
        <tag>相交检测</tag>
      </tags>
  </entry>
  <entry>
    <title>拉普拉斯矩阵与拉普拉斯算子的关系</title>
    <url>/2020/02/05/febd937d/</url>
    <content><![CDATA[<h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><p>首先贴出一段利用拉普拉斯矩阵进行光滑处理的代码，根据<em>Learning Category-Specific Mesh Reconstruction from Image Collections</em>中的描述，拉普拉斯算子可以获得表面的平均曲率，通过最小化平均曲率，就可以使得表面变得光滑。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">class LaplacianLoss(nn.Module):</span><br><span class="line">    def __init__(self, vertex, faces, average=False):</span><br><span class="line">        &#x27;&#x27;&#x27;</span><br><span class="line">			vertex: N*3</span><br><span class="line">            faces: F*3</span><br><span class="line">        &#x27;&#x27;&#x27;</span><br><span class="line">        super(LaplacianLoss, self).__init__()</span><br><span class="line">        self.nv = vertex.size(0)</span><br><span class="line">        self.nf = faces.size(0)</span><br><span class="line">        self.average = average</span><br><span class="line">        laplacian = np.zeros([self.nv, self.nv]).astype(np.float32)</span><br><span class="line"></span><br><span class="line">        laplacian[faces[:, 0], faces[:, 1]] = -1</span><br><span class="line">        laplacian[faces[:, 1], faces[:, 0]] = -1</span><br><span class="line">        laplacian[faces[:, 1], faces[:, 2]] = -1</span><br><span class="line">        laplacian[faces[:, 2], faces[:, 1]] = -1</span><br><span class="line">        laplacian[faces[:, 2], faces[:, 0]] = -1</span><br><span class="line">        laplacian[faces[:, 0], faces[:, 2]] = -1</span><br><span class="line"></span><br><span class="line">        r, c = np.diag_indices(laplacian.shape[0])</span><br><span class="line">        laplacian[r, c] = -laplacian.sum(1)</span><br><span class="line"></span><br><span class="line">        for i in range(self.nv):</span><br><span class="line">            laplacian[i, :] /= laplacian[i, i]</span><br><span class="line"></span><br><span class="line">        self.register_buffer(&#x27;laplacian&#x27;, torch.from_numpy(laplacian))</span><br><span class="line"></span><br><span class="line">    def forward(self, x):</span><br><span class="line">        batch_size = x.size(0)</span><br><span class="line">        x = torch.matmul(self.laplacian, x)</span><br><span class="line">        dims = tuple(range(x.ndimension())[1:])</span><br><span class="line">        x = x.pow(2).sum(dims)</span><br><span class="line">        if self.average:</span><br><span class="line">            return x.sum() / batch_size</span><br><span class="line">        else:</span><br><span class="line">            return x</span><br></pre></td></tr></table></figure>

<p><strong>Q：为什么拉普拉斯算子可以获得一个3D网格的平均曲率？</strong></p>
<p><strong>A: 图拉普拉斯矩阵，如果把它看作线性变换的话，它起的作用与数学分析中的拉普拉斯算子是一样的。也就是说拉普拉斯矩阵就是图上的拉普拉斯算子，或者说是离散的拉普拉斯算子。而拉普拉斯算子是用以获取连续可微函数的二阶微分（散度)。</strong></p>
<h2 id="拉普拉斯算子和拉普拉斯矩阵"><a href="#拉普拉斯算子和拉普拉斯矩阵" class="headerlink" title="拉普拉斯算子和拉普拉斯矩阵"></a>拉普拉斯算子和拉普拉斯矩阵</h2><h3 id="符号定义"><a href="#符号定义" class="headerlink" title="符号定义"></a>符号定义</h3><ul>
<li>$f$是欧式空间中的二阶可微实函数，或从图的视角看作一组高维向量。</li>
<li>$\Delta$为拉普拉斯算子，求欧式空间的散度</li>
<li>$L$为拉普拉斯矩阵，求图空间的散度</li>
</ul>
<h3 id="理论推导"><a href="#理论推导" class="headerlink" title="理论推导"></a>理论推导</h3><p><strong>梯度（矢量）</strong> ：梯度 $\nabla$ 的本意是一个向量（矢量），表示某一函数在该点处的方向导数沿着该方向取得最大值，即函数在该方向处沿着该方向（此梯度方向）变化最快，变化率最大（为该梯度的模）。假设一个三元函数 $u&#x3D;f(x,y,z)$ 在空间区域 $G$ 内具有一阶连续偏导数，点 $P(x,y,z) \in G$ ， 称向量</p>
<p>$\lbrace \frac{\partial f}{\partial x}, \frac{\partial f}{\partial y}, \frac{\partial f}{\partial z} \rbrace &#x3D; \frac{\partial f}{\partial x} \overrightarrow{i} + \frac{\partial f}{\partial y} \overrightarrow{j} + \frac{\partial f}{\partial z} \overrightarrow{k} \tag{1}$</p>
<p>为函数$u&#x3D;f(x,y,z)$在点$P$处的梯度，记为$gradf(x,y,z)$ 或 $\nabla f(x,y,z)$。其中： $\nabla &#x3D; \frac{\partial}{\partial x} \overrightarrow{i} + \frac{\partial}{\partial y} \overrightarrow{j} + \frac{\partial}{\partial z} \overrightarrow{k}$ 被称为三维向量的微分算子。</p>
<p><strong>散度（标量）</strong> 散度 $\nabla\cdot$（divergence）可用于表针空间中各点矢量场发散的强弱程度，物理上，散度的意义是场的有源性。当 $div(F)&gt;0$ ，表示该点有散发通量的正源（发散源）；当 $div(F)&lt;0$ 表示该点有吸收能量的负源（洞或汇）；当 $div(F)&#x3D;0$ ，表示该点无源。</p>
<p><strong>拉普拉斯算子</strong>： 拉普拉斯算子（Laplace Operator）是 $n$ 维欧几里得空间中的一个二阶微分算子，定义为梯度（ $\nabla f$ ）的散度（ $\nabla\cdot$ ）。 $\Delta f &#x3D; \nabla^2f &#x3D; \nabla \cdot \nabla f&#x3D; div(gradf)$。 在笛卡尔坐标系下，拉普拉斯算子可以被表示为：</p>
<p>$\Delta f &#x3D; \frac{\partial^2f}{\partial x^2} + \frac{\partial^2f}{\partial y^2} + \frac{\partial^2f}{\partial z^2} \tag{2}$</p>
<p>推广到$n$维空间中的形式为:</p>
<p>$\Delta &#x3D; \sum \limits_{i} \frac{\partial^2f}{\partial x^2_i} \tag{3}$</p>
<p>如果将其推导到离散的形式下：</p>
<p><img src="/images/others/laplacian/fig1.png"></p>
<p>$\Delta f &#x3D; \frac{\partial^2f}{\partial x^2} + \frac{\partial^2f}{\partial y^2} \\ &#x3D;f(x+1, y) + f(x-1,y) - 2f(x,y) + f(x,y+1) - 2f(x,y) \\<br>&#x3D;f(x+1, y) + f(x-1, y) + f(x, y+1) + f(x, y-1) - 4f(x,y) \tag{4}$</p>
<p>现在用<strong>散度</strong>的概念解读一下：</p>
<p>如果 $\Delta f &#x3D; 0$ ，可以近似认为中心点 $f(x,y)$ 的势和其周围点的势是相等的， $f(x,y)$局部范围内不存在势差。所以该点无源<br>$\Delta f &gt; 0$ ，可以近似认为中心点 $f(x,y)$ 的势低于周围点，可以想象成中心点如恒星一样发出能量，补给周围的点，所以该点是正源<br>$\Delta f &lt; 0$ ,可以近似认为中心点 $f(x,y)$ 的势高于周围点，可以想象成中心点如吸引子一样在吸收能量，所以该点是负源<br>另一个角度，拉普拉斯算子计算了周围点与中心点的梯度差。当 $f(x,y)$ 受到扰动之后，其可能变为相邻的 $f(x+1,y), f(x-1,y), f(x,y+1), f(x,y-1)$ 之一，拉普拉斯算子得到的是对该点进行微小扰动后可能获得的总增益 （或者说是总变化）。</p>
<p><strong>我们现在将这个结论推广到图</strong>： 假设具有 $N$ 个节点的图 $G$ ，此时以上定义的函数 $f$ 不再是二维，而是 $N$ 维向量： $f&#x3D;(f_1,f_2,…,f_n)$ ，其中 $f_i$ 为函数 $f$ 在图中节点 $i$ 处的函数值(<strong>注意：在实际中这个‘函数值’通常不是一个标量，而是一个高维向量，表征某个特征信息</strong>)。类比于 $f(x,y)$ 在节点 $(x_i,y_i)$ 处的值。对 $i$ 节点进行扰动，它可能变为任意一个与它相邻的节点 $j \in N_i$ , $N_i$ 表示节点 $i$ 的一环邻域节点。</p>
<p>通过公式(4)，可以推广得到下面公式</p>
<p>$\Delta f_i &#x3D; \sum \limits_{j \in N_i}W_{ij}(f_i - f_j) \tag{5}$</p>
<p>其中， $W_{ij}$表示的边的权重， $N_i$表示节点$i$的一环邻域。当$W_{ij} &#x3D; 1$时，我们继续化简公式，可以得到：</p>
<p>$\Delta f_i &#x3D; \sum \limits_{j \in N_i}W_{ij}(f_i - f_j) \\<br>&#x3D;\sum \limits_{j \in N_i}W_{ij}f_i - \sum \limits_{j \in N_i}W_{ij}f_j \\<br>&#x3D;d_if_i - \sum \limits_{j \in N_i}W_{ij}f_j \tag{6}$</p>
<p>我们把$d_i$记为节点$i$的度，那么我们可以得到对于$f&#x3D;(f_1, f_2, \cdots,f_n)$的拉普拉斯矩阵为：</p>
<p>$\Delta f &#x3D; Df - Wf \\<br>&#x3D;(D-W)f \\<br>&#x3D; \left(\begin{bmatrix} d_1 &amp; 0 &amp; \cdots &amp; 0 &amp; 0\\ 0 &amp; d_2 &amp; \cdots &amp; 0 &amp; 0\\ \vdots &amp; 0 &amp; \cdots &amp; d_{n-1}&amp; 0 \\ 0 &amp; 0 &amp; \cdots\ &amp; 0 &amp; d_{n}\end{bmatrix} - \begin{bmatrix} 1 &amp; 0 &amp; \cdots &amp; 0 &amp; 1 \\ 0 &amp; 0 &amp; \cdots &amp; 1 &amp; 0 \\ 1 &amp; 1 &amp; \cdots &amp; 0 &amp; 1 \\ 0 &amp; 1 &amp; \cdots &amp; 0 &amp; 1 \end{bmatrix}\right) f \\<br>&#x3D; Lf \tag{7}$</p>
<p><strong>其中，当边的权重$W_{ij}$均为1时，$D,W$分别为关于网（graph)的度矩阵和邻接矩阵。</strong></p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>拉普拉斯矩阵$L$其实是离散化拉普拉斯算子的一种表示方式，通过这个方式，可以求得以图表示的，非规则结构的，点与点之间的二阶微分（某点曲率与该点关于函数的二阶导有关）。我们可以利用求得的曲率，来使平面变得光滑。</p>
<p>离散化拉普拉斯算子有多种表示形式，主要差别是符号，缩放因子上的差别。</p>
<p>公式(7)中的$W_{ij}$有不同的选择，比较常见的有常数1，度的倒数$\frac{1}{d_i}$, 余切权重 $\frac{\cot \alpha_{ij} + \cot \beta_{ij}}{2}$, $\alpha$和$\beta$为空间四边形$aibj$的相对角</p>
]]></content>
  </entry>
  <entry>
    <title>树的遍历算法</title>
    <url>/2019/12/25/cb9a2247/</url>
    <content><![CDATA[<h3 id="层次遍历"><a href="#层次遍历" class="headerlink" title="层次遍历"></a>层次遍历</h3><h4 id="使用vector"><a href="#使用vector" class="headerlink" title="使用vector"></a>使用vector</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">class Solution &#123;</span><br><span class="line">public:</span><br><span class="line">    vector&lt;vector&lt;int&gt;&gt; levelOrder(TreeNode* root) &#123;</span><br><span class="line">        </span><br><span class="line">        vector&lt;TreeNode*&gt; curQue;</span><br><span class="line">        vector&lt;TreeNode*&gt; nextQue;</span><br><span class="line">        vector&lt;vector&lt;int&gt;&gt; res;</span><br><span class="line">        vector&lt;int&gt; tmp;</span><br><span class="line">        int depth=0;</span><br><span class="line">        </span><br><span class="line">        if(!root) return res; </span><br><span class="line">        </span><br><span class="line">        curQue.push_back(root);</span><br><span class="line">        </span><br><span class="line">        while(!curQue.empty())&#123;</span><br><span class="line">            for(int i =0; i&lt;curQue.size(); i++)&#123;</span><br><span class="line">                if(curQue[i]-&gt;left != NULL)&#123;</span><br><span class="line">                    nextQue.push_back(curQue[i]-&gt;left);</span><br><span class="line">                &#125;</span><br><span class="line">                if(curQue[i]-&gt;right != NULL)&#123;</span><br><span class="line">                    nextQue.push_back(curQue[i]-&gt;right);</span><br><span class="line">                &#125;</span><br><span class="line">                tmp.push_back(curQue[i]-&gt;val);</span><br><span class="line">            &#125;</span><br><span class="line">            </span><br><span class="line">            res.push_back(tmp);</span><br><span class="line">            curQue = nextQue;</span><br><span class="line">            depth++;</span><br><span class="line">            nextQue.clear();</span><br><span class="line">            tmp.clear();</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        return res;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<h4 id="使用双端队列"><a href="#使用双端队列" class="headerlink" title="使用双端队列"></a>使用双端队列</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">class Solution &#123;</span><br><span class="line">public:</span><br><span class="line">    vector&lt;vector&lt;int&gt;&gt; levelOrder(TreeNode* root) &#123;</span><br><span class="line">        vector&lt;vector&lt;int&gt;&gt; res;</span><br><span class="line">        if(!root) return res;</span><br><span class="line">        vector&lt;int&gt; path;</span><br><span class="line">        deque&lt;TreeNode*&gt; cur, next;</span><br><span class="line">        cur.push_back(root);</span><br><span class="line">        while(!cur.empty())&#123;</span><br><span class="line">            TreeNode* k = cur.front();</span><br><span class="line">            cur.pop_front();</span><br><span class="line">            </span><br><span class="line">            path.push_back(k-&gt;val);</span><br><span class="line">            if(k-&gt;left) next.push_back(k-&gt;left);</span><br><span class="line">            if(k-&gt;right) next.push_back(k-&gt;right);</span><br><span class="line">            </span><br><span class="line">            if(cur.empty()) &#123;</span><br><span class="line">                res.push_back(path);</span><br><span class="line">                path.clear();</span><br><span class="line">                swap(cur, next);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        return res;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>上边两种方法大同小异，主要是使用的数据结构不同。</p>
<h4 id="使用图（map）"><a href="#使用图（map）" class="headerlink" title="使用图（map）"></a>使用图（map）</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">class Solution &#123;</span><br><span class="line">private:</span><br><span class="line">    </span><br><span class="line">    // Map sorts by key, maintains </span><br><span class="line">    // our levels in order</span><br><span class="line">    map&lt;int, vector&lt;int&gt;&gt; ourLevels;</span><br><span class="line">    </span><br><span class="line">    void insertAtLevel(TreeNode* root, int level) &#123;</span><br><span class="line">        if (!root) return;</span><br><span class="line">        // Visit each node once, add it to our map that</span><br><span class="line">        // maps nodes to their levels in the tree</span><br><span class="line">        ourLevels[level].push_back(root-&gt;val);</span><br><span class="line">        insertAtLevel(root-&gt;left, level + 1);</span><br><span class="line">        insertAtLevel(root-&gt;right, level + 1);</span><br><span class="line">        return;</span><br><span class="line">    &#125;</span><br><span class="line">public:</span><br><span class="line">    vector&lt;vector&lt;int&gt;&gt; levelOrder(TreeNode* root) &#123;</span><br><span class="line">        vector&lt;vector&lt;int&gt;&gt; ourRes;</span><br><span class="line">        insertAtLevel(root, 0);</span><br><span class="line">        // Go over each level in our map</span><br><span class="line">        for (const auto&amp; key : ourLevels) &#123;</span><br><span class="line">        // Push the level into our result vector</span><br><span class="line">            ourRes.push_back(key.second);</span><br><span class="line">        &#125;</span><br><span class="line">        return ourRes;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>使用图的方法，主要是遍历到每个节点时，保存它的层次信息在图中。</p>
<h3 id="中序遍历"><a href="#中序遍历" class="headerlink" title="中序遍历"></a>中序遍历</h3><p>leetcode 94</p>
<p>Reference: <a href="https://www.cnblogs.com/grandyang/p/4297300.html">https://www.cnblogs.com/grandyang/p/4297300.html</a></p>
<h4 id="Recursion"><a href="#Recursion" class="headerlink" title="Recursion"></a>Recursion</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">// 回溯法</span><br><span class="line">class Solution &#123;</span><br><span class="line">public:</span><br><span class="line">    vector&lt;int&gt; inorderTraversal(TreeNode* root) &#123;</span><br><span class="line">    	// 用以存储每次访问的结点值</span><br><span class="line">        vector&lt;int&gt; res;</span><br><span class="line">        inorder(root,res);</span><br><span class="line">        return res;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">private:</span><br><span class="line">    void inorder(TreeNode *root, vector&lt;int&gt; &amp;res)&#123;</span><br><span class="line">        if(!root) return;</span><br><span class="line">        if(root-&gt;left) inorder(root-&gt;left, res);</span><br><span class="line">        res.push_back(root-&gt;val);</span><br><span class="line">        if(root-&gt;right) inorder(root-&gt;right,res);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<h4 id="w-o-Recursion"><a href="#w-o-Recursion" class="headerlink" title="w&#x2F;o Recursion"></a>w&#x2F;o Recursion</h4><h5 id="方法一"><a href="#方法一" class="headerlink" title="方法一"></a>方法一</h5><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">class Solution &#123;</span><br><span class="line">public:</span><br><span class="line">    vector&lt;int&gt; inorderTraversal(TreeNode *root) &#123;</span><br><span class="line">        vector&lt;int&gt; res;</span><br><span class="line">        stack&lt;TreeNode*&gt; s;</span><br><span class="line">        TreeNode* p = root;</span><br><span class="line">        while(p || !s.empty())&#123;</span><br><span class="line">            while(p)&#123;</span><br><span class="line">                s.push(p);</span><br><span class="line">                p = p-&gt;left;</span><br><span class="line">            &#125;</span><br><span class="line">            p = s.top();</span><br><span class="line">            s.pop();</span><br><span class="line">            res.push_back(p-&gt;val);</span><br><span class="line">            p = p-&gt;right;</span><br><span class="line">        &#125;</span><br><span class="line">     return res;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<h5 id="方法二"><a href="#方法二" class="headerlink" title="方法二"></a>方法二</h5><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">class Solution &#123;</span><br><span class="line">public:</span><br><span class="line">    vector&lt;int&gt; preorderTraversal(TreeNode* root) &#123;</span><br><span class="line">        vector&lt;int&gt; res;</span><br><span class="line">        stack&lt;TreeNode*&gt; s;</span><br><span class="line">        TreeNode *p = root;</span><br><span class="line">        while (!s.empty() || p) &#123;</span><br><span class="line">            if (p) &#123;</span><br><span class="line">                s.push(p);</span><br><span class="line">                // 先访问跟结点，在压入栈中</span><br><span class="line">                res.push_back(p-&gt;val); </span><br><span class="line">                p = p-&gt;left;</span><br><span class="line">            &#125; else &#123;</span><br><span class="line">                TreeNode *t = s.top(); s.pop();</span><br><span class="line">                p = t-&gt;right;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        return res;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<h3 id="后序遍历"><a href="#后序遍历" class="headerlink" title="后序遍历"></a>后序遍历</h3><p>leetcode: 145<br>Reference: <a href="https://www.cnblogs.com/grandyang/p/4146981.html">https://www.cnblogs.com/grandyang/p/4146981.html</a></p>
<h4 id="Recursion-1"><a href="#Recursion-1" class="headerlink" title="Recursion"></a>Recursion</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">// 回溯法</span><br><span class="line">class Solution &#123;</span><br><span class="line">public:</span><br><span class="line">    vector&lt;int&gt; preorderTraversal(TreeNode* root) &#123;</span><br><span class="line">    	// 用以存储每次访问的结点值</span><br><span class="line">        vector&lt;int&gt; res;</span><br><span class="line">        preorder(root,res);</span><br><span class="line">        return res;</span><br><span class="line">    &#125;    </span><br><span class="line">private:</span><br><span class="line">    void preorder(TreeNode *root, vector&lt;int&gt; &amp;res)&#123;</span><br><span class="line">        if(!root) return;</span><br><span class="line">        res.push_back(root-&gt;val);</span><br><span class="line">        if(root-&gt;left) preorder(root-&gt;left, res);   </span><br><span class="line">        if(root-&gt;right) preorder(root-&gt;right,res);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<h4 id="w-o-Recursion-1"><a href="#w-o-Recursion-1" class="headerlink" title="w&#x2F;o Recursion"></a>w&#x2F;o Recursion</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">class Solution &#123;</span><br><span class="line">public:</span><br><span class="line">    vector&lt;int&gt; preorderTraversal(TreeNode *root) &#123;</span><br><span class="line">        vector&lt;int&gt; res;</span><br><span class="line">        stack&lt;TreeNode*&gt; s;</span><br><span class="line">        TreeNode* p = root;</span><br><span class="line">        while(p || !s.empty())&#123;</span><br><span class="line">           if(p)&#123;</span><br><span class="line">               s.push(p);</span><br><span class="line">               p = p-&gt;left;</span><br><span class="line">           &#125;else&#123;</span><br><span class="line">               p = s.top();</span><br><span class="line">               s.pop();</span><br><span class="line">               res.push_back(p-&gt;val);</span><br><span class="line">               p = p-&gt;right;</span><br><span class="line">           &#125;</span><br><span class="line">        &#125;</span><br><span class="line">     return res;</span><br><span class="line">    &#125;   </span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<h3 id="先序遍历"><a href="#先序遍历" class="headerlink" title="先序遍历"></a>先序遍历</h3><h4 id="Recursion-2"><a href="#Recursion-2" class="headerlink" title="Recursion"></a>Recursion</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">// 回溯法</span><br><span class="line">class Solution &#123;</span><br><span class="line">public:</span><br><span class="line">    vector&lt;int&gt; postorderTraversal(TreeNode* root) &#123;</span><br><span class="line">    	// 用以存储每次访问的结点值</span><br><span class="line">        vector&lt;int&gt; res;</span><br><span class="line">        postorder(root,res);</span><br><span class="line">        return res;</span><br><span class="line">    &#125;    </span><br><span class="line">private:</span><br><span class="line">    void postorder(TreeNode *root, vector&lt;int&gt; &amp;res)&#123;</span><br><span class="line">        if(!root) return;</span><br><span class="line">        if(root-&gt;left) preorder(root-&gt;left, res);   </span><br><span class="line">        if(root-&gt;right) preorder(root-&gt;right,res);</span><br><span class="line">        res.push_back(root-&gt;val);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<h4 id="w-o-Recursion-2"><a href="#w-o-Recursion-2" class="headerlink" title="w&#x2F;o Recursion"></a>w&#x2F;o Recursion</h4><p>leetcode 145</p>
<p>Reference: <a href="https://www.cnblogs.com/grandyang/p/4251757.html">https://www.cnblogs.com/grandyang/p/4251757.html</a></p>
<h5 id="方法一-1"><a href="#方法一-1" class="headerlink" title="方法一"></a>方法一</h5><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">class Solution &#123;</span><br><span class="line">public:</span><br><span class="line">    vector&lt;int&gt; postorderTraversal(TreeNode *root) &#123;</span><br><span class="line">        if (!root) return &#123;&#125;;</span><br><span class="line">        vector&lt;int&gt; res;</span><br><span class="line">        stack&lt;TreeNode*&gt; s&#123;&#123;root&#125;&#125;;</span><br><span class="line">        TreeNode *head = root;</span><br><span class="line">        while (!s.empty()) &#123;</span><br><span class="line">            TreeNode *t = s.top();</span><br><span class="line">            if ((!t-&gt;left &amp;&amp; !t-&gt;right) || t-&gt;left == head || t-&gt;right == head) &#123;</span><br><span class="line">                res.push_back(t-&gt;val);</span><br><span class="line">                s.pop();</span><br><span class="line">                head = t;</span><br><span class="line">            &#125; else &#123;</span><br><span class="line">                if (t-&gt;right) s.push(t-&gt;right);</span><br><span class="line">                if (t-&gt;left) s.push(t-&gt;left);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        return res;</span><br><span class="line">    &#125;   </span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<h5 id="方法二-1"><a href="#方法二-1" class="headerlink" title="方法二"></a>方法二</h5><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">class Solution &#123;</span><br><span class="line">public:</span><br><span class="line">    vector&lt;int&gt; postorderTraversal(TreeNode* root) &#123;</span><br><span class="line">        if (!root) return &#123;&#125;;</span><br><span class="line">        vector&lt;int&gt; res;</span><br><span class="line">        stack&lt;TreeNode*&gt; s&#123;&#123;root&#125;&#125;;</span><br><span class="line">        while (!s.empty()) &#123;</span><br><span class="line">            TreeNode *t = s.top(); s.pop();</span><br><span class="line">            res.insert(res.begin(), t-&gt;val);</span><br><span class="line">            if (t-&gt;left) s.push(t-&gt;left);</span><br><span class="line">            if (t-&gt;right) s.push(t-&gt;right);</span><br><span class="line">        &#125;</span><br><span class="line">        return res;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>


<h5 id="方法三"><a href="#方法三" class="headerlink" title="方法三"></a>方法三</h5><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">class Solution &#123;</span><br><span class="line">public:</span><br><span class="line">    vector&lt;int&gt; postorderTraversal(TreeNode* root) &#123;</span><br><span class="line">        vector&lt;int&gt; res;</span><br><span class="line">        stack&lt;TreeNode*&gt; s;</span><br><span class="line">        TreeNode *p = root;</span><br><span class="line">        while (!s.empty() || p) &#123;</span><br><span class="line">            if (p) &#123;</span><br><span class="line">                s.push(p);</span><br><span class="line">                res.insert(res.begin(), p-&gt;val);</span><br><span class="line">                p = p-&gt;right;</span><br><span class="line">            &#125; else &#123;</span><br><span class="line">                TreeNode *t = s.top(); s.pop();</span><br><span class="line">                p = t-&gt;left;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        return res;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>数据结构与算法</category>
        <category>遍历算法</category>
      </categories>
      <tags>
        <tag>中序</tag>
        <tag>后序</tag>
        <tag>先序</tag>
        <tag>层次</tag>
      </tags>
  </entry>
  <entry>
    <title>常见排序算法</title>
    <url>/2019/12/05/ec44b182/</url>
    <content><![CDATA[<p>2019年12月18日更新：加入归并排序的两种链表版本：top-down, bottom-up。</p>
<p>2019年12月28日更新：加入桶排序算法</p>
<p>2020年3月20日更新：加入堆排序，计数排序，希尔排序</p>
<h2 id="冒泡排序"><a href="#冒泡排序" class="headerlink" title="冒泡排序"></a>冒泡排序</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">//冒泡排序: 每次迭代最大的在最上方</span><br><span class="line"> int* sort(int* nums, int numsSize)&#123;</span><br><span class="line">     int tmp = 0;</span><br><span class="line">     // 注意这里的起始值</span><br><span class="line">     for(int i =numsSize-1;i&gt;0;i--)&#123; //最大的值所放置的位置</span><br><span class="line">         for(int j = 0;j&lt;i;j++)&#123; // 比较的位置</span><br><span class="line">             if(nums[j] &gt; nums[j+1])&#123;</span><br><span class="line">                 tmp = nums[j];</span><br><span class="line">                 nums[j] = nums[j+1];</span><br><span class="line">                 nums[j+1] = tmp;</span><br><span class="line">             &#125;</span><br><span class="line">        &#125;</span><br><span class="line">     &#125;</span><br><span class="line">     return nums;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>时间复杂度：$O(n^2)$  空间复杂度：$O(1)$ 稳定</p>
<h2 id="选择排序"><a href="#选择排序" class="headerlink" title="选择排序"></a>选择排序</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">// 选择排序 找到最大或最小的值，放在最边的位置</span><br><span class="line"> int* sort(int* nums, int numsSize)&#123;</span><br><span class="line">     int minInd = 0;</span><br><span class="line">     int tmp = 0;</span><br><span class="line">     for(int i=0;i&lt;numsSize-1;i++)&#123; //最小值的位置 和 比较的位置</span><br><span class="line">         minInd = i;</span><br><span class="line">         for(int j =i+1;j&lt;numsSize;j++)&#123;</span><br><span class="line">             if(nums[minInd] &gt; nums[j])&#123;</span><br><span class="line">                 minInd = j;</span><br><span class="line">             &#125;</span><br><span class="line">         &#125;</span><br><span class="line">         // 交换</span><br><span class="line">         tmp = nums[i];</span><br><span class="line">         nums[i] = nums[minInd];</span><br><span class="line">         nums[minInd] = tmp;</span><br><span class="line">     &#125;</span><br><span class="line">     return nums;</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure>
<p>时间复杂度：$O(n^2)$  空间复杂度：$O(1)$ 不稳定</p>
<h2 id="插入排序"><a href="#插入排序" class="headerlink" title="插入排序"></a>插入排序</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">// 插入排序 每次迭代，都与以排序好的数组进行比较，在排序好的数组中找到合适的位置。 </span><br><span class="line"> int* sort(int* nums, int numsSize)&#123;</span><br><span class="line">     for(int i=0;i&lt;numsSize;i++)&#123;</span><br><span class="line">         int tmp = nums[i];</span><br><span class="line">         int j =i;</span><br><span class="line">        </span><br><span class="line">         while(j&gt;0 &amp;&amp; tmp &lt; nums[j-1])&#123;</span><br><span class="line">             nums[j] = nums[j-1];</span><br><span class="line">             j=j-1;</span><br><span class="line">         &#125;</span><br><span class="line">         nums[j] = tmp;</span><br><span class="line">     &#125;</span><br><span class="line">     return nums;</span><br><span class="line"> &#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>时间复杂度：$O(n^2)$  空间复杂度：$O(1)$  稳定</p>
<h2 id="归并排序"><a href="#归并排序" class="headerlink" title="归并排序"></a>归并排序</h2><ul>
<li>数组Top-Down版本</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">// 归并排序 分治算法</span><br><span class="line">void merge(int* nums, int start, int mid, int end)&#123;</span><br><span class="line">    // for(int i=start;i&lt;=end;i++)&#123;</span><br><span class="line">        // printf(&quot;%d  &quot;,nums[i]);</span><br><span class="line">    // &#125;</span><br><span class="line">    // printf(&quot;\n&quot;);</span><br><span class="line">    int p =start, q =mid+1;</span><br><span class="line">    int* newNums = (int*)malloc(sizeof(int) * (end-start+1));</span><br><span class="line">    int k =0;</span><br><span class="line">   </span><br><span class="line">    for(int i = start;i&lt;=end;i++)&#123;</span><br><span class="line">        // 检查第一部分是否完毕</span><br><span class="line">        if(p &gt; mid)</span><br><span class="line">            newNums[k++] = nums[q++];</span><br><span class="line">        else if(q &gt; end)</span><br><span class="line">            newNums[k++] = nums[p++];</span><br><span class="line">        else if(nums[p] &lt; nums[q])</span><br><span class="line">            newNums[k++] = nums[p++];</span><br><span class="line">        else</span><br><span class="line">            newNums[k++] = nums[q++];</span><br><span class="line">    &#125;</span><br><span class="line">	   </span><br><span class="line">    for(int p=0;p&lt;k;p++)&#123;</span><br><span class="line">        nums[start++] = newNums[p];</span><br><span class="line">    &#125;   </span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">void divide(int* nums, int start, int end)&#123;</span><br><span class="line">    if(start &lt; end)&#123;</span><br><span class="line">        int mid = (start + end) / 2;</span><br><span class="line">        divide(nums,start,mid);</span><br><span class="line">        divide(nums, mid+1, end);</span><br><span class="line">       </span><br><span class="line">        merge(nums, start , mid ,end);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">int* sort(int* nums, int numsSize)&#123;</span><br><span class="line">    divide(nums, 0, numsSize-1);</span><br><span class="line">    return nums;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>时间复杂度：$O(n\log_2{n})$  空间复杂度：$O(n+log_2{n})$  稳定</p>
<ul>
<li>链表Top-Down版本</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">class Solution &#123;</span><br><span class="line">public:</span><br><span class="line">    ListNode* sortList(ListNode* head) &#123;</span><br><span class="line">        if(!head || !head-&gt;next) return head;</span><br><span class="line">          /*</span><br><span class="line">            这里head-&gt;next是要给trick, 因为如果不加next的话,若子链长度为2,在</span><br><span class="line">            一次walk之后，fast指向nullptr,slow就指向最后一个元素，而下边有mid =slow-&gt;next = nullptr</span><br><span class="line">            所以就直接返回了，等于只有左半边链。而这时做半边脸仍然有两个元素，就会陷入循环，导致无法正常结束。</span><br><span class="line">            换句话说，如果不加next, 当子链长度为2时，就无法继续进行分治（分为左右两个长度为1的子链）,使得程序无法结束。</span><br><span class="line">            而又由于我们使用递归，使得栈不断有新数据写入，最后就栈满溢出。</span><br><span class="line">        */</span><br><span class="line">        ListNode* slow = head;</span><br><span class="line">        ListNode* fast = head-&gt;next;</span><br><span class="line">        // 当fast走到低时，slow正好在中间</span><br><span class="line">        while(fast &amp;&amp; fast-&gt;next)&#123;</span><br><span class="line">            fast = fast-&gt;next-&gt;next;</span><br><span class="line">            slow = slow-&gt;next;</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        ListNode* mid = slow-&gt;next;</span><br><span class="line">        // 将左，右两个子链断开</span><br><span class="line">        slow-&gt;next = nullptr;</span><br><span class="line">        </span><br><span class="line">        return merge(sortList(head), sortList(mid));</span><br><span class="line">    &#125;</span><br><span class="line">private:</span><br><span class="line">    // 两个子链排序，空间复杂度为常数</span><br><span class="line">    ListNode* merge(ListNode* l1, ListNode* l2)&#123;</span><br><span class="line">        ListNode dummy(0);</span><br><span class="line">        ListNode* tail = &amp;dummy;</span><br><span class="line">        while(l1 &amp;&amp; l2)&#123;</span><br><span class="line">            if(l1-&gt;val &gt; l2-&gt;val)</span><br><span class="line">                swap(l1,l2);</span><br><span class="line">            tail-&gt;next = l1;</span><br><span class="line">            l1 = l1-&gt;next;            </span><br><span class="line">            tail = tail-&gt;next;</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        if(l1) tail-&gt;next = l1;</span><br><span class="line">        if(l2) tail-&gt;next = l2;</span><br><span class="line">        </span><br><span class="line">        return dummy.next;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p>时间复杂度：$O(log_2{n})$ 空间复杂度$(log_2{n})$ 稳定</p>
<ul>
<li>链表Bottom-up版本</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">class Solution &#123;</span><br><span class="line">public:</span><br><span class="line">    ListNode* sortList(ListNode* head) &#123;</span><br><span class="line">        </span><br><span class="line">        if(!head || !head-&gt;next) return head;</span><br><span class="line">        //由于我们采用bottom-up,所以需要知道整个链表的长度，作为大致范围的限制，但要求不算严格</span><br><span class="line">        int len = 0;</span><br><span class="line">        ListNode* cur = head;</span><br><span class="line">        // 获取长度</span><br><span class="line">        while(cur = cur-&gt;next) ++len;</span><br><span class="line">        </span><br><span class="line">        ListNode dummy(0);</span><br><span class="line">        dummy.next = head;</span><br><span class="line">        </span><br><span class="line">        ListNode* l;</span><br><span class="line">        ListNode* r;</span><br><span class="line">        ListNode* tail;</span><br><span class="line">        </span><br><span class="line">        for(int n =1; n&lt;len; n&lt;&lt;=1)&#123;</span><br><span class="line">        	/*</span><br><span class="line">                cur不能等于head, 因为head只是一个存储值得指针名，并不是代表</span><br><span class="line">                它在每次排序之后，都是头结点，可能在一次排序过后，head指针所</span><br><span class="line">                指的那个元素，就被放置在了最尾处，所以不能每次都将起始位置初始化为head.</span><br><span class="line">                这也是为什么要维护一个dummy结点，使dummy结点每次都指向真正的头节点。</span><br><span class="line">            */</span><br><span class="line">            // cur = head;</span><br><span class="line">            cur = dummy.next;</span><br><span class="line">            tail = &amp;dummy;</span><br><span class="line">            while(cur)&#123;</span><br><span class="line">                l = cur;</span><br><span class="line">                r = split(l, n);</span><br><span class="line">                cur = split(r, n);</span><br><span class="line">                </span><br><span class="line">                auto merged = merge(l, r);</span><br><span class="line">                tail-&gt;next = merged.first;</span><br><span class="line">                tail = merged.second;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        return dummy.next;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">private:</span><br><span class="line">    // 前n个元素一组，剩下的元素一组，返回剩下元素的head</span><br><span class="line">    ListNode* split(ListNode* head, int n)&#123;</span><br><span class="line">    	// 这里需要注意的是子链长度n是包括了头结点的长度</span><br><span class="line">        while(--n &amp;&amp; head)</span><br><span class="line">            head = head-&gt;next;</span><br><span class="line">        </span><br><span class="line">        ListNode* rest = head ? head-&gt;next : nullptr;     </span><br><span class="line">        if(head) head-&gt;next = nullptr;</span><br><span class="line">        // 上面两行或换成下面易懂</span><br><span class="line">        // if(head)&#123;</span><br><span class="line">        //     rest = head-&gt;next;</span><br><span class="line">        //     head-&gt;next = nullptr;</span><br><span class="line">        // &#125;else&#123;</span><br><span class="line">        //     rest = nullptr;</span><br><span class="line">        // &#125;</span><br><span class="line">        return rest;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    pair&lt;ListNode*, ListNode*&gt; merge(ListNode* l1, ListNode* l2)&#123;</span><br><span class="line">        ListNode dummy(0);</span><br><span class="line">        ListNode* tail = &amp;dummy;</span><br><span class="line">        while( l1 &amp;&amp; l2)&#123;</span><br><span class="line">            if(l1-&gt;val &gt; l2-&gt;val) swap(l1,l2);</span><br><span class="line">            </span><br><span class="line">            tail-&gt;next = l1;</span><br><span class="line">            l1 = l1-&gt;next;</span><br><span class="line">            tail = tail-&gt;next;</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        tail-&gt;next = l1 ? l1 : l2;</span><br><span class="line">        while( tail-&gt;next) tail = tail-&gt;next;</span><br><span class="line">        return &#123;dummy.next, tail&#125;;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p>时间复杂度：$O(log_2{n})$ 空间复杂度：$O(1)$</p>
<p>首先对于Top-Down版本来讲，数组版本由于每次需要新建一个数组来对左右两部分子数组进行排序，所以相较于链表版本来说要多$O(n)$的空间复杂度。而对于Top-Down的版本，无论是数组还是链表，都比Bottom-up版本多了递归操作，所以空间复杂度要多$O(log_2{n})$。</p>
<h2 id="快速排序"><a href="#快速排序" class="headerlink" title="快速排序##"></a>快速排序##</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">int partition(int* nums, int start, int end) &#123;</span><br><span class="line">    int pivot = start;</span><br><span class="line">    int l = pivot + 1;</span><br><span class="line">    int r = end;</span><br><span class="line">    int tmp = 0;</span><br><span class="line">    // 等号是防止长度为2的子序列</span><br><span class="line">    while (l &lt;= r) &#123;</span><br><span class="line">        while (l &lt;= end &amp;&amp; nums[l] &lt;= nums[pivot]) &#123;</span><br><span class="line">            ++ l;</span><br><span class="line">        &#125;</span><br><span class="line">        while (r &gt;= start &amp;&amp; nums[r] &gt; nums[pivot]) &#123;</span><br><span class="line">            -- r;</span><br><span class="line">        &#125;</span><br><span class="line">        if (l &lt; r) &#123;</span><br><span class="line">            tmp = nums[l];</span><br><span class="line">            nums[l] = nums[r];</span><br><span class="line">            nums[r] = tmp;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;;</span><br><span class="line">    // 这里由于pivot是取到最*左边*一个，要保证交换后，pivot左侧必须全部小于pivot，右侧必须全部大于pivot，就必须</span><br><span class="line">    // 与右指针所指元素进行交换（因为这时候右指针所指元素（记为i）小于pivot,交换之后，i还是在pivot*左边*，这就符合条件。</span><br><span class="line">    // 假设与左指针进行交换，那么由于做指针所指元素大于pivot，交换之后，在pivot左边就有一个大于pivot的元素，不符合条件。</span><br><span class="line">    tmp = nums[pivot];</span><br><span class="line">    nums[pivot] = nums[r];</span><br><span class="line">    nums[r] = tmp;</span><br><span class="line">    pivot = r;</span><br><span class="line">    return pivot;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">void quick_sort(int* nums, int start, int end)&#123;</span><br><span class="line">    if(start &lt; end)&#123;</span><br><span class="line">        int piv_pos = partition(nums, start, end);</span><br><span class="line">        quick_sort(nums,start,piv_pos-1); // sorts the left side of pivot</span><br><span class="line">        quick_sort(nums, piv_pos+1,end);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">int* sort(int* nums, int numsSize)&#123;</span><br><span class="line">    quick_sort(nums,0,numsSize-1);</span><br><span class="line">    return nums;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>时间复杂度：$O(n\log_2{n})$  空间复杂度：$O(1)$  不稳定</p>
<h2 id="桶排序"><a href="#桶排序" class="headerlink" title="桶排序##"></a>桶排序##</h2><p>桶排序（Bucket sort）或所谓的箱排序，是一个排序算法，工作的原理是将数组分到有限数量的桶里。每个桶再个别排序（有可能再使用别的排序算法或是以递归方式继续使用桶排序进行排序）。桶排序是鸽巢排序的一种归纳结果。当要被排序的数组内的数值是均匀分配的时候，桶排序使用线性时间$\Theta (n)$。但桶排序并不是比较排序，他不受到$O(n\log_2 n)$下限的影响。具体步骤如下：</p>
<ul>
<li>设置一个定量的数组当做空桶子</li>
<li>寻访序列，并且把每一个元素一个一个放到对应的桶子中</li>
<li>对每个不是空的桶子进行排序</li>
<li>从不是空的桶子里把项目再放回原来的序列中。</li>
</ul>
<p>假设我们有一组长度为20的数据, 同时设定空桶子数量为5:</p>
<blockquote>
<p>[63,157,189,51,101,47,141,121,157,156,194,117,98,139,67,133,181,13,28,109] </p>
</blockquote>
<ul>
<li>找到数组中的最大值194和最小值13，然后根据桶数为5，计算出每个桶中的数据范围为<code>(194-13+1)/5=36.4</code></li>
<li>遍历原始数据，(以第一个数据63为例)先找到该数据对应的桶序列<code>(63 - 13) / 36.4) =1</code>，然后将该数据放入序列为1的桶中(从0开始算)</li>
<li>当向同一个序列的桶中第二次插入数据时，判断桶中已存在的数字与新插入的数字的大小，按从左到右，从小打大的顺序插入。如第一个桶已经有了63，再插入51，67后，桶中的排序为(51,63,67) 一般通过链表来存放桶中数据。</li>
<li>全部数据装桶完毕后，按序列，从小到大合并所有非空的桶(如0,1,2,3,4桶)</li>
<li>全部数据装桶完毕后，按序列，从小到大合并所有非空的桶(如0,1,2,3,4桶)</li>
</ul>
<p><img src="/images/others/sort/bucketSort_1.png"></p>
<p>桶排序的时间复杂度主要受两个因素影响。</p>
<ul>
<li>循环计算每个元素是属于哪个桶：O(n)</li>
<li>对每个桶内的元素进行排序，受不同排序算法的影响，最好情况为：$\sum \limits^{N} \limits_{i&#x3D;1}O(n_i\log_2(n_i))$, $n_i$为每个桶内的元素数量。</li>
</ul>
<p>可以看出，若每个桶内的数量均为1的话，则时间复杂度为$O(n)$</p>
<h3 id="堆排序"><a href="#堆排序" class="headerlink" title="堆排序"></a>堆排序</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">#include&lt;vector&gt;</span><br><span class="line">#include&lt;string&gt;</span><br><span class="line">using namespace std;</span><br><span class="line">void show(const vector&lt;int&gt;&amp; nums,const string&amp; describe)&#123;</span><br><span class="line">    cout &lt;&lt; describe &lt;&lt; &quot;:  &quot;;</span><br><span class="line">    for(int i : nums) cout &lt;&lt; i &lt;&lt; &quot; &quot;;</span><br><span class="line">    cout &lt;&lt; endl;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// 自底向上建堆</span><br><span class="line">void AdjustBottom2Up(vector&lt;int&gt;&amp; nums)&#123;</span><br><span class="line">    int len = nums.size();</span><br><span class="line"></span><br><span class="line">    for(int i=len-1; i&gt;0; i = (i-1)/2)&#123;</span><br><span class="line">        if(nums[i] &gt; nums[(i-1)/2])&#123;</span><br><span class="line">            swap(nums[i], nums[(i-1)/2]);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    return;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">/*</span><br><span class="line">    自顶向下调整时，注意要判断有单个结点或双个结点的情况</span><br><span class="line">*/</span><br><span class="line">void AdjustTop2Down(vector&lt;int&gt;&amp; nums, int i)&#123;</span><br><span class="line">    int len = nums.size()-1;</span><br><span class="line">    // show(nums, &quot;Adjust&quot;);</span><br><span class="line">    while(i&lt;=(len-1)/2)&#123;</span><br><span class="line">        int nextI = 2*i+1;</span><br><span class="line">        if(2*i+2 &lt;= len)&#123;</span><br><span class="line">            nextI = nums[2*i+1] &gt; nums[2*i+2] ? nextI : (2*i+2);</span><br><span class="line">        &#125;</span><br><span class="line">        if(nums[nextI] &gt; nums[i])&#123;</span><br><span class="line">            swap(nums[nextI], nums[i]);</span><br><span class="line">            i = nextI;</span><br><span class="line">        &#125;else&#123;</span><br><span class="line">            break;</span><br><span class="line">        &#125;</span><br><span class="line">        // show(nums, &quot;Adjust&quot;);</span><br><span class="line">    &#125;</span><br><span class="line">    return;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">void Insert(const int i, vector&lt;int&gt;&amp; nums)&#123;</span><br><span class="line">    nums.push_back(i);</span><br><span class="line">    show(nums, &quot;Before Insert&quot;);</span><br><span class="line">    AdjustBottom2Up(nums);</span><br><span class="line">    show(nums, &quot;After Insert&quot;);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">void Pop(vector&lt;int&gt;&amp; nums)&#123;</span><br><span class="line">    int len = nums.size();</span><br><span class="line">    // show(nums, &quot;Debug&quot;);</span><br><span class="line">    swap(nums[0], nums.back());</span><br><span class="line">    // show(nums, &quot;Debug&quot;);</span><br><span class="line">    nums.pop_back();</span><br><span class="line">    // show(nums, &quot;Debug&quot;);</span><br><span class="line">    AdjustTop2Down(nums, 0);</span><br><span class="line">    // show(nums, &quot;Debug&quot;);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">vector&lt;int&gt; BuildMaxHeapOut(const vector&lt;int&gt;&amp; nums)&#123;</span><br><span class="line">    int len = nums.size();</span><br><span class="line">    vector&lt;int&gt; res;</span><br><span class="line">    for(int i=0; i&lt;len; i++)&#123;</span><br><span class="line">        Insert(nums[i], res);</span><br><span class="line">    &#125;</span><br><span class="line">    return res;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">void BuildMaxHeapIn(vector&lt;int&gt;&amp; nums)&#123;</span><br><span class="line">    int len = nums.size();</span><br><span class="line"></span><br><span class="line">    for(int i=(len-1)/2; i&gt;=0; i--)&#123;</span><br><span class="line">        AdjustTop2Down(nums, i);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">int main()&#123;</span><br><span class="line">    vector&lt;int&gt; nums&#123;5,6,3,1,7,5,7,4,12,13,11,20,5,32,18,22&#125;;</span><br><span class="line"></span><br><span class="line">    // Out-Place 操作</span><br><span class="line">    show(nums,&quot;Before BuildMaxHeap&quot;);</span><br><span class="line">    auto res = BuildMaxHeapOut(nums);</span><br><span class="line">    show(res, &quot;After BuildMaxHeap&quot;);</span><br><span class="line">    </span><br><span class="line">    cout &lt;&lt; &quot;===================Insert==================\n&quot; &lt;&lt; endl;</span><br><span class="line">    show(res, &quot;Before Insert&quot;);</span><br><span class="line">    Insert(15, res);</span><br><span class="line">    show(res, &quot;After Insert&quot;);</span><br><span class="line"></span><br><span class="line">    show(res, &quot;Before Insert&quot;);</span><br><span class="line">    Insert(19, res);</span><br><span class="line">    show(res, &quot;After Insert&quot;);</span><br><span class="line"></span><br><span class="line">    cout &lt;&lt; &quot;===================Pop======================\n&quot; &lt;&lt; endl;</span><br><span class="line">    for(int i=0; i&lt;10; i++)&#123;</span><br><span class="line">        show(res, &quot;Before Pop&quot;);</span><br><span class="line">        Pop(res);</span><br><span class="line">        show(res, &quot;After Pop&quot;);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    cout &lt;&lt; endl;</span><br><span class="line">    cout &lt;&lt; &quot;In-Place Sort&quot; &lt;&lt; endl;</span><br><span class="line">    // In-Place 操作</span><br><span class="line">    show(nums,&quot;Before BuildMaxHeap&quot;);</span><br><span class="line">    BuildMaxHeapIn(nums);</span><br><span class="line">    show(nums, &quot;After BuildMaxHeap&quot;); // 32 22 20 12 13 5 18 4 6 7 11 5 5 7 3 1</span><br><span class="line"></span><br><span class="line">    cout &lt;&lt; &quot;===================Insert==================\n&quot; &lt;&lt; endl;</span><br><span class="line">    show(nums, &quot;Before Insert&quot;);</span><br><span class="line">    Insert(15, nums);</span><br><span class="line">    show(nums, &quot;After Insert&quot;);</span><br><span class="line"></span><br><span class="line">    show(nums, &quot;Before Insert&quot;);</span><br><span class="line">    Insert(19, nums);</span><br><span class="line">    show(nums, &quot;After Insert&quot;);</span><br><span class="line"></span><br><span class="line">    cout &lt;&lt; &quot;===================Pop======================\n&quot; &lt;&lt; endl;</span><br><span class="line">    for(int i=0; i&lt;10; i++)&#123;</span><br><span class="line">        show(nums, &quot;Before Pop&quot;);</span><br><span class="line">        Pop(nums);</span><br><span class="line">        show(nums, &quot;After Pop&quot;);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>堆可以看作是一个完全二叉数，为了方便比较，用数组方式存储。</p>
<p>堆的构建有两种，一个是<code>In-Place</code>的操作，就是不占用额外的空间；另外一种是将建堆看成是循环插入，是一中<code>Out-Place</code>的插入方式，每次插入最后一个位置。第一种方法需要从第$(n-1)&#x2F;2$个元素开始，遍历到第$0$个元素。在每次遍历的时候，都需要从当前位置，往下（TOP-Down）判断当前子堆是否合法。第二种方法就是往上（Bottom-Up）的方法，将新插入元素放在堆的最后一位上，然后跟父结点进行判断。</p>
<p>堆删除时，需要将第一个元素与最后一个元素进行交换，然后弹出最后一个元素。接着从第一个元素开始，自顶向下调整堆（这与第一种建堆的方式一致）。</p>
<h3 id="计数排序"><a href="#计数排序" class="headerlink" title="计数排序"></a>计数排序</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#include &lt;iostream&gt;</span><br><span class="line">#include &lt;vector&gt;</span><br><span class="line">#include &lt;algorithm&gt;</span><br><span class="line">using namespace std;</span><br><span class="line"> </span><br><span class="line">int main() &#123;</span><br><span class="line">    vector&lt;int&gt; nums&#123;1,6,4,2,7,8,4,2,6,10&#125;;</span><br><span class="line"></span><br><span class="line">    int maxE=nums[0], minE=nums[0];</span><br><span class="line">    for(int i=0; i&lt;nums.size(); i++)&#123;</span><br><span class="line">        maxE = max(nums[i], maxE);</span><br><span class="line">        minE = min(nums[i], minE);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    vector&lt;int&gt; cnt(maxE-minE+1,0);</span><br><span class="line"></span><br><span class="line">    for(int i : nums)&#123;</span><br><span class="line">        cnt[i-minE]++;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    for(int i=1; i&lt;cnt.size(); i++)&#123;</span><br><span class="line">        cnt[i] += cnt[i-1];</span><br><span class="line">    &#125;</span><br><span class="line">    vector&lt;int&gt; res(nums.size(), 0);</span><br><span class="line">    for(int i=nums.size()-1; i&gt;=0; i--)&#123;</span><br><span class="line">        res[--cnt[nums[i]-minE]] = nums[i];</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    for(int i : res) cout &lt;&lt; i &lt;&lt; &quot; &quot;;</span><br><span class="line"></span><br><span class="line">    return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>思想：如果比元素x小的元素个数有n个，则元素x排序后位置为n+1。</p>
<h3 id="希尔排序"><a href="#希尔排序" class="headerlink" title="希尔排序"></a>希尔排序</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#include&lt;iostream&gt;</span><br><span class="line">#include&lt;vector&gt;</span><br><span class="line">#include&lt;string&gt;</span><br><span class="line">using namespace std;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">void show(const vector&lt;int&gt;&amp; nums,const string&amp; describe)&#123;</span><br><span class="line">    cout &lt;&lt; describe &lt;&lt; &quot;:  &quot;;</span><br><span class="line">    for(int i : nums) cout &lt;&lt; i &lt;&lt; &quot; &quot;;</span><br><span class="line">    cout &lt;&lt; endl;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">void shellsort1(vector&lt;int&gt;&amp; a, int n)</span><br><span class="line">&#123;</span><br><span class="line">	int i, j, gap;</span><br><span class="line"> </span><br><span class="line">	for (gap = n / 2; gap &gt; 0; gap /= 2) //步长</span><br><span class="line">		for (i = 0; i &lt; gap; i++)        //直接插入排序</span><br><span class="line">		&#123;</span><br><span class="line">			for (j = i + gap; j &lt; n; j += gap) </span><br><span class="line">				if (a[j] &lt; a[j - gap])</span><br><span class="line">				&#123;</span><br><span class="line">					int temp = a[j];</span><br><span class="line">					int k = j - gap;</span><br><span class="line">					while (k &gt;= 0 &amp;&amp; a[k] &gt; temp)</span><br><span class="line">					&#123;</span><br><span class="line">						a[k + gap] = a[k];</span><br><span class="line">						k -= gap;</span><br><span class="line">					&#125;</span><br><span class="line">					a[k + gap] = temp;</span><br><span class="line">				&#125;</span><br><span class="line">		&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">int main()&#123;</span><br><span class="line">    vector&lt;int&gt; nums&#123;3,5,2,7,6,5,8,9,11,2,31,21,15,17,20&#125;;</span><br><span class="line">    int n = nums.size();</span><br><span class="line"></span><br><span class="line">    shellsort1(nums, n);</span><br><span class="line">    show(nums, &quot;After Shell Sort: &quot;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>希尔排序的实质就是<strong>分组插入排序</strong>，该方法又称缩小增量排序。</p>
<p>该方法的基本思想是：先将整个待排元素序列分割成若干个子序列（由相隔某个“增量”的元素组成的）分别进行直接插入排序，然后依次缩减增量再进行排序，待整个序列中的元素基本有序（增量足够小）时，再对全体元素进行一次直接插入排序。因为直接插入排序在元素基本有序的情况下（接近最好情况），效率是很高的，因此希尔排序在时间效率上比前两种方法有较大提高。</p>
<h3 id="基数排序"><a href="#基数排序" class="headerlink" title="基数排序"></a>基数排序</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">int maxbit(int data[], int n) //辅助函数，求数据的最大位数</span><br><span class="line">&#123;</span><br><span class="line">    int maxData = data[0];		///&lt; 最大数</span><br><span class="line">    /// 先求出最大数，再求其位数，这样有原先依次每个数判断其位数，稍微优化点。</span><br><span class="line">    for (int i = 1; i &lt; n; ++i)</span><br><span class="line">    &#123;</span><br><span class="line">        if (maxData &lt; data[i])</span><br><span class="line">            maxData = data[i];</span><br><span class="line">    &#125;</span><br><span class="line">    int d = 1;</span><br><span class="line">    int p = 10;</span><br><span class="line">    while (maxData &gt;= p)</span><br><span class="line">    &#123;</span><br><span class="line">        //p *= 10; // Maybe overflow</span><br><span class="line">        maxData /= 10;</span><br><span class="line">        ++d;</span><br><span class="line">    &#125;</span><br><span class="line">    return d;</span><br><span class="line">&#125;</span><br><span class="line">void radixsort(int data[], int n) //基数排序</span><br><span class="line">&#123;</span><br><span class="line">    int d = maxbit(data, n);</span><br><span class="line">    int *tmp = new int[n];</span><br><span class="line">    int *count = new int[10]; //计数器</span><br><span class="line">    int i, j, k;</span><br><span class="line">    int radix = 1;</span><br><span class="line">    for(i = 1; i &lt;= d; i++) //进行d次排序</span><br><span class="line">    &#123;</span><br><span class="line">        for(j = 0; j &lt; 10; j++)</span><br><span class="line">            count[j] = 0; //每次分配前清空计数器</span><br><span class="line">        for(j = 0; j &lt; n; j++)</span><br><span class="line">        &#123;</span><br><span class="line">            k = (data[j] / radix) % 10; //统计每个桶中的记录数</span><br><span class="line">            count[k]++;</span><br><span class="line">        &#125;</span><br><span class="line">        for(j = 1; j &lt; 10; j++)</span><br><span class="line">            count[j] = count[j - 1] + count[j]; //将tmp中的位置依次分配给每个桶</span><br><span class="line">        for(j = n - 1; j &gt;= 0; j--) //将所有桶中记录依次收集到tmp中</span><br><span class="line">        &#123;</span><br><span class="line">            k = (data[j] / radix) % 10;</span><br><span class="line">            tmp[count[k] - 1] = data[j];</span><br><span class="line">            count[k]--;</span><br><span class="line">        &#125;</span><br><span class="line">        for(j = 0; j &lt; n; j++) //将临时数组的内容复制到data中</span><br><span class="line">            data[j] = tmp[j];</span><br><span class="line">        radix = radix * 10;</span><br><span class="line">    &#125;</span><br><span class="line">    delete []tmp;</span><br><span class="line">    delete []count;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>基数排序时间复杂度为$O(nk)$,其中$n$为元素个数，$k$为元素的属性。如果是数字的话，就是数字的位数。</p>
]]></content>
      <categories>
        <category>数据结构与算法</category>
        <category>排序算法</category>
      </categories>
      <tags>
        <tag>冒泡</tag>
        <tag>插入</tag>
        <tag>归并</tag>
        <tag>快速</tag>
        <tag>桶排序</tag>
      </tags>
  </entry>
  <entry>
    <title>欧式空间的旋转表示(三)-旋转矩阵</title>
    <url>/2020/02/18/ca04af5a/</url>
    <content><![CDATA[<h3 id="什么是旋转矩阵"><a href="#什么是旋转矩阵" class="headerlink" title="什么是旋转矩阵"></a>什么是旋转矩阵</h3><p>旋转矩阵被用来在欧式空间进行旋转变换. 例如矩阵$R &#x3D; \begin{bmatrix} \cos{\theta} &amp; -\sin{\theta} \\ \sin{\theta} &amp; \cos{\theta}\end{bmatrix}$，就是将二维平面上的<strong>某点逆时针</strong>旋转$\theta$度。</p>
<p>如果将向量（为了方便计算，这里将点表示为向量）和坐标系两者分离开，向量是独立于坐标系存在的。我们就可以将选择单独看作是坐标系的旋转，而旋转矩阵$R&#x3D;[X_1, Y_1, Z_1]$中的<strong>每一列就表示原始坐标系的坐标轴在新坐标系下的投影长度</strong>。我们有两个坐标系$C_{new}$和$C_{old}$，且$X_{1} &#x3D; \begin{bmatrix} \cos{\theta} &amp; \sin{\theta} &amp; 0 \end{bmatrix}^{T}$，则如下图所示：</p>
<p><img src="/images/others/rotation/rota_demo1.png"></p>
<p>$X_{old}$在新坐标系下的投影分别是$X_{new}$：$\cos{\theta}$，$Y_{new}$：$\sin{\theta}$，$Z_{new}$：$0$，从而就得到了旋转矩阵的第一列$X_1$。其他列也是相同求解方法。</p>
<h4 id="旋转矩阵的特性"><a href="#旋转矩阵的特性" class="headerlink" title="旋转矩阵的特性"></a>旋转矩阵的特性</h4><p>根据<a href="https://en.wikipedia.org/wiki/Rotation_matrix">WiKi</a>上的定义:<strong>当且仅当方阵$R$满足$det(R)&#x3D;1$，且$R^{-1} &#x3D; R^{T}$，我们就称它为旋转矩阵。</strong> 而所有满足$det(R)&#x3D;1$的正交矩阵所组成的集合被称为特殊正交群$SO(n)$(Sepcial Orthogonal Group), 而旋转就是属于$SO(3)$。而所有满足$det(R) &#x3D; \pm1$的正交阵所形成的群被称为正交群$O(n)$</p>
<h5 id="为什么旋转矩阵的行列式值必须为1"><a href="#为什么旋转矩阵的行列式值必须为1" class="headerlink" title="为什么旋转矩阵的行列式值必须为1"></a>为什么旋转矩阵的行列式值必须为1</h5><p>旋转是一种线性变换，而<strong>行列式就是线性变换的尺度因子，它会改变被变换向量的模长</strong>。如前边所讲，旋转操作是对坐标系的旋转操作，<strong>旋转是不会改变独立于坐标系客观存在的向量</strong>，我们所看到的“变化”仅仅是向量在某个坐标系下的表征方式，也就是我们常说的<strong>坐标</strong>。如果旋转矩阵的$det(R) \neq 1$，由于坐标系的基依旧是为单位向量，使得目标向量的模长发生了改变，那么这个操作就不能被称为旋转操作。</p>
<h5 id="为什么旋转矩阵必须是正交矩阵"><a href="#为什么旋转矩阵必须是正交矩阵" class="headerlink" title="为什么旋转矩阵必须是正交矩阵"></a>为什么旋转矩阵必须是正交矩阵</h5><p>正交矩阵是行向量和列向量皆相互正交且为单位向量的方阵，满足$R^{-1} &#x3D; R^{T}$。前边踢到，可以将旋转矩阵的每一列看作是原始坐标系上的坐标轴向量在目标坐标系下的投影。但其实我们稍微观察一下就可以发现，旋转向量的每一列其实还等于新坐标系下的坐标轴（表示方法是通过旧坐标系作为参考坐标系）。那么正是这个要求，使得其列与行向量必须正交。</p>
<h3 id="旋转矩阵与其他旋转表征的转换"><a href="#旋转矩阵与其他旋转表征的转换" class="headerlink" title="旋转矩阵与其他旋转表征的转换"></a>旋转矩阵与其他旋转表征的转换</h3><p>由旋转轴$u &#x3D; \begin{bmatrix} u_x &amp; u_y &amp; u_z\end{bmatrix}$和旋转角度$\theta$可得绕任意旋转轴旋转任意角度的旋转矩阵为(具体推导过程可看:<a href="http://">欧式空间的旋转表示(一)-轴角式</a>:</p>
<p>$R &#x3D; \begin{bmatrix}<br>        \cos{\theta}+(1-\cos{\theta})u_x^2 &amp; (1-\cos{\theta})u_xu_y-\sin\theta u_z &amp; (1-\cos\theta)u_xu_z + \sin\theta u_y \\<br>        (1-\cos\theta)u_yu_x + \sin\theta u_z &amp; \cos\theta + (1-\cos\theta)u_y^2 &amp; (1-\cos\theta)u_yu_z - \sin\theta u_x \\<br>        (1-\cos\theta)u_zu_x - \sin\theta u_y &amp; (1-\cos\theta)u_zu_y + \sin\theta u_x &amp; \cos\theta + (1-\cos\theta)u_y^2<br>\end{bmatrix}$</p>
<h4 id="旋转矩阵到轴角式"><a href="#旋转矩阵到轴角式" class="headerlink" title="旋转矩阵到轴角式"></a>旋转矩阵到轴角式</h4><p>可以知道$tr(R) &#x3D; 3\cos\theta + (1-\cos\theta)(u_x^2 + u_y^2 + u_z^2)$，由于旋转轴的模长为1，我们可得$\theta &#x3D; \arccos{\frac{tr(R)-1}{2}}$。</p>
<p>观察旋转矩阵我们可以发现$\begin{bmatrix} R_{32} - R_{23} \\ R_{13} - R_{31} \\ R_{21} - R_{12}\end{bmatrix} &#x3D; \begin{bmatrix} 2u_x\sin\theta \\ 2u_y\sin\theta \\ 2u_z\sin\theta \end{bmatrix}$，将所得向量归一化后即为旋转轴。然后便可使用右手螺旋定则（大拇指指向正方法，其余四指为正向旋转方向）。</p>
<p>由于旋转轴在选择过程中保持不变，我们也可以通过$Ru &#x3D; R$来求解出旋转轴。</p>
<h4 id="旋转矩阵到四元数"><a href="#旋转矩阵到四元数" class="headerlink" title="旋转矩阵到四元数"></a>旋转矩阵到四元数</h4><p>四元数$q &#x3D; (w, x, y, z)$，其中$w &#x3D; \cos{\frac{\theta}{2}};[x,y,z]^T&#x3D;\sin{\frac{\theta}{2}}u^T$，u为旋转轴。根据上面的推导，我们可以知道$\cos\theta &#x3D; \frac{tr(R)-1}{2}$，而$\cos\theta &#x3D; 2\cos^2{\frac{\theta}{2}} - 1 &#x3D; 2w^2-1$。所以我们可以知道$tr(R) &#x3D; 4w^2 -1$。</p>
<p>而$(x,y,z)$也可用上面的公式得到$[x,y,z]^T &#x3D; \frac{1}{4\cos\frac{\theta}{2}}[R_{32}-R_{23},R_{13} - R_{31},R_{21} - R_{12}]^T$</p>
<h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><p><a href="https://zh.wikipedia.org/wiki/%E6%AD%A3%E4%BA%A4%E7%9F%A9%E9%98%B5">Wiki-正交矩阵</a></p>
<p><a href="https://zh.wikipedia.org/wiki/%E8%A1%8C%E5%88%97%E5%BC%8F">Wiki-行列式</a></p>
<p><a href="https://www.matongxue.com/madocs/247/">行列式本质</a></p>
]]></content>
      <categories>
        <category>三维基础</category>
        <category>旋转表征</category>
      </categories>
      <tags>
        <tag>旋转矩阵</tag>
      </tags>
  </entry>
  <entry>
    <title>欧式空间的旋转表示(二）-欧拉角</title>
    <url>/2020/02/17/36f31d81/</url>
    <content><![CDATA[<h3 id="什么是欧拉角"><a href="#什么是欧拉角" class="headerlink" title="什么是欧拉角"></a>什么是欧拉角</h3><p>欧拉角被用来描述一个物体绕某个坐标系旋转的角度，坐标系可以分解为三个相互正交的坐标轴构造。欧拉角的定义由三个部分组成：</p>
<ul>
<li><p><strong>顺规</strong>：欧拉角具有两大类的顺规表示方式：1）Proper Euler angles: (z-x-z, x-y-x, y-z-y, z-y-z, x-z-x, y-x-y); 2) Tait-Bryan angles：(x-y-z, y-z-x, z-x-y, x-z-y, <strong>z-y-x</strong>, y-x-z)。一般，我们也可以用yaw, pitch, roll来分别指代$z$轴，$y$轴, $x$轴的旋转。我们将其简称为$rpy$角</p>
</li>
<li><p><strong>旋转角度</strong>：常用$(\gamma ,\beta ,\alpha)$来描述绕三个坐标轴旋转的角度, 若以ZYX顺规来解释，既先绕$z$轴旋转$\gamma$度，再绕$y$轴旋转$\beta$度,最后绕$x$轴旋转$\alpha$度。</p>
</li>
<li><p><strong>内旋or外旋</strong>：根据每次旋转是绕<strong>旋转之后的轴</strong>旋转，还是<strong>固定轴</strong>旋转，我们将欧拉角分为<strong>内旋（intrisic roatation）</strong>和<strong>外旋(extrinsic rotation)<strong>。也有称内旋为动态旋转，绕物体坐标系旋转；将外旋称为静态旋转，绕世界坐标系旋转。</strong>事实上，如果将12种顺规中的一种的第一次旋转轴和第三次旋转轴互换顺序，那么可以使得外旋，内旋两者造成的姿态变化是等价的</strong>。比如外旋（<strong>z</strong>,y,<strong>x</strong>）就等价于内旋（<strong>x</strong>,y,<strong>z</strong>)，证明如下：</p>
</li>
</ul>
<p>根据题目可得如下定义：</p>
<p>$R_{外} &#x3D; R(Z)R(Y)R(X)$ 和 $R_{内} &#x3D; R(\alpha)R(\beta)R(\gamma)$。其中对于外旋来说，也是绕固定Z轴旋转$\gamma$度，绕固定Y轴旋转$\beta$度，绕固定X轴旋转$\alpha$度。</p>
<p>$R(\alpha) &#x3D; R(X)$这是显然的，而$R(\beta)$可以写为$R(\beta) &#x3D; R(\alpha)^{-1}R(Y)R(\alpha)$（可以用三支笔模拟一下）。同理我们可得$R(\gamma) &#x3D; (R(\alpha)R(\beta))^{-1}R(Z)(R(\alpha)R(\beta))$。由此：</p>
<p>$R_{外} &#x3D; R(\alpha)R(\beta)R(\gamma) \\<br>&#x3D; R(\alpha)R(\beta)*(R(\alpha)R(\beta))^{-1}R(Z)(R(\alpha)R(\beta)) \\<br>&#x3D; R(Z)(R(\alpha)R(\beta)) \\<br>&#x3D; R(Z)(R(\alpha)R(\alpha)^{-1}R(Y)R(\alpha)) \\<br>&#x3D; R(Z)R(Y)R(\alpha) \\<br>&#x3D; R(Z)R(Y)R(X)$</p>
<p>我们可以从以上三个方面确定一次用欧拉角定义的旋转，当任意一个因素发生改变时，都可能形成另一种不一样的旋转。</p>
<h3 id="什么是万向锁-Gimbal-Lock"><a href="#什么是万向锁-Gimbal-Lock" class="headerlink" title="什么是万向锁(Gimbal Lock)"></a>什么是万向锁(Gimbal Lock)</h3><p>假设我们的**顺规为zyx, 内旋，旋转角度为$(\gamma ,\beta ,\alpha)$**，当$\beta$为$\pm90$度时，就会产生万向锁。下面我们以内旋，顺规为(z,y,x)为例。</p>
<p><img src="/images/others/rotation/gimbal_lock.png" alt="gimbal lock示意图"></p>
<p>我们将起始地坐标轴定义为$(X_1, Y_1, Z_1)$首先我们绕$Z_1$轴旋转任意$\gamma$角，易得此时$X_1$轴和$Y_1$轴的方向已经发生了改变，记为$(X_2, Y_2, Z_1)$。我们再绕$Y_2$轴旋转90度，得到$(X_3, Y_2, Z_3)$。我们可以发现$X_3$轴与$Z_1$轴处以同一条水平线上。那么当我们按照<code>顺规</code>第三次绕$X_3$轴旋转时，<strong>本质上就是重复了第一次绕$Z_1$轴的旋转</strong>。此时就称发生了万向锁（Gimbal Lock)。</p>
<p>任何<code>顺规</code>都有可能发生万向锁，<strong>只要第二次旋转的角度为$\pm 90$度</strong>，就会发生万向锁。</p>
<iframe width="975" height="731" src="https://www.youtube.com/embed/zc8b2Jo7mno" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

<p>视频在2分56秒的地方介绍了万向锁的本质，<strong>其实就是objects没有安装期望的轨迹运动到规定的位置</strong>。而不是真正意义上的“锁”住某个维度。或者可以这样理解（不确定，没经过数学推导），我们已知任何选择都可以分解为三次基本旋转矩阵，当我们规定顺规为(z,y,x)时，若分解得y的旋转度数为90度时，我们<strong>预想</strong>的$X$轴的旋转度数$\alpha$就变得”无效”了，（X轴此时抑郁第一次旋转绕的Z轴重复）。解决方法就是使用其他的顺规，从而规避的第二次旋转度数为$\pm 90$度</p>
<h4 id="从矩阵角度看万向锁"><a href="#从矩阵角度看万向锁" class="headerlink" title="从矩阵角度看万向锁"></a>从矩阵角度看万向锁</h4><p>当我们以顺规(z,y,z)对物体进行旋转时，我们可以将三个基本旋转矩阵写成一个$R &#x3D; \begin{bmatrix} c_1c_2 &amp; c_1s_2s_3 - c_3s_1 &amp; s_1s_3 + c_1c_3s_2 \\ c_2s_1 &amp; c_1c_3 + s_1s_2s_3 &amp; c_3s_1s_2 - c_1s_3 \\ -s_2 &amp; c_2s_3 &amp; c_2c_3 \end{bmatrix} $</p>
<p>当第二次旋转角度为$\pm 90$度时，我们有$c2&#x3D;0$和$s2&#x3D;\pm 1$。于是矩阵就可以简化为$R &#x3D; \begin{bmatrix} 0 &amp; \pm c_1s_3 - c_3s_1 &amp; s_1s_3 \pm c_1c_3 \\ 0 &amp; c_1c_3 \pm s_1s_3 &amp; \pm c_3s_1 - c_1s_3 \\ \pm 1 &amp; 0 &amp; 0 \end{bmatrix} &#x3D; \begin{bmatrix} 0 &amp; -\sin(\alpha \pm \gamma) &amp; \cos(\alpha \pm \gamma) \\ 0 &amp; \cos(\alpha \pm \gamma) &amp; \sin(\alpha \pm \gamma) \\ \pm 1 &amp; 0 &amp; 0 \end{bmatrix} $</p>
<p>我们可以看出，当对$\alpha$进行选择操作时，就相当于在$\gamma$上施加了一个反方向的旋律，两者效果是等价的。这就是造成万向锁的原因，我们在三维空间中，只能进行两个维度的变化。</p>
<h3 id="欧拉角与其他旋转表征的转换"><a href="#欧拉角与其他旋转表征的转换" class="headerlink" title="欧拉角与其他旋转表征的转换"></a>欧拉角与其他旋转表征的转换</h3><h4 id="欧拉角与旋转矩阵"><a href="#欧拉角与旋转矩阵" class="headerlink" title="欧拉角与旋转矩阵"></a>欧拉角与旋转矩阵</h4><p>由上边的定义可以，欧拉角可以分解为三个基本旋转的复合变换。所谓基本旋转是指以$X$轴，$Y$轴，$Z$轴。采用<strong>右手法则</strong>，设$\theta$为转角，我们可得三个基本旋转矩阵为：</p>
<p>$R_{X}(\theta) &#x3D; \begin{bmatrix} 1 &amp; 0 &amp; 0 \\<br>                                 0 &amp; \cos{\theta} &amp; -\sin{\theta} \\<br>                                 0 &amp; \sin{\theta} &amp; \cos{\theta}<br>                \end{bmatrix}$</p>
<p>$R_{Y}(\theta) &#x3D; \begin{bmatrix} \cos{\theta} &amp; 0 &amp; \sin{\theta} \\<br>                                 0 &amp; 0 &amp; 0 \\<br>                                 -\sin{\theta} &amp; 0 &amp; \cos{\theta}<br>                \end{bmatrix}$</p>
<p>$R_{Z}(\theta) &#x3D; \begin{bmatrix} \cos{\theta} &amp; -\sin{\theta} &amp; 0 \\<br>                                 \sin{\theta} &amp; \cos{\theta} &amp; 0 \\<br>                                 0 &amp; 0 &amp; 1<br>                \end{bmatrix}$</p>
<p>若顺规为(z,y,x），则$R &#x3D; R_{Z}(\theta)R_{Y}(\theta)R_{X}(\theta)$。具体结果参照下图：</p>
<p><img src="/images/others/rotation/e2r.jpg"></p>
<h4 id="欧拉角与四元数"><a href="#欧拉角与四元数" class="headerlink" title="欧拉角与四元数"></a>欧拉角与四元数</h4><p>对于四元数$q &#x3D; (w,x,y,z) &#x3D; \cos{\theta} + \sin{\theta}x + \sin{\theta}y + \sin{\theta}z$。其中$\cos{\theta}$是表示旋转度数为$2\theta$，而$(x, y, z)$表明旋转轴。</p>
<p>而欧拉角转四元数就是，与欧拉角构造旋转矩阵一样，把三个基础旋转Elemental Rotation组合在一起。</p>
<p>$q(\gamma,\beta,\alpha) &#x3D; q_{z}(\gamma)q_{y}(\beta)q_{x}(\alpha) \\<br>                        &#x3D; \begin{bmatrix} \cos{\frac{\gamma}{2}} \\ 0 \\ 0 \\ \sin{\frac{\gamma}{2}} \end{bmatrix}<br>                        \begin{bmatrix} \cos{\frac{\beta}{2}} \\ 0 \\ \sin{\frac{\beta}{2}} \\ 0 \end{bmatrix}<br>                        \begin{bmatrix} \cos{\frac{\alpha}{2}} \\ \sin{\frac{\alpha}{2}} \\ 0 \\ 0 \end{bmatrix}				\\<br>                        &#x3D; \begin{bmatrix}<br>                        \cos{\frac{\gamma}{2}}\cos{\frac{\beta}{2}} \\ 						\sin{\frac{\gamma}{2}}\sin{\frac{\beta}{2}}  \\<br>                        \cos{\frac{\gamma}{2}}\sin{\frac{\beta}{2}} \\ 						\sin{\frac{\gamma}{2}}\cos{\frac{\beta}{2}}<br>                        \end{bmatrix}<br>                        \begin{bmatrix} \cos{\frac{\alpha}{2}} \\ \sin{\frac{\alpha}{2}} \\ 0 \\ 0 \end{bmatrix} \\<br>                        &#x3D; \begin{bmatrix}<br>                        \cos{\frac{\gamma}{2}}\cos{\frac{\beta}{2}}\cos{\frac{\alpha}{2}} - \sin{\frac{\gamma}{2}}\sin{\frac{\beta}{2}}\sin{\frac{\alpha}{2}} \\<br>                        \sin{\frac{\gamma}{2}}\sin{\frac{\beta}{2}}\cos{\frac{\alpha}{2}} + \cos{\frac{\gamma}{2}}\cos{\frac{\beta}{2}}\sin{\frac{\alpha}{2}} \\<br>                        \cos{\frac{\gamma}{2}}\sin{\frac{\beta}{2}}\cos{\frac{\alpha}{2}} - \sin{\frac{\gamma}{2}}\cos{\frac{\beta}{2}}\sin{\frac{\alpha}{2}} \\<br>                        \sin{\frac{\gamma}{2}}\cos{\frac{\beta}{2}}\cos{\frac{\alpha}{2}} - \cos{\frac{\gamma}{2}}\sin{\frac{\beta}{2}}\sin{\frac{\alpha}{2}}<br>                        \end{bmatrix}$</p>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><p><a href="https://blog.csdn.net/hy3316597/article/details/50966633">外旋内旋转化</a></p>
<p><a href="https://ccjou.wordpress.com/2014/04/29/%E4%B8%89%E7%B6%AD%E7%A9%BA%E9%96%93%E7%9A%84%E6%97%8B%E8%BD%89%E7%9F%A9%E9%99%A3/">三维空间的旋转矩阵</a></p>
<p><a href="https://en.wikipedia.org/wiki/Euler_angles">Euler_angles</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/45404840">三维旋转：欧拉角、四元数、旋转矩阵、轴角之间的转换</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/85108850">欧拉角细节&#x2F;旋转顺序&#x2F;内旋外旋</a></p>
<p><a href="https://blog.csdn.net/huazai434/article/details/6458257">游戏动画中欧拉角与万向锁的理解</a></p>
<p><a href="https://blog.csdn.net/HappyKocola/article/details/72788588">欧拉角万向节锁问题</a></p>
]]></content>
      <categories>
        <category>三维基础</category>
        <category>旋转表征</category>
      </categories>
      <tags>
        <tag>欧拉角</tag>
      </tags>
  </entry>
  <entry>
    <title>欧式空间的旋转表示(一)</title>
    <url>/2019/09/28/4767f891/</url>
    <content><![CDATA[<h2 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念##"></a>基本概念##</h2><h3 id="刚体变换"><a href="#刚体变换" class="headerlink" title="刚体变换###"></a>刚体变换###</h3><p>刚体变换也被称为欧氏变换，它在变化当中保持了向量的长度和相互之间的夹角大小，相当于我们把一个刚体原封不同的进行了移动或旋转，不改变它自身的样子。</p>
<h3 id="点与向量的关系"><a href="#点与向量的关系" class="headerlink" title="点与向量的关系###"></a>点与向量的关系###</h3><p>点和向量两者并不是等价的关系。向量$\overrightarrow{a}$是一个空间上的抽象概念，只有当我们将其与某个坐标系联系起来的时候，它就具象化为了坐标点。<br>$\begin{align}\overrightarrow{a} &#x3D;<br>\begin{bmatrix} e_1&amp;e_2&amp;e_3 \end{bmatrix} \begin{bmatrix}a_1\\a_2\\a_3\end{bmatrix}<br>&#x3D; a_1e_1 + a_2e_2 + a_3e_3 \end{align}$</p>
<p>这里$e_i$为列向量，代表了空间当中坐标系的一组基。</p>
<h3 id="内积和外积"><a href="#内积和外积" class="headerlink" title="内积和外积###"></a>内积和外积###</h3><ul>
<li>内积</li>
</ul>
<p>$$\begin{align}a \cdot b &#x3D; a^Tb &#x3D; \sum_{i&#x3D;1}^{3}a_ib_i &#x3D; |a||b|\cos&lt;a,b&gt; \end{align}$$</p>
<ul>
<li>外积</li>
</ul>
<p>$\begin{align}a \times b &#x3D; \begin{bmatrix} i&amp;j&amp;k\\a_1&amp;a_2&amp;a_3\\b_1&amp;b_2&amp;b_3 \end{bmatrix} &#x3D; \begin{bmatrix} a_2b_3 - a_3b_2\\a_3b_1 - a_1b_3\\a_1b_2 - a_2b_1\end{bmatrix} &#x3D; \begin{bmatrix} 0&amp;-a_3&amp;a_2\\a_3&amp;0&amp;-a_1\\-a_2&amp;-a_1&amp;0 \end{bmatrix}b \triangleq a^ b \end{align}$</p>
<p>这里将$\overrightarrow{a}^$记为将向量$\overrightarrow a$变为反对称。外积的大小为$|a||b|\sin&lt;a,b&gt;$,是两个向量张成的四边形的有向面积。</p>
<h2 id="欧拉角和旋转向量"><a href="#欧拉角和旋转向量" class="headerlink" title="欧拉角和旋转向量"></a>欧拉角和旋转向量</h2><p>假设我们有一个经过原点的旋转轴$\overrightarrow{u} &#x3D; (x,y,z)^T$,我们希望将一个向量$\overrightarrow{v}$，以$\overrightarrow u$为旋转轴，旋转$\theta$度之后，变换到$\overrightarrow{v \prime }$</p>
<p><img src="/images/others/rotation/axis_angle.jpg"></p>
<p>这时，我们就可以用一个<strong>旋转向量$\overrightarrow u$和角度$\theta$来表示一次旋转</strong>。由于以这种方式表示旋转需要四个自由度(向量三个，角度一个)，而刻画一次选择只需要三个自由度（x,y,z)这就导致了冗余。所以，我们额外规定向量的模长为一，$|\overrightarrow u| &#x3D; \sqrt{x^2 + y^2 + z^2} &#x3D;1$。</p>
<p>欧拉角其实与旋转向量十分类似，但是却更加符合人们思考旋转的方式。欧拉角使用三个分离的转角，把一个旋转分解为三次绕不同轴的旋转。分解方式可以是多种多样的，但通常是分解为X轴，Y轴，Z轴。</p>
<ul>
<li>绕物体Z轴旋转，得到偏航角<code>yaw</code></li>
<li>绕<strong>旋转之后</strong>的Y轴旋转，得到俯仰角<code>pitch</code></li>
<li>绕<strong>旋转之后</strong>的X轴旋转，得到滚转角<code>roll</code></li>
</ul>
<p>那么一个三维向量[90,-60,80]，就可以定义一次旋转了。但是使用欧拉角会出现万向锁（Gimbal Lock）的错误: 在俯仰角为$±90^°$的时候，第一次旋转与第三次旋转将会使用同一个轴，这使得系统丢失了一个自由度。</p>
<p><img src="/%5Cimages%5Cothers%5Crotation%5Cgimbal_lock.jpg"></p>
<h2 id="旋转矩阵"><a href="#旋转矩阵" class="headerlink" title="旋转矩阵##"></a>旋转矩阵##</h2><p>在<code>基本概念</code>中提到，向量在刚体变化中的长度和相对夹角是不变的，利用这种不变性，我们可以得到：</p>
<p>$\begin{align}\begin{bmatrix}e_1&amp;e_2&amp;e_3\end{bmatrix}\begin{bmatrix}x_1\\y_1\\z_1\end{bmatrix} &amp; &#x3D; \begin{bmatrix}e_1^{‘}&amp;e_2^{&#96;}&amp;e_3^{‘}\end{bmatrix}\begin{bmatrix}x_2\\y_2\\z_2\end{bmatrix}  \\<br>\begin{bmatrix}x_1\\y_1\\z_1\end{bmatrix}<br>&amp; &#x3D; \underbrace{\begin{bmatrix}e_1^Te_1^{‘}&amp;e_1^Te_2^{‘}&amp;e_1^Te_3^{‘} \\ e_2^Te_1^{‘}&amp;e_2^Te_2^{‘}&amp;e_2^Te_3^{‘} \\<br>e_3^Te_1^{‘}&amp;e_3^Te_2^{‘}&amp;e_3^Te_3^{‘}\end{bmatrix}}_{R} \begin{bmatrix}x_2\\y_2\\z_2\end{bmatrix}<br>\end{align} $</p>
<p>我们将中间这个矩阵称为<code>旋转矩阵R</code>,它具有如下性质：<br>$\begin{align} SO(n) &#x3D; \lbrace R \in \mathbb R^{n \times n} | RR^T &#x3D; I, det(R) &#x3D; 1 \rbrace \end{align} $</p>
<p>不管多少维的旋转矩阵，它都必须是正交矩阵，且满足公式6。同时满足$tr(R) &#x3D; 2\cos\theta + 1$,$\theta$为旋转的角度。而旋转矩阵的特征值为$\lbrace e^{i\theta},e^{-i\theta},1\rbrace$。 可以根据$R\overrightarrow{n} &#x3D; R$求解出旋转轴向量。</p>
<h2 id="四元数"><a href="#四元数" class="headerlink" title="四元数##"></a>四元数##</h2><h3 id="复数基础"><a href="#复数基础" class="headerlink" title="复数基础"></a>复数基础</h3><p>如果有两个复数$z_1 &#x3D; a + bi,z_2 &#x3D; c +di$,由分配率我们可得</p>
<p>$\begin{align}<br>z_1z_2 &amp;&#x3D; ac+adi+bci+bdi^2 \\<br>        &amp;&#x3D; ac-bd+(bc+ad)i \\<br>        &amp;&#x3D; \begin{bmatrix}a&amp;-b\\b&amp;a \end{bmatrix}\begin{bmatrix}c\\d \end{bmatrix}<br>\end{align}$</p>
<p>我们可以将$\begin{bmatrix}a&amp;-b\\b&amp;a \end{bmatrix}$ 看成一个二维旋转矩阵，将复平面上的向量$(c,d)$变换到$(ac-bd,bc+ad)$上。具体来说：</p>
<p>$\begin{align}<br>\begin{bmatrix}a&amp;-b\\b&amp;a \end{bmatrix} &amp;&#x3D; \sqrt{a^2 + b^2}\begin{bmatrix}\frac{a}{\sqrt{a^2 + b^2}}&amp;\frac{-b}{\sqrt{a^2 + b^2}}\\\frac{b}{\sqrt{a^2 + b^2}}&amp;\frac{a}{\sqrt{a^2 + b^2}} \end{bmatrix} \\<br>    &amp;&#x3D;\sqrt{a^2 + b^2} \begin{bmatrix}\cos(\theta)&amp;-\sin(\theta)\\\sin(\theta&amp;\cos(\theta) \end{bmatrix}<br>\end{align}$</p>
<p>根据欧拉公式，我们可以进一步将二维旋转坐标写成极坐标的形式：</p>
<p>$\begin{align}<br>\begin{bmatrix}\cos(\theta)&amp;-\sin(\theta)\\\sin(\theta&amp;\cos(\theta) \end{bmatrix}  &#x3D; \cos(\theta) + i\sin(\theta) &#x3D; e^{i\theta}<br>\end{align}$</p>
<p><strong>注意这里的$\theta$是逆时针方向,同时多个二维旋转操作可以叠加，即若干个二维旋转矩阵相乘仍是一个旋转矩阵，而且与施加的次序无关。角度为多个旋转角之和</strong></p>
<h3 id="四元数定义与操作"><a href="#四元数定义与操作" class="headerlink" title="四元数定义与操作###"></a>四元数定义与操作###</h3><p>所有四元数$q \in \mathbb H$都可以写成如下形式：<br>$\begin{align} q &#x3D; a + bi +cj +dk&amp;(a,b,c,d \in \mathbb R)\end{align}$</p>
<p>其中：</p>
<p>$\begin{align}i^2&#x3D;j^2&#x3D;k^2&#x3D;ijk&#x3D;-1\end{align}$</p>
<p>通常可以简化表示为有序对形式：</p>
<p>$\begin{align}q&#x3D;[s,\bf{v}]&amp;&amp;(\bf{v}&#x3D;\begin{bmatrix}x\\y\\z\end{bmatrix},s,x,y,z \in \mathbb R) \end{align}$</p>
<p>如果一个四元数的$s&#x3D;&#x3D;0$,即$q_0&#x3D;[0,{\bf{v}}]$。那么我们就称$q_0$为纯四元数。两个纯四元数相乘:<br>$\begin{align}vu &#x3D; [\bf -v \cdot u,v \times u]\end{align}$</p>
<p>四元数的加减法与复数保持一致，乘法可以总结为下表：</p>
<p><img src="/images/others/rotation/quat_mul.jpg"></p>
<p>与复数一致，四元数的乘法也能写成矩阵乘向量的形式：</p>
<p>$\begin{align}q_1q_2 &amp;&#x3D; \begin{bmatrix}<br>a&amp;-b&amp;-c&amp;-d\\<br>b&amp;a&amp;d&amp;-c\\<br>c&amp;-d&amp;a&amp;b\\<br>d&amp;c&amp;-b&amp;a<br>\end{bmatrix}<br>\begin{bmatrix}<br>e\\f\\g\\h<br>\end{bmatrix}\\<br>&amp;&#x3D;(ae-(bf+cg+dh))+ \\<br>&amp;(be+af+ch-dg)i+ \\<br>&amp;(ce+ag+df-bh)j+ \\<br>&amp;(de+ah+bg-cf)k \\<br>&amp;&#x3D;[ae-{\bf{u}} \cdot {\bf{v}}, a {\bf{u}}+e {\bf{v}}+{\bf{v}} \times \bf{u}]<br>\end{align}<br>$</p>
<p>其中：${\bf{v}} &#x3D; \begin{bmatrix}b\\c\\d\end{bmatrix},{\bf{u}} &#x3D; \begin{bmatrix}f\\g\\h\end{bmatrix}$</p>
<p><strong>注意四元数并不满足交换律，即$q_1q_2 \neq q_2q_1$。这点与复数不一样。</strong></p>
<h3 id="四元数的逆和共轭"><a href="#四元数的逆和共轭" class="headerlink" title="四元数的逆和共轭"></a>四元数的逆和共轭</h3><p>四元数共轭：$q^* &#x3D; (s,-{\bf{v}})$</p>
<p>四元数的逆：$q^{-1} &#x3D; \frac{q^*}{||q||^2}$</p>
<p>四元数的逆和共轭都满足交换律 : $q^*q &#x3D; qq^*&#x3D;||q||^2\quad;\quad q^{-1} &#x3D;q^{-1}q&#x3D;1$ </p>
<p>单位四元数满足 : $q^{-1} &#x3D; \frac{q^*}{||q||^2} &#x3D; q^{*}$</p>
<h3 id="四元数型3D旋转"><a href="#四元数型3D旋转" class="headerlink" title="四元数型3D旋转"></a>四元数型3D旋转</h3><p>任意向量$\bf v$沿着以单位向量定义的旋转轴$\bf u$旋转$\theta$度之后的$\bf v’$可以使用四元数乘法获得.用纯四元数$v &#x3D; [0,{\bf v}]$表示三维空间中一个点,$\quad q &#x3D; [\cos(\frac{1}{2}\theta),\sin(\frac{1}{2}\theta{\bf u})]$表示一次选择，那么：</p>
<p>$\begin{align}v’ &#x3D; qvq^* &#x3D; qvq^{-1}\end{align}$</p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料##"></a>参考资料##</h2><ol>
<li><a href="http://www.baidu.com/s?wd=%E8%A7%86%E8%A7%89slam%E5%8D%81%E5%9B%9B%E8%AE%B2&rsv_spt=1&rsv_iqid=0xba8a1b9c000a4e61&issp=1&f=3&rsv_bp=1&rsv_idx=2&ie=utf-8&tn=baiduhome_pg&rsv_enter=1&rsv_dl=ts_0&rsv_sug3=24&rsv_sug1=3&rsv_sug7=101&rsv_t=dab2/GnTtkD786FniyQVwjpH8Cs9UrV9x4FkWg1sHBeH1ZAwrkxldkoUbepsePGrchbe&rsv_sug2=1&prefixsug=%25E8%25A7%2586%25E8%25A7%2589SLAM&rsp=0&inputT=10337&rsv_sug4=11386">视觉SLAM十四讲</a></li>
<li><a href="http://www.euclideanspace.com/">euclideanspace</a></li>
<li><a href="https://github.com/Krasjet/quaternion">quaternion</a></li>
</ol>
]]></content>
      <categories>
        <category>三维基础</category>
        <category>旋转表征</category>
      </categories>
      <tags>
        <tag>旋转矩阵</tag>
        <tag>欧拉角</tag>
        <tag>四元数</tag>
        <tag>轴角</tag>
      </tags>
  </entry>
  <entry>
    <title>薄板样条插值</title>
    <url>/2019/11/06/d3c15ac3/</url>
    <content><![CDATA[<h3 id="Thin-Plate"><a href="#Thin-Plate" class="headerlink" title="Thin Plate"></a>Thin Plate</h3><p>薄板样条插值可以为一组对应的控制点提供<strong>光滑</strong>的插值结果，通过一组控制点，可以得到一个“平面”（不一定是二维平面），穿过这组控制点，并使得“平面”的弯曲能量（bending energy)最小。</p>
<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" 
    src="\images\others\tps\thinplates.png">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">穿过一组特征点的2D平面</div>
</center>

<p>图示的弯曲屏幕可以通过如下公式得到：</p>
<p>$f(x_i,y_i) &#x3D; a_1 + a_2x_i + a_3y_i + \sum \limits_{j&#x3D;1} \limits^{n}w_iU(|p_i - p_j|) \tag{1}$</p>
<p>前三个参数$a_1, a_2, a_3$可以看作是<code>仿射变换</code>, 第四个变换参数是关于使得“平面”弯曲以通过给定控制点。$U(r) &#x3D; r^2\log r$是径向基函数。$|p_i - p_j|$中的$p_i$和$p_j$都是控制点坐标，（1）总共有$N$个弯曲参数$w_i$和$1+D$个仿射参数，其中$D$为控制点的维度。</p>
<p>我们可以化简公式（1）为：$f(x_i, y_i) &#x3D; L_i(W_i|a_{1,i}a_{2,i}a_{3,i})^T $, 其中$L &#x3D; [U(|p_i - p_1|), U(|p_i - p_2], \ldots , U(|p_i - pj|), U(|p_i - p_n), p_i, 1 n]$。我们接着定义$P &#x3D; \begin{bmatrix} 1 &amp; x_1 &amp; y_1 \\ 1 &amp; x_2 &amp; y_2 \\ 1 &amp; x_3 &amp; y_3 \\ &amp; \cdots  &amp;\\ 1 &amp; x_n &amp; y_n \end{bmatrix}$, $K &#x3D; \begin{bmatrix} U(r_{11}) &amp; U(r_{12}) &amp; \cdots &amp; U(r_{1n}) \\ U(r_{21}) &amp; U(r_{22}) &amp; \cdots &amp; U(r_{2n}) \\ \vdots &amp; \vdots &amp; \vdots &amp; \vdots \\ U(r_{n1}) &amp; U(r_{n2}) &amp; \cdots &amp; U(r_{nn})\end{bmatrix}$。其中$(x1, y1)$表示控制点的坐标（以二维为例），$r_{1n} &#x3D; |p_i - p_n|$。我们可以将$P$和$K$组合得到:$L &#x3D; \begin{bmatrix} K &amp; P \\ P^T &amp; 0\end{bmatrix}$。这时，从公式（2）就可以推广到$N$个控制点的情形：</p>
<p>$V &#x3D; L [W|a_1a_2a_3]^T \tag{3}$</p>
<p>其中$L \in \mathbb R^{(n+3) \times (n+3)}$, $W \in \mathbb R^{n \times 1}$, $K \in \mathbb R^{n \times n}$, $P \in \mathbb R^{n \times 3}$, $a_i \in \mathbb R$， $V &#x3D; [v_1, v_2, \ldots, v_n, 0, 0, 0]^T$, <strong>$v_i &#x3D; f(x_i, y_i)$表示在控制点$(x_i, y_i)$的“高度”</strong>。</p>
<h3 id="Deformation"><a href="#Deformation" class="headerlink" title="Deformation"></a>Deformation</h3><h4 id="How-to-calculate-the-TPS-parameters"><a href="#How-to-calculate-the-TPS-parameters" class="headerlink" title="How to calculate the TPS parameters"></a>How to calculate the TPS parameters</h4><p>由于L是一个对称矩阵，$[W|a_1a_2a_3]^T &#x3D; VL^{-1}$，我们可以得到<strong>一组控制点关于某个维度的TPS参数（如上图所示，我们有7个控制点，每个控制点$f(x_i, y_i)$都有其“高度”，我们便可通过TPS拟合出一个平面，通过这些高度值）。</strong>但如果是Deformaition的话（假设我们将<strong>img1</strong>“扭曲”得到<strong>img2</strong>），我们已知的是一组控制点的对应关系，即$(x_{1,1}, y_{1,1})$与$(x_{2,1}, y_{2,1})$是对应的，我们便需要两组TPS参数来将图片“扭曲”。</p>
<p>$[X_2, Y_2] &#x3D; L\begin{bmatrix} W_x &amp; W_y \\ a_{1,x} &amp; a_{1,y} \\ a_{2,x} &amp; a_{2,y} \\ a_{3,x} &amp; a_{3,y}\end{bmatrix}$</p>
<figure class="half">
    <img src="\images\others\tps\herve.png" width="250">
    <img src="\images\others\tps\herve-smile.png" width="250">
    <br>
    <center>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">左图是原图，右图是扭曲之后的图片</div>
    </center>
</figure>


<figure class="half">
    <img src="\images\others\tps\thinplates-dx.png" width="300">
    <img src="\images\others\tps\thinplates-dy.png" width="300">
    <br>
    <center>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">左图是表示x方向的形变，右图表示y方向形变（与上图对应）</div>
    </center>
</figure>

<p>以嘴角为例，可以看到x方向上的“高度”为0，而y方向上的“高度”却有很大的值。</p>
<h4 id="How-to-conduct-image-warping"><a href="#How-to-conduct-image-warping" class="headerlink" title="How to conduct image warping"></a>How to conduct image warping</h4><p>现假设我们已经求得了一组图片之间的TPS参数$c_x \in \mathbb R^{(N+3) \times 1}, c_y \in \mathbb R^{(N+3) \times 1}$分别代表x方向和y方向。我们可以根据下面这个公式求得“扭曲”之后的点的位置（其实就是公式（1））。</p>
<p>$\begin{bmatrix} x’ &amp; y’\end{bmatrix} &#x3D; \begin{bmatrix} U(||(x_{i,1}, y_{i,1}) - (x_{t,m}, y_{t, n})||_2) &amp; P\end{bmatrix}^T[c_x, c_y] \tag{4}$</p>
<p>其中，$(x_{i,1}, y_{i,1})， i \in [1 \ldots N] $表示上面提到的img1中的控制点，而$(x_{t,m}, y_{t, n})$表示<strong>任意一组待扭曲的图片初始像素坐标，我们这里记为img3</strong>。而$||(x_{i,1}, y_{i,1}) - (x_{t,m}, y_{t, n})||_2$则表示两个点之间的欧式距离。如果img3有M个点，则$||*||_2$得到的值其维度是$N \times M$。那么就可以得到扭曲后的坐标：$\begin{bmatrix} x’ &amp; y’\end{bmatrix} \in \mathbb R^{M \times 2}$。代码如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">% MATLAB</span><br><span class="line">[N1,N2]=size(img3); % 获取img3的高，宽</span><br><span class="line">[x,y]=meshgrid(1:N2,1:N1); % 由于初始图像未扭曲，其做为整数，可以这样获取</span><br><span class="line">x=x(:);y=y(:);M=length(x);</span><br><span class="line">% cx: 为x方向形变参数，其维度与img1中控制点个数有关，这里就是n_good+3,n_good就是控制点个数</span><br><span class="line">fx_aff=cx(n_good+1:n_good+3)&#x27;*[ones(1,M); x&#x27;; y&#x27;]; %公式（1）前三个项的实现</span><br><span class="line">d2=dist2(X3b,[x y]); %X3b: (n_good * 2)  d2: (n_good * N)</span><br><span class="line">fx_wrp=cx(1:n_good)&#x27;*(d2.*log(d2+eps)); %fx_wrp: (1 * N)</span><br><span class="line">fx=fx_aff+fx_wrp;</span><br><span class="line">fy_aff=cy(n_good+1:n_good+3)&#x27;*[ones(1,M); x&#x27;; y&#x27;];</span><br><span class="line">fy_wrp=cy(1:n_good)&#x27;*(d2.*log(d2+eps));</span><br><span class="line">fy=fy_aff+fy_wrp;</span><br><span class="line"></span><br><span class="line">%%</span><br><span class="line">%% 接下来就是根据扭曲后的坐标【fx, fy】进行插值</span><br><span class="line">%%</span><br></pre></td></tr></table></figure>
<h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><p><a href="https://profs.etsmtl.ca/hlombaert/thinplates/">Manual Registration with Thin Plates</a></p>
]]></content>
      <categories>
        <category>图形学基础</category>
      </categories>
      <tags>
        <tag>薄板样条插值</tag>
      </tags>
  </entry>
  <entry>
    <title>&lt;论文阅读&gt;(一)Learning Category-Specific Mesh Reconstruction From Image Collections</title>
    <url>/2019/03/08/ed6ad9d5/</url>
    <content><![CDATA[<h2 id="Learning-Category-Specific-Mesh-Reconstruction-from-Image-Collections"><a href="#Learning-Category-Specific-Mesh-Reconstruction-from-Image-Collections" class="headerlink" title="&lt;论文阅读&gt;Learning Category-Specific Mesh Reconstruction from Image Collections"></a>&lt;论文阅读&gt;Learning Category-Specific Mesh Reconstruction from Image Collections</h2><p><a href="https://arxiv.org/abs/1803.07549" title="Learning Category-Specific Mesh Reconstruction"><strong>论文链接</strong></a></p>
<p><a href="https://github.com/akanazawa/cmr"><strong>Github链接</strong></a></p>
<h3 id="Contribution"><a href="#Contribution" class="headerlink" title="Contribution"></a>Contribution</h3><ul>
<li>单图重建</li>
<li>纹理渲染</li>
<li>训练过程无需3d ground truth数据</li>
</ul>
<h3 id="Method"><a href="#Method" class="headerlink" title="Method"></a>Method</h3><h4 id="训练数据预处理"><a href="#训练数据预处理" class="headerlink" title="训练数据预处理"></a>训练数据预处理</h4><p>本次实验用到的数据集是<code>CUB-200-2011</code>,提供了200种鸟类，共计11788张图片。每张图片附含了15个关键点的标记（头部，背部，脚等）、一张Mask和Bounding box。<br>作者首先将这些数据导入Matlab当中，首先对每组关键点进行零均值处理，接着计算平均模型$\hat{S}$。 接着利用所有关键点进行<code>structure from motion</code>变换，得到每张图片相对于平均模型$\hat{S}$的<code>rot</code>,<code>Translation</code>和<code>Scale</code>三个参数。</p>
<h4 id="网络训练"><a href="#网络训练" class="headerlink" title="网络训练"></a>网络训练</h4><p>作者用到了三个网络来达到重建效果，分别是<code>文中所用主体网络</code>,<a href="https://arxiv.org/abs/1711.07566"><strong>Neural Mesh Render</strong></a><br>和<a href="https://arxiv.org/abs/1801.03924"><strong>Perceptual loss</strong></a>。</p>
<ul>
<li>论文中所用网络简介</li>
</ul>
<p><img src="/images/paper/bird_net/Net_Arch.jpg"></p>
<p>首先网络接受一张图片，经过encoder之后变为了一个200d的shape feature <code>f</code>（注：encoder是一个经过imagenet预训练的resnet-18接上两个全连接层）。之后将得到的<code>f</code>送入三个网络,分别是<code>ShapePredictor</code>,<code>CameraPredictor</code>和<code>UVMapPredictor</code>. 其中<code>ShapePredictor</code>是预测形状变化$\Delta{V}$,最后的形状预测结果就是$V &#x3D; \hat{V} + \Delta{V}$。<code>CameraPredictor</code>是预测<code>rot</code>,<code>Translation</code>和<code>Scale</code>三个参数的。值得一提的是<code>rot</code>参数,它与以前见到的旋转矩阵不同，<code>rot</code>$\in \mathbb{R}^4$,是一个<a href="https://zh.wikipedia.org/wiki/%E5%9B%9B%E5%85%83%E6%95%B0%E4%B8%8E%E7%A9%BA%E9%97%B4%E6%97%8B%E8%BD%AC"><strong>四元数</strong></a>,可以用来表示三维空间中点的旋转。</p>
<ul>
<li>TexturePredictor</li>
</ul>
<p>作者提出的纹理预测思路比较巧妙。首先在数据预处理过程中的$\hat{S}$与网络训练过程的$\hat{V}$并不一致，实际上$\hat{V} &#x3D;\mathcal{P}(\hat{S})$，$\mathcal{P}$表示将一个点数为642，面片数为1280的二十面体投影至$\hat{S}$。在将二十面体投影至$\hat{S}$前，作者对二十面体的点，面做了一次<em><strong>重新排序</strong></em>，使他们的顺序按照独立点，左侧点，右侧点排列。而投影操作$\mathcal{P}$作者在代码注释中写了这么一句话：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">triangle_direction_intersection</span>(<span class="params">tri, trg</span>):</span><br><span class="line">    Finds where an origin-centered ray going <span class="keyword">in</span> direction trg intersects a triangle.</span><br><span class="line">    Args:</span><br><span class="line">        tri: <span class="number">3</span> X <span class="number">3</span> vertex locations. tri[<span class="number">0</span>, :] <span class="keyword">is</span> 0th vertex.</span><br></pre></td></tr></table></figure>
<p><img src="/images/paper/bird_net/project.png"></p>
<p>多边形相当于二十面体，而中间的三角形就相当于$\hat{S}$,其边就可以看作三角面片。投影操作就是求解沿着二十面体点的方法，求与三角片面的交点。</p>
<p>有了上面的基础，作者就认为由于所有的预测3D模型都是从同一个平均模型在保持拓扑变化的基础上变化得到的原因，所以每个所预测3D模型的点语义都是一致，即编号为1的点若代表嘴巴，则所有预测模型中编号为1的点就是所预测的嘴巴那个点。那么对于所预测的纹理图片来说，只要知道了最原始的那个二十面体的UV图，便可以对预测3D模型进行渲染(rendering)。</p>
<p><img src="/images/paper/bird_net/rendering.png"></p>
<ul>
<li>Loss函数介绍</li>
</ul>
<p>** 注1：$\mathcal{R}$（<em>）和$G$（</em>）分别表示渲染(rendering)和双线性取样(bilinear sampling),其中$\mathcal{R}$（<em>）引用自</em>*<a href="https://arxiv.org/abs/1711.07566">Hiroharu Kato, etc. Neural 3D Mesh Renderer</a></p>
<p>** 注2：$L_{texture}$函数表示的percetual loss,较传统的pixel loss相比更能从人的感知角度来评价两幅图像的相似度 引用自**<a href="https://arxiv.org/abs/1801.03924">Zhang,R etc. The unreasonable effectiveness of deep networks as a perceptual metric. In CVPR 2018</a></p>
<p>$L_1 &#x3D; L_{reproj} + L_{mask} + L_{cam} + L_{smooth} + L_{def} + L_{vert2kp}$</p>
<p>$L_{reproj} &#x3D; \sum_{i}^{}||x_{i}-\tilde{\pi}_{i}(AV_{i})||_{2}$，其中 $\tilde{\pi}（*）$表示投影操作，其值是从<code>structure-from-motion</code>中获得参数</p>
<p>$L_{mask} &#x3D; \sum_i||S_{i}-\mathcal{R}(V_{i},F,\tilde{\pi}_{i})||_{2}$，$S_{i}$表示ground-truth的Mask。</p>
<p>$L_{cam} &#x3D; \sum_{i}||\tilde{\pi}_{i}-{\pi}_{i}||_{2}$，$\pi_{i}$表示估计的相机旋转参数，由于旋转参数是由四元数表示，那么就是利用hamilton_product来求解估计与实际的误差</p>
<p>$L_{smooth} &#x3D; ||LV||_{2}$，$L$表示Laplacian光滑，其目的是为了最小化平均曲率</p>
<p>$L_{def}&#x3D;||\Delta{V}||_{2}$，这个是一个正则项</p>
<p>$L_{vert2kp} &#x3D; \frac{1}{|K|}\sum_{k}\sum_{v}-A_{k,v}logA_{k,v}$，这个是一个k*V的矩阵，每一行表示一个特征点，而每一列表示这个特征点在各个点的概率分布。初始化是，每个特征点在各个点上的概率分布是一致的，进过迭代之后，作者期望形成一个类似与one-hot的矩阵。</p>
<p>$L_2 &#x3D; L_{texture} + L_{dt}$</p>
<p>$L_{texture} &#x3D; \sum_{i}dist(\mathcal{S_{i}}\bigodot\mathcal{I_{i}},\mathcal{S_{i}}\bigodot\mathcal{R}(V_{i},F,\tilde{\pi_{i}},I^{uv}))$</p>
<p>$L_{dt} &#x3D; \sum_{i}\sum_{u,v}G(\mathcal{D_{S_{i}};F_{i}}(u,v)$， $\mathcal{D_{S_{i}}}$表示对于每一个Mask的distance transform。</p>
<p>TexturePredictor会输出一个<code>texture flow</code>，也就是$\mathcal{F} \in \mathbb{R}^{H_{uv} * W_{uv} * 2}$,其中$H_{uv}*W_{uv}$分别表示UVmap的长和宽，而$\mathcal{F}(x,y)$对应的就是input image(x,y)。最后的UVmap就是$I^{uv} &#x3D; G(I;\mathcal{F})$。而这个<code>texture flow</code>不是神经网络的直接输出产物，而神经网络直接输出的是一个表示体现了UV图和Img的对应位置的关系，而其还是会与另一个<code>UVsample</code>进行取样。而<code>UVsample</code>表示的是UV图与$\hat{V}$上各个点的一个对应关系。这两个东西结合在一起后就可以体现UVmap、$\hat{V}$、img三者之间的关系。</p>
<h3 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h3><p><img src="/images/paper/bird_net/exp.png"></p>
]]></content>
      <categories>
        <category>论文阅读</category>
        <category>三维动物重建</category>
      </categories>
      <tags>
        <tag>三维重建</tag>
        <tag>纹理渲染</tag>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>&lt;论文阅读&gt;(七)Conditional Single-View Shape Generation for Multi-View Stereo Reconstruction</title>
    <url>/2019/09/09/dc749c90/</url>
    <content><![CDATA[<h2 id="Conditional-Single-view-Shape-Generation-for-Multi-view-Stereo-Reconstruction"><a href="#Conditional-Single-view-Shape-Generation-for-Multi-view-Stereo-Reconstruction" class="headerlink" title="&lt;论文阅读&gt;Conditional Single-view Shape Generation for Multi-view Stereo Reconstruction"></a>&lt;论文阅读&gt;Conditional Single-view Shape Generation for Multi-view Stereo Reconstruction</h2><p><a href="https://arxiv.org/pdf/1904.06699.pdf">论文链接</a></p>
<p><a href="https://github.com/weiyithu/OptimizeMVS">github</a></p>
<h3 id="Contribution"><a href="#Contribution" class="headerlink" title="Contribution###"></a>Contribution###</h3><ul>
<li>首次提出将单图重建工作中的模糊性进行建模。以单张图片作为输入，网络可以重建出若干符合单视角约束条件的三维模型。而这若干个三维模型就对单视角中的模糊性问题进行了建模，生成了模糊性空间。</li>
</ul>
<h3 id="Method"><a href="#Method" class="headerlink" title="Method###"></a>Method###</h3><p><img src="/images/paper/openmvs/overview.jpg"></p>
<h4 id="Overview"><a href="#Overview" class="headerlink" title="Overview####"></a>Overview####</h4><p>从上图可以看出，对于单图作为输入的重建模型，现有方法只能重建出一个确定的模型，而由于单图存在重建模糊性问题，肯定会导致该重建结果存在一些问题，特别是对不可见趋于的重建。而作者所提出的方法，可以在符合仅有的单视角约束条件下，重建出若干张图片，这些图片就模拟了不可见视角下的形状。</p>
<h4 id="Single-view-Reconstruction"><a href="#Single-view-Reconstruction" class="headerlink" title="Single-view Reconstruction####"></a>Single-view Reconstruction####</h4><p><img src="/images/paper/openmvs/single_view_re.jpg"></p>
<p>作者为了实现在重建的三维模型在符合单视角约束的前提下，对不可见视角进行合理猜想，设计了三个约束条件<code>Front Constraint</code>,<code>Diversity Constraint</code>,<code>Latent Space Discriminator</code>。</p>
<ul>
<li>Front Constraint</li>
</ul>
<p><code>Front Constraint</code>的作用是将收到视角约束限制的点从整个点云中分离开来。作者的做法是首先将重建得到的三维点云投影至二维平面以得到depth图片，然后再计算出哪些三维点构成了这些depth图片。文中将这些点的数量记为$N_i$</p>
<ul>
<li>Diversity Constraint</li>
</ul>
<p><code>Diversity Constraint</code>是限制剩下的$N-N_i$个生成点的位置。作者利用&nbsp;&nbsp;$loss_{div}&#x3D;max(0,||r_1-r_2||_2 - \alpha EMD(S_1,S_2))$ 来约束两个由同一张单视角图片生成的点云之间的差异性。$r_1，r_2$表示两个不同的随机向量，作者用这个来使得生成的模型具有一定的，可控的差异性。</p>
<ul>
<li>Latent Space Discriminator</li>
</ul>
<p><code>Latent Space Discriminator</code>被作者用来使生成的若干个三维模型不仅要符合单视角图片的约束，还需要符合一定的合理性。作者首先利用已有的点云表征学习的方法，训练了一个auto-encoder。接着作者将auto-encoder中的解码器移植到他自己的网络结构最后面，并将生成的三维模型作为输入，生成三维模型。</p>
<p><img src="/images/paper/openmvs/arch.jpg"></p>
<p>$loss_{gan} &#x3D; - \mathbb E_{I_i \thicksim p_{data},r_i \thicksim p(r)}[D(E_I(I_i,r_i))] + \mathbb E_{S \thicksim P_{data}}[D(E_S(S))] -\lambda \mathbb E_{\hat z \thicksim p_{\hat z}}[(||\triangledown_{\hat z}D(\hat z)||_2)^2] \tag{1}$</p>
<p>其中$E_I$为作者自己网络的编码器，$E_S$为auto-encoder的编码器，$D$为判别器，$S$为从训练数据集中采样的三维模型。作者认为该结构可以学习到形状先验，以保证生成的三维模型的合理性</p>
<h4 id="Synthesizing-Multi-view-Predictions"><a href="#Synthesizing-Multi-view-Predictions" class="headerlink" title="Synthesizing Multi-view Predictions"></a>Synthesizing Multi-view Predictions</h4><p>有了上面三个约束条件，作者预训练了一个单视角生成网络，但是网络的最终目的是生成一个准确的三维模型，这就需要用到多视角约束。</p>
<p><img src="/images/paper/openmvs/multi_view_re.jpg"> </p>
<p>根据上图可知，输入有单视角图片扩展为多视角图片，然后为每个输入图片生成一个三维模型。接着根据&nbsp;&nbsp; $loss_{consis} &#x3D; \frac{2}{n(n-1)}\sum_{i&#x3D;1}^{n-1}\sum^n_{j&#x3D;i+1}CD(S_i,S_j)$&nbsp;&nbsp;来约束这几个三维模型的一致性。</p>
<p><img src="/images/paper/openmvs/algorithm.jpg"></p>
<p>根据算法步骤可以发现一个<em><strong>有意思的</strong></em>地方，作者称为<code>heuristic search in initialization</code>。作者首先随机选择5组不同和的${r_{ij}}^5_{j&#x3D;1}$,每组包含的数量与输入图片数量一致。接着就分别把这5组$r_{ij}$结合同一组输入图片，输入到网络中，得到5个不同的$loss_{consis}$,把得到最小$loss_{consis}$的那组$r_{ij}$记为${r_i^+}<em>{i&#x3D;1}^n$。 接着在开始训练前，将预测模型Freeze,只根据loss值更新$r</em>{ij}$，直到收敛。</p>
<h3 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h3><p>1、将多视角重建问题分成两个部分，第一部分进行单输入图重建，并<strong>创造性</strong>的对固有的模糊性进行建模。作者对此在文中解释道：</p>
<blockquote>
<p>However, different from the scenarios of generation in CGAN [27], we only have limited groundtruth (in fact, only one shape per image) which cannot span the reasonable shape space. We aim to learn a mapping to approximate the probabilistic model $p(S|I)$) in the reasonable shape space.</p>
</blockquote>
<p>作者认为，单单靠一个监督是不足以使网络学习到一个可靠的形状空间。<strong>尽管作者做了消融实验证明了有效性，但是仍不足说服我。一个上百个点组成的三维空间，靠多预测个位数的三维模型，就能完成建模？）</strong></p>
<p>2、作者采用的启发式初始化有一定的可取之处，让网络自身决定合适的初始参数是什么</p>
]]></content>
      <categories>
        <category>论文阅读</category>
        <category>刚性物体重建</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>模糊性建模</tag>
      </tags>
  </entry>
  <entry>
    <title>&lt;论文阅读&gt;(二)End-to-End Recovery of Human Shape and Pose</title>
    <url>/2019/03/09/e6413cd/</url>
    <content><![CDATA[<h2 id="End-to-end-Recovery-of-Human-Shape-and-Pose"><a href="#End-to-end-Recovery-of-Human-Shape-and-Pose" class="headerlink" title="&lt;论文阅读&gt;End-to-end Recovery of Human Shape and Pose"></a>&lt;论文阅读&gt;End-to-end Recovery of Human Shape and Pose</h2><p><a href="https://arxiv.org/pdf/1712.06584.pdf" title="Learning Category-Specific Mesh Reconstruction"><strong>论文链接</strong></a></p>
<p><a href="https://github.com/akanazawa/hmr"><strong>Github链接</strong></a></p>
<h3 id="Contribution"><a href="#Contribution" class="headerlink" title="Contribution"></a>Contribution</h3><ul>
<li>单图重建</li>
<li>利用SMPL进行重建，并且达到real-time效果</li>
<li>不要求每一个训练的image都要有其对应的3D ground truth</li>
</ul>
<h3 id="Method"><a href="#Method" class="headerlink" title="Method"></a>Method</h3><p><img src="/images/paper/SMPL_net/method.png"></p>
<p>作者提出了一个end-to-end的网络来从单张RGB人像恢复其3D形状。作者利用已有的<code>SMPL</code>模型，<code>SMPL</code>模型可由<code>3D relative joint rotation</code>和<code>Shape</code> 来刻画一个人的<code>3D shape</code>。作者认为在以往的人体建模工作当中，有<code>3D joint location</code>来估计一个完整的<code>3D shape</code> 是不鲁棒的。原因有二：1、<code>3D joint location</code> alone do not constrain the full DoF at each joint. <a href="https://zh.wikipedia.org/wiki/%E6%99%AF%E6%B7%B1">DoF</a>意思就是景深，这个跟相机的参数有关。对这个参数的估计错误，可能会导致所估计的<code>3D shape</code>在图像中的显示位置有区别（我自己想的，不一定正确）2、Joints are sparse, whereas the human body is defined by a surface in 3D space. 这个就是Joints的点数过少，不足以约束一个完整的<code>3D human shape</code>。</p>
<p>作者还解决了两个在重建工作的问题。其一就是缺少<code>3D ground-truth</code>数据，同时，已有的<code>3D ground-truth</code>绝大部分是在实验室环境下采集的，其对<code>in the wild</code>的2D图像泛化性很差。其二就是单视角情况下2D-3D mapping的问题，不同的<code>3D shape</code>存在对应一张相同的2D图片，在这些<code>3D shape</code>中，存在一些不正常的shape(may not be anthropometrically reasonable)</p>
<h4 id="网络训练"><a href="#网络训练" class="headerlink" title="网络训练"></a>网络训练</h4><ul>
<li>网络结构</li>
</ul>
<p><img src="/images/paper/SMPL_net/Net_Arc.jpg"></p>
<ul>
<li>Encoder和Regression</li>
</ul>
<p>网络首先输入一张图片经过Encoder(Resnet-50)后，输出一个feature$\in \mathbb{R}^{2048}$。之后输入到一个Regressor（3层FC,2048D-&gt;1024D-&gt;1024D-&gt;85D）进行迭代，总共会迭代3次，每次迭代过程中会输入一个<code>cam_para</code>,<code>shape</code> $\beta$,<code>pose</code> $\theta$。将<code>pose</code>和<code>shape</code>输入smpl可以得到本次迭代后预测的模型（包括<code>3D joint location</code>）。由<code>cam_para</code>和<code>3D joint location</code>可以得到<code>2D joint location</code>从而可以计算$L_{reproj}$。由<code>pose</code>(也就是<code>joint rotation</code>)和<code>shape</code>可以计算出$L_{adv}$。若输入的2D image有对应的3D数据，则还可以计算$L_{3D}$。 但是在最后计算loss的时候，只会使用每次迭代时产生的$L_{adv}$，而$L_{3D}$和$L_{reproj}$只会利用最后一次迭代产生的loss。这是由于作者认为若每次迭代产生的loss全部都利用,这容易导致regressor限于局部最优化。</p>
<ul>
<li>Adversarial Prior</li>
</ul>
<p>Adversarial Prior是用来解决上面提到的生成3D数据不真实情况的一个判别器。由于该判别器的任务是判断smpl参数是否是一个正常的人体，那么自然就不需要与输入2D image对应的3D ground truth数据来训练这个判别器判断参数的正确性。由于事先知道我们预测的latent space的意义，所以作者将整个discriminator分解为pose discriminator和shape discriminate。作者又进一步将pose discriminator分解为对每个关节点的判别器（23个，这些判别器的作用在于限制每个关节点的旋转角度）和一个对所有关节点整体做判断的判别器（这个判别器作用在于判断所有关节点的分布关系)。</p>
<p>作者认为因为这个网络结构不存在刻意去欺骗Discriminator的行为，所以不会产生一般GANs网络会产生的mode collapse现象。</p>
<ul>
<li>loss函数</li>
</ul>
<p>$L &#x3D; \lambda(L_{reproj} + \mathbb{1}L_{3D}) + L_{adv} $，$\lambda$是用来控制两个目标函数的相对权重的。若输入的2D图像有对应的ground truth 3D数据时，$\mathbb{1}$的值就为1,否则就是0。</p>
<p>$L_{reproj} &#x3D; \sum \limits_{i}||v_{i}(x_{i}-\hat{x_{i}})||_{1}$,其中$\hat{x_{i}} &#x3D; s\Pi(RX(\theta,\beta)) + t$。 $R$表示旋转操作，$\Pi$表示正交投影，$s，t$分别表示Scale和translation。</p>
<p>$L_{3D} &#x3D; L_{3D joints} + L_{3D smpl}$</p>
<p>$L_{joints} &#x3D; ||(X_i-\hat{X_i})||_2^2$</p>
<p>$L_{smpl} &#x3D; ||[\beta_i,\theta_i]-[\hat{\beta_i},\hat{\theta_i}]||_2^2$</p>
<p>$minL_{abv}(E) &#x3D; \sum_i\mathbb{E}_{\Theta ~ pE}[(D_i(E(I)-1)^2]$</p>
<p>$minL(D_i) &#x3D; \mathbb{E}<em>{\Theta~pdata}[(D_i(\Theta)-1)^2]+\mathbb{E}</em>{\Theta ~ pE}[D_i(E(I)^2]$</p>
<p>很典型的GANs网络结构的Loss函数，其中$\Theta$表示真实的smpl参数。（这个loss函数真的能够限制每个关节的旋转角度和整体关节的分布情况么？？表示很难理解,欢迎提出新的见解~)</p>
<h3 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h3><p>对于2D image dataset,作者使用了<code>LSP</code>,<code>LSP-extended</code>,<code>MPII</code>和<code>MS COCO</code>，训练数据量分别是1k,10k,20k和80k。2D image和3D dataset作者使用了<code>Human 3.6M</code>和<code>MPI-INF-3DHP</code>。而用作训练<code>discriminator</code>的<code>SMPL</code>真实数据是: <code>CMU</code>, <code>Human3.6M training set</code> 和<br><code>the PosePrior dataset</code>,训练数据量分别是390k,150k,180k。</p>
<p>作者在<code>Human 3.6M</code>上采用了两种评价标准：</p>
<ul>
<li>mean per joint position error (MPJPE)</li>
<li>Reconstruction error, which is MPJPE after rigid alignment of the prediction with ground truth via Procrustes Analysis.</li>
</ul>
<p>相较于第一种，<code>Reconstruction error</code>能排除全局误差的影响，更好的比较<code>3D skeleton</code>.</p>
<p><img src="/images/paper/SMPL_net/evaluation1.jpg"></p>
<p><img src="/images/paper/SMPL_net/evaluation2.jpg"></p>
<p>作者发现即使拥有较高的<code>MPJPE</code>，文中的方法生成的3D模型从视觉效果上看，也不错。<br><img src="/images/paper/SMPL_net/h_error_b_reasonable.jpg"></p>
<p>作者在<code>MPI-INF-3DHP</code>上采用了两种评价标准：</p>
<ul>
<li>Percentage of Correct Keypoints(PCK) thresholded at 150mm</li>
<li>Area Under the Curve(AUC) over a range of PCK thresholds</li>
</ul>
<p><img src="/images/paper/SMPL_net/evaluation3.jpg"></p>
]]></content>
      <categories>
        <category>论文阅读</category>
        <category>三维人体重建</category>
      </categories>
      <tags>
        <tag>三维重建</tag>
        <tag>深度学习</tag>
        <tag>SMPL</tag>
      </tags>
  </entry>
  <entry>
    <title>&lt;论文阅读&gt;(五)Learning View Priors for Single-View 3D Reconstruction</title>
    <url>/2019/08/19/54bbc8cd/</url>
    <content><![CDATA[<h2 id="Learning-View-Priors-for-Single-view-3D-Reconstruction"><a href="#Learning-View-Priors-for-Single-view-3D-Reconstruction" class="headerlink" title="&lt;论文阅读&gt;Learning View Priors for Single-view 3D Reconstruction"></a>&lt;论文阅读&gt;Learning View Priors for Single-view 3D Reconstruction</h2><p><a href="https://arxiv.org/pdf/1811.10719.pdf">论文链接</a></p>
<h3 id="Contribution"><a href="#Contribution" class="headerlink" title="Contribution"></a>Contribution</h3><ul>
<li>提出了新的<code>视角先验</code>方法，该方法弥补了<code>对称先验</code>的不足，虽然重建物体大多是符合对称先验的，但是在拍摄照片的那一瞬间，由于拍摄角度和物体本身发生的一些形变等原因，使得待重建的物体本身并不是对称，这样便会使得重建效果不佳。</li>
<li>提出了<code>internal pressure</code>,即点可在与面片垂直的外方向尽可能膨胀。使得重建的物体更加饱满，看起来更加真实。</li>
</ul>
<h3 id="Methond"><a href="#Methond" class="headerlink" title="Methond"></a>Methond</h3><blockquote>
<p>本文主要介绍其中的单图重建工作，方法可以很好的泛化为多图重建方法。</p>
</blockquote>
<p><img src="/images/paper/view_prior/single_net.jpg"></p>
<ul>
<li>View prior</li>
</ul>
<p>其核心Loss函数为：</p>
<p>$\mathcal L_{r}(x,v) &#x3D; \sum_{i&#x3D;1}^{N_0} \mathcal L_{v}(P(R(x_{i1}),v_{i1}),x_{i1}) \tag{1}$<br>其中$R\left (* \right )$表示为重建函数，$P \left (* \right )$表示将重建好的三维物体按照$v_{i1}$视角投影会二维平面。而$\mathcal L_{v}$为衡量$x_{i1}$和$v_{i1}$视角下的重投影结果之间的误差（<code>a function that measures the difference between two views</code>）。</p>
<p>$\mathcal L_{s_1}(x_s,\hat x_s) &#x3D; \sum_{i&#x3D;1}^{N_s}\left( 1- \frac{x^i_s \cdot \hat x^i_s}{|x^i_s||\hat x^i_s|}\right) \tag{2}$</p>
<p>$\mathcal L_{s_2}(x_s,\hat x_s) &#x3D; 1 - \frac{|x_s \bigodot \hat x_s|_1}{|x_s+\hat x_s + x_s \bigodot \hat x_s|_1} \tag{3}$</p>
<p>$\mathcal L_v &#x3D; \mathcal L_s + \lambda_c \mathcal L_c \tag{4}$</p>
<p>其中$\mathcal L_c$为<code>perceptual loss</code>输入为RGB图片。$\mathcal L_s$的输入为剪影。$\mathcal L_{s_1}$是计算两个mask之间的余弦距离（可能是代表相似度？？），作者使用了多尺度mask,$N_s$代表下采样的次数。 $\mathcal L_{s_2}$为IOU（intersection over union)函数，为的是约束其剪影尽可能重叠。正如上面的$\mathcal L_r(x,v)$所介绍的那也，以上的所有函数都是为了评价两张图片($x_s,\hat x_s$)之间的相似度,其中前者为<code>ground-truth</code>图片,后者为预测的图片。在此基础上，作者使用<code>GAN</code>网络来<strong>学习训练数据集中待重建物体不同视角的先验知识</strong>,而上面这个Loss函数是用来限制生成器的，根据原图和重投影图片之间的误差不同，来更新生成器的参数，以期获得更好的重建效果。</p>
<p><img src="/images/paper/view_prior/example.jpg"></p>
<p>可以看到，对于椅子，使用作者提出<code>视角先验</code>的方法，重建的结果从各个视角看上去都更加符合实际情况。 基于这种情况，作者使用判别器来给生成器提供不同视角的重建信息。</p>
<p>$\mathcal L_d(x_{ij},v_{ij}) &#x3D; -log(Dis(P(R(x_{ij}),v_{ij}),v_{ij}))-\sum_{v_u \in \mathcal V ,, v_u \neq v_{ij}} \frac{ log(1- Dis(P(R(x_{ij}),v_{u}),v_{u}))}{|\mathcal V -1|}  \tag{5}$</p>
<p>整个网络的输入为单张RGB的图片，生成器首先依据图片重建出一个对应的三维模型，再根据这张图片所对应的<code>相机视角</code>反投影回二维平面，获得的图片可以记为$x_{gt}$。接着，在从$\mathcal V$中选取任一与之前的<code>相机视角</code>不一致的的<code>相机视角</code>，并依据此相机视角，再一次投影会二维平面。这是，第一次投影所得的$x_{gt}$就可以当做真实数据，第二次投影所得就可以当做加数据，一同送入判别器进行判断。作者在文中提到，所有的视角都是存在于训练集中的（$\mathcal V$ be the set of all viewpoints in the training dataset）。<strong>这是否意味着对于一些在训练集中不存在的视角，该网络还是难以学习到其形状？</strong></p>
<ul>
<li>Internal Pressure</li>
</ul>
<p>这是一个较弱的先验知识，这个是受启发与<code>Visual hull</code>重建技术。通俗的来讲，就是使重建结果，在不改变投影误差的限制下，尽可能的朝着某个方向膨胀。作者采用的方法就是对每个点施加了一个沿着所在面片法向量的梯度（Concretely, we add a gradient along the normal of the face for each vertex of a triangle face. Let p i be one of the vertices of a triangle face, and n be the normal of the face）。为了实现这一效果，需要添加一个函数，该函数需要满足:<br>$\frac{\partial \mathcal L_{p}(p_i)}{\partial p_i} &#x3D; -n  \tag{6}$</p>
<p>即关于$p_i$点的偏导等于该点所在的面片的法向量$\overrightarrow n$。文中没有提及具体的函数选择。</p>
<h3 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h3><p><img src="/images/paper/view_prior/exp1.jpg"></p>
<p>作者在文中提到，对于手机，沙发，飞机等物体。由于其形状单一，获取的<code>多视角先验</code>可以很好的解决在不可见视角下，重建效果差的问题。但是对于灯(lamp）这类物体，由于其形状的多样性，<strong>现有的网络并不能很好解决这个问题</strong>。</p>
]]></content>
      <categories>
        <category>论文阅读</category>
        <category>刚性物体重建</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>视角先验</tag>
      </tags>
  </entry>
  <entry>
    <title>&lt;论文阅读&gt;(九)Deep Marching Cubes Learning Explicit Surface Representations</title>
    <url>/2020/01/06/a18afe7a/</url>
    <content><![CDATA[<h2 id="Deep-Marching-Cubes-Learning-Explicit-Surface-Representations"><a href="#Deep-Marching-Cubes-Learning-Explicit-Surface-Representations" class="headerlink" title="Deep Marching Cubes: Learning Explicit Surface Representations"></a>Deep Marching Cubes: Learning Explicit Surface Representations</h2><h3 id="Background"><a href="#Background" class="headerlink" title="Background"></a>Background</h3><h4 id="Definition"><a href="#Definition" class="headerlink" title="Definition"></a>Definition</h4><p>Marching Cubes 常被用来从一个隐函数(比方说：$f(x,y,z) &#x3D; 0$)中恢复Mesh. 通过迭代式的对函数空间上的立方体进行匹配，来获取Mesh的点和拓扑结构。如果8个点全部为正数或负数，那么这8个点全部在物体外部或内部。所有的可能情况如下图所示。</p>
<p><img src="/images/paper/dmc/MarchingCubesCases.png"></p>
<p> 函数 $x^2 + y^2 + z^2 - 1 &#x3D; 0$ 表示一个单位球体. 其利用marching cubes 来得到的mesh如下图所示:</p>
 <iframe width="640" height="360" src="https://www.youtube.com/embed/B_xk71YopsA" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
 
<h4 id="Procedure"><a href="#Procedure" class="headerlink" title="Procedure"></a>Procedure</h4><p>首先将某次迭代的立方体各边和点定义好：</p>
<p> <img src="/images/paper/dmc/polygonise1.gif"></p>
<p>对于每个点，我们都有一个对应的值来表示其信息，该信息可以是1. 点属于表面的概率值。2. 点到距离其最近表面的距离（有正负）。3. 单纯的【1,0】表示点是否在物体内部。下面所有表述均已第<code>1</code>种情况为准。如果只有点<code>3</code>位于物体外部，其余点均位于物体内部，则我们可以大致将这个立方体切割为：</p>
<p><img src="/images/paper/dmc/polygonise2.gif"></p>
<p>边<code>11</code>,<code>2</code>,<code>3</code>被切割，但是具体的切割位置还需要求点<code>0</code>，<code>2</code>，<code>3</code>的值决定。即假设点<code>2</code>，<code>3</code>坐标为$P_2$，$P_3$，对于的值为$V_2$，$V_3$。那么在边<code>2</code>上的切割点坐标为：</p>
<p> $$ P&#x3D; \begin{cases} P_2 + \frac{(isovalue - V_2)(P_3 - P_2)}{V_3 - V_2}, &amp; \text {if  V_3 !&#x3D; V_2} \ \frac{P_2 + P_3}{2}, &amp; \text{if  V_3 &#x3D;&#x3D; V_2} \end{cases} \tag{1}$$</p>
<p> 其中$isovalue（isolevel）$为阈值，用来判断点是否在物体内部。</p>
<h4 id="Code"><a href="#Code" class="headerlink" title="Code"></a>Code</h4> <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"> typedef struct &#123;</span><br><span class="line">   XYZ p[3];</span><br><span class="line">&#125; TRIANGLE;</span><br><span class="line"></span><br><span class="line">typedef struct &#123;</span><br><span class="line">   XYZ p[8];</span><br><span class="line">   double val[8];</span><br><span class="line">&#125; GRIDCELL;</span><br><span class="line"></span><br><span class="line">/*</span><br><span class="line">   Given a grid cell and an isolevel, calculate the triangular</span><br><span class="line">   facets required to represent the isosurface through the cell.</span><br><span class="line">   Return the number of triangular facets, the array &quot;triangles&quot;</span><br><span class="line">   will be loaded up with the vertices at most 5 triangular facets.</span><br><span class="line">	0 will be returned if the grid cell is either totally above</span><br><span class="line">   of totally below the isolevel.</span><br><span class="line">*/</span><br><span class="line">int Polygonise(GRIDCELL grid,double isolevel,TRIANGLE *triangles)</span><br><span class="line">&#123;</span><br><span class="line">   int i,ntriang;</span><br><span class="line">   int cubeindex;</span><br><span class="line">   XYZ vertlist[12];</span><br><span class="line"></span><br><span class="line">int edgeTable[256]=&#123;</span><br><span class="line">0x0  , 0x109, 0x203, 0x30a, 0x406, 0x50f, 0x605, 0x70c,</span><br><span class="line">0x80c, 0x905, 0xa0f, 0xb06, 0xc0a, 0xd03, 0xe09, 0xf00,</span><br><span class="line">0x190, 0x99 , 0x393, 0x29a, 0x596, 0x49f, 0x795, 0x69c,</span><br><span class="line">0x99c, 0x895, 0xb9f, 0xa96, 0xd9a, 0xc93, 0xf99, 0xe90,</span><br><span class="line">0x230, 0x339, 0x33 , 0x13a, 0x636, 0x73f, 0x435, 0x53c,</span><br><span class="line">0xa3c, 0xb35, 0x83f, 0x936, 0xe3a, 0xf33, 0xc39, 0xd30,</span><br><span class="line">0x3a0, 0x2a9, 0x1a3, 0xaa , 0x7a6, 0x6af, 0x5a5, 0x4ac,</span><br><span class="line">0xbac, 0xaa5, 0x9af, 0x8a6, 0xfaa, 0xea3, 0xda9, 0xca0,</span><br><span class="line">0x460, 0x569, 0x663, 0x76a, 0x66 , 0x16f, 0x265, 0x36c,</span><br><span class="line">0xc6c, 0xd65, 0xe6f, 0xf66, 0x86a, 0x963, 0xa69, 0xb60,</span><br><span class="line">0x5f0, 0x4f9, 0x7f3, 0x6fa, 0x1f6, 0xff , 0x3f5, 0x2fc,</span><br><span class="line">0xdfc, 0xcf5, 0xfff, 0xef6, 0x9fa, 0x8f3, 0xbf9, 0xaf0,</span><br><span class="line">0x650, 0x759, 0x453, 0x55a, 0x256, 0x35f, 0x55 , 0x15c,</span><br><span class="line">0xe5c, 0xf55, 0xc5f, 0xd56, 0xa5a, 0xb53, 0x859, 0x950,</span><br><span class="line">0x7c0, 0x6c9, 0x5c3, 0x4ca, 0x3c6, 0x2cf, 0x1c5, 0xcc ,</span><br><span class="line">0xfcc, 0xec5, 0xdcf, 0xcc6, 0xbca, 0xac3, 0x9c9, 0x8c0,</span><br><span class="line">0x8c0, 0x9c9, 0xac3, 0xbca, 0xcc6, 0xdcf, 0xec5, 0xfcc,</span><br><span class="line">0xcc , 0x1c5, 0x2cf, 0x3c6, 0x4ca, 0x5c3, 0x6c9, 0x7c0,</span><br><span class="line">0x950, 0x859, 0xb53, 0xa5a, 0xd56, 0xc5f, 0xf55, 0xe5c,</span><br><span class="line">0x15c, 0x55 , 0x35f, 0x256, 0x55a, 0x453, 0x759, 0x650,</span><br><span class="line">0xaf0, 0xbf9, 0x8f3, 0x9fa, 0xef6, 0xfff, 0xcf5, 0xdfc,</span><br><span class="line">0x2fc, 0x3f5, 0xff , 0x1f6, 0x6fa, 0x7f3, 0x4f9, 0x5f0,</span><br><span class="line">0xb60, 0xa69, 0x963, 0x86a, 0xf66, 0xe6f, 0xd65, 0xc6c,</span><br><span class="line">0x36c, 0x265, 0x16f, 0x66 , 0x76a, 0x663, 0x569, 0x460,</span><br><span class="line">0xca0, 0xda9, 0xea3, 0xfaa, 0x8a6, 0x9af, 0xaa5, 0xbac,</span><br><span class="line">0x4ac, 0x5a5, 0x6af, 0x7a6, 0xaa , 0x1a3, 0x2a9, 0x3a0,</span><br><span class="line">0xd30, 0xc39, 0xf33, 0xe3a, 0x936, 0x83f, 0xb35, 0xa3c,</span><br><span class="line">0x53c, 0x435, 0x73f, 0x636, 0x13a, 0x33 , 0x339, 0x230,</span><br><span class="line">0xe90, 0xf99, 0xc93, 0xd9a, 0xa96, 0xb9f, 0x895, 0x99c,</span><br><span class="line">0x69c, 0x795, 0x49f, 0x596, 0x29a, 0x393, 0x99 , 0x190,</span><br><span class="line">0xf00, 0xe09, 0xd03, 0xc0a, 0xb06, 0xa0f, 0x905, 0x80c,</span><br><span class="line">0x70c, 0x605, 0x50f, 0x406, 0x30a, 0x203, 0x109, 0x0   &#125;;</span><br><span class="line">int triTable[256][16] =</span><br><span class="line">&#123;&#123;-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;0, 8, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;0, 1, 9, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;1, 8, 3, 9, 8, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;1, 2, 10, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;0, 8, 3, 1, 2, 10, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;9, 2, 10, 0, 2, 9, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;2, 8, 3, 2, 10, 8, 10, 9, 8, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;3, 11, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;0, 11, 2, 8, 11, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;1, 9, 0, 2, 3, 11, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;1, 11, 2, 1, 9, 11, 9, 8, 11, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;3, 10, 1, 11, 10, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;0, 10, 1, 0, 8, 10, 8, 11, 10, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;3, 9, 0, 3, 11, 9, 11, 10, 9, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;9, 8, 10, 10, 8, 11, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;4, 7, 8, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;4, 3, 0, 7, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;0, 1, 9, 8, 4, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;4, 1, 9, 4, 7, 1, 7, 3, 1, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;1, 2, 10, 8, 4, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;3, 4, 7, 3, 0, 4, 1, 2, 10, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;9, 2, 10, 9, 0, 2, 8, 4, 7, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;2, 10, 9, 2, 9, 7, 2, 7, 3, 7, 9, 4, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;8, 4, 7, 3, 11, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;11, 4, 7, 11, 2, 4, 2, 0, 4, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;9, 0, 1, 8, 4, 7, 2, 3, 11, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;4, 7, 11, 9, 4, 11, 9, 11, 2, 9, 2, 1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;3, 10, 1, 3, 11, 10, 7, 8, 4, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;1, 11, 10, 1, 4, 11, 1, 0, 4, 7, 11, 4, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;4, 7, 8, 9, 0, 11, 9, 11, 10, 11, 0, 3, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;4, 7, 11, 4, 11, 9, 9, 11, 10, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;9, 5, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;9, 5, 4, 0, 8, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;0, 5, 4, 1, 5, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;8, 5, 4, 8, 3, 5, 3, 1, 5, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;1, 2, 10, 9, 5, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;3, 0, 8, 1, 2, 10, 4, 9, 5, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;5, 2, 10, 5, 4, 2, 4, 0, 2, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;2, 10, 5, 3, 2, 5, 3, 5, 4, 3, 4, 8, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;9, 5, 4, 2, 3, 11, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;0, 11, 2, 0, 8, 11, 4, 9, 5, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;0, 5, 4, 0, 1, 5, 2, 3, 11, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;2, 1, 5, 2, 5, 8, 2, 8, 11, 4, 8, 5, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;10, 3, 11, 10, 1, 3, 9, 5, 4, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;4, 9, 5, 0, 8, 1, 8, 10, 1, 8, 11, 10, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;5, 4, 0, 5, 0, 11, 5, 11, 10, 11, 0, 3, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;5, 4, 8, 5, 8, 10, 10, 8, 11, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;9, 7, 8, 5, 7, 9, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;9, 3, 0, 9, 5, 3, 5, 7, 3, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;0, 7, 8, 0, 1, 7, 1, 5, 7, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;1, 5, 3, 3, 5, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;9, 7, 8, 9, 5, 7, 10, 1, 2, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;10, 1, 2, 9, 5, 0, 5, 3, 0, 5, 7, 3, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;8, 0, 2, 8, 2, 5, 8, 5, 7, 10, 5, 2, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;2, 10, 5, 2, 5, 3, 3, 5, 7, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;7, 9, 5, 7, 8, 9, 3, 11, 2, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;9, 5, 7, 9, 7, 2, 9, 2, 0, 2, 7, 11, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;2, 3, 11, 0, 1, 8, 1, 7, 8, 1, 5, 7, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;11, 2, 1, 11, 1, 7, 7, 1, 5, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;9, 5, 8, 8, 5, 7, 10, 1, 3, 10, 3, 11, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;5, 7, 0, 5, 0, 9, 7, 11, 0, 1, 0, 10, 11, 10, 0, -1&#125;,</span><br><span class="line">&#123;11, 10, 0, 11, 0, 3, 10, 5, 0, 8, 0, 7, 5, 7, 0, -1&#125;,</span><br><span class="line">&#123;11, 10, 5, 7, 11, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;10, 6, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;0, 8, 3, 5, 10, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;9, 0, 1, 5, 10, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;1, 8, 3, 1, 9, 8, 5, 10, 6, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;1, 6, 5, 2, 6, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;1, 6, 5, 1, 2, 6, 3, 0, 8, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;9, 6, 5, 9, 0, 6, 0, 2, 6, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;5, 9, 8, 5, 8, 2, 5, 2, 6, 3, 2, 8, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;2, 3, 11, 10, 6, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;11, 0, 8, 11, 2, 0, 10, 6, 5, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;0, 1, 9, 2, 3, 11, 5, 10, 6, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;5, 10, 6, 1, 9, 2, 9, 11, 2, 9, 8, 11, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;6, 3, 11, 6, 5, 3, 5, 1, 3, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;0, 8, 11, 0, 11, 5, 0, 5, 1, 5, 11, 6, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;3, 11, 6, 0, 3, 6, 0, 6, 5, 0, 5, 9, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;6, 5, 9, 6, 9, 11, 11, 9, 8, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;5, 10, 6, 4, 7, 8, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;4, 3, 0, 4, 7, 3, 6, 5, 10, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;1, 9, 0, 5, 10, 6, 8, 4, 7, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;10, 6, 5, 1, 9, 7, 1, 7, 3, 7, 9, 4, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;6, 1, 2, 6, 5, 1, 4, 7, 8, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;1, 2, 5, 5, 2, 6, 3, 0, 4, 3, 4, 7, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;8, 4, 7, 9, 0, 5, 0, 6, 5, 0, 2, 6, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;7, 3, 9, 7, 9, 4, 3, 2, 9, 5, 9, 6, 2, 6, 9, -1&#125;,</span><br><span class="line">&#123;3, 11, 2, 7, 8, 4, 10, 6, 5, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;5, 10, 6, 4, 7, 2, 4, 2, 0, 2, 7, 11, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;0, 1, 9, 4, 7, 8, 2, 3, 11, 5, 10, 6, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;9, 2, 1, 9, 11, 2, 9, 4, 11, 7, 11, 4, 5, 10, 6, -1&#125;,</span><br><span class="line">&#123;8, 4, 7, 3, 11, 5, 3, 5, 1, 5, 11, 6, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;5, 1, 11, 5, 11, 6, 1, 0, 11, 7, 11, 4, 0, 4, 11, -1&#125;,</span><br><span class="line">&#123;0, 5, 9, 0, 6, 5, 0, 3, 6, 11, 6, 3, 8, 4, 7, -1&#125;,</span><br><span class="line">&#123;6, 5, 9, 6, 9, 11, 4, 7, 9, 7, 11, 9, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;10, 4, 9, 6, 4, 10, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;4, 10, 6, 4, 9, 10, 0, 8, 3, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;10, 0, 1, 10, 6, 0, 6, 4, 0, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;8, 3, 1, 8, 1, 6, 8, 6, 4, 6, 1, 10, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;1, 4, 9, 1, 2, 4, 2, 6, 4, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;3, 0, 8, 1, 2, 9, 2, 4, 9, 2, 6, 4, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;0, 2, 4, 4, 2, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;8, 3, 2, 8, 2, 4, 4, 2, 6, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;10, 4, 9, 10, 6, 4, 11, 2, 3, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;0, 8, 2, 2, 8, 11, 4, 9, 10, 4, 10, 6, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;3, 11, 2, 0, 1, 6, 0, 6, 4, 6, 1, 10, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;6, 4, 1, 6, 1, 10, 4, 8, 1, 2, 1, 11, 8, 11, 1, -1&#125;,</span><br><span class="line">&#123;9, 6, 4, 9, 3, 6, 9, 1, 3, 11, 6, 3, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;8, 11, 1, 8, 1, 0, 11, 6, 1, 9, 1, 4, 6, 4, 1, -1&#125;,</span><br><span class="line">&#123;3, 11, 6, 3, 6, 0, 0, 6, 4, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;6, 4, 8, 11, 6, 8, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;7, 10, 6, 7, 8, 10, 8, 9, 10, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;0, 7, 3, 0, 10, 7, 0, 9, 10, 6, 7, 10, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;10, 6, 7, 1, 10, 7, 1, 7, 8, 1, 8, 0, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;10, 6, 7, 10, 7, 1, 1, 7, 3, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;1, 2, 6, 1, 6, 8, 1, 8, 9, 8, 6, 7, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;2, 6, 9, 2, 9, 1, 6, 7, 9, 0, 9, 3, 7, 3, 9, -1&#125;,</span><br><span class="line">&#123;7, 8, 0, 7, 0, 6, 6, 0, 2, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;7, 3, 2, 6, 7, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;2, 3, 11, 10, 6, 8, 10, 8, 9, 8, 6, 7, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;2, 0, 7, 2, 7, 11, 0, 9, 7, 6, 7, 10, 9, 10, 7, -1&#125;,</span><br><span class="line">&#123;1, 8, 0, 1, 7, 8, 1, 10, 7, 6, 7, 10, 2, 3, 11, -1&#125;,</span><br><span class="line">&#123;11, 2, 1, 11, 1, 7, 10, 6, 1, 6, 7, 1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;8, 9, 6, 8, 6, 7, 9, 1, 6, 11, 6, 3, 1, 3, 6, -1&#125;,</span><br><span class="line">&#123;0, 9, 1, 11, 6, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;7, 8, 0, 7, 0, 6, 3, 11, 0, 11, 6, 0, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;7, 11, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;7, 6, 11, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;3, 0, 8, 11, 7, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;0, 1, 9, 11, 7, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;8, 1, 9, 8, 3, 1, 11, 7, 6, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;10, 1, 2, 6, 11, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;1, 2, 10, 3, 0, 8, 6, 11, 7, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;2, 9, 0, 2, 10, 9, 6, 11, 7, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;6, 11, 7, 2, 10, 3, 10, 8, 3, 10, 9, 8, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;7, 2, 3, 6, 2, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;7, 0, 8, 7, 6, 0, 6, 2, 0, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;2, 7, 6, 2, 3, 7, 0, 1, 9, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;1, 6, 2, 1, 8, 6, 1, 9, 8, 8, 7, 6, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;10, 7, 6, 10, 1, 7, 1, 3, 7, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;10, 7, 6, 1, 7, 10, 1, 8, 7, 1, 0, 8, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;0, 3, 7, 0, 7, 10, 0, 10, 9, 6, 10, 7, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;7, 6, 10, 7, 10, 8, 8, 10, 9, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;6, 8, 4, 11, 8, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;3, 6, 11, 3, 0, 6, 0, 4, 6, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;8, 6, 11, 8, 4, 6, 9, 0, 1, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;9, 4, 6, 9, 6, 3, 9, 3, 1, 11, 3, 6, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;6, 8, 4, 6, 11, 8, 2, 10, 1, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;1, 2, 10, 3, 0, 11, 0, 6, 11, 0, 4, 6, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;4, 11, 8, 4, 6, 11, 0, 2, 9, 2, 10, 9, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;10, 9, 3, 10, 3, 2, 9, 4, 3, 11, 3, 6, 4, 6, 3, -1&#125;,</span><br><span class="line">&#123;8, 2, 3, 8, 4, 2, 4, 6, 2, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;0, 4, 2, 4, 6, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;1, 9, 0, 2, 3, 4, 2, 4, 6, 4, 3, 8, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;1, 9, 4, 1, 4, 2, 2, 4, 6, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;8, 1, 3, 8, 6, 1, 8, 4, 6, 6, 10, 1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;10, 1, 0, 10, 0, 6, 6, 0, 4, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;4, 6, 3, 4, 3, 8, 6, 10, 3, 0, 3, 9, 10, 9, 3, -1&#125;,</span><br><span class="line">&#123;10, 9, 4, 6, 10, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;4, 9, 5, 7, 6, 11, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;0, 8, 3, 4, 9, 5, 11, 7, 6, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;5, 0, 1, 5, 4, 0, 7, 6, 11, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;11, 7, 6, 8, 3, 4, 3, 5, 4, 3, 1, 5, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;9, 5, 4, 10, 1, 2, 7, 6, 11, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;6, 11, 7, 1, 2, 10, 0, 8, 3, 4, 9, 5, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;7, 6, 11, 5, 4, 10, 4, 2, 10, 4, 0, 2, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;3, 4, 8, 3, 5, 4, 3, 2, 5, 10, 5, 2, 11, 7, 6, -1&#125;,</span><br><span class="line">&#123;7, 2, 3, 7, 6, 2, 5, 4, 9, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;9, 5, 4, 0, 8, 6, 0, 6, 2, 6, 8, 7, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;3, 6, 2, 3, 7, 6, 1, 5, 0, 5, 4, 0, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;6, 2, 8, 6, 8, 7, 2, 1, 8, 4, 8, 5, 1, 5, 8, -1&#125;,</span><br><span class="line">&#123;9, 5, 4, 10, 1, 6, 1, 7, 6, 1, 3, 7, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;1, 6, 10, 1, 7, 6, 1, 0, 7, 8, 7, 0, 9, 5, 4, -1&#125;,</span><br><span class="line">&#123;4, 0, 10, 4, 10, 5, 0, 3, 10, 6, 10, 7, 3, 7, 10, -1&#125;,</span><br><span class="line">&#123;7, 6, 10, 7, 10, 8, 5, 4, 10, 4, 8, 10, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;6, 9, 5, 6, 11, 9, 11, 8, 9, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;3, 6, 11, 0, 6, 3, 0, 5, 6, 0, 9, 5, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;0, 11, 8, 0, 5, 11, 0, 1, 5, 5, 6, 11, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;6, 11, 3, 6, 3, 5, 5, 3, 1, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;1, 2, 10, 9, 5, 11, 9, 11, 8, 11, 5, 6, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;0, 11, 3, 0, 6, 11, 0, 9, 6, 5, 6, 9, 1, 2, 10, -1&#125;,</span><br><span class="line">&#123;11, 8, 5, 11, 5, 6, 8, 0, 5, 10, 5, 2, 0, 2, 5, -1&#125;,</span><br><span class="line">&#123;6, 11, 3, 6, 3, 5, 2, 10, 3, 10, 5, 3, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;5, 8, 9, 5, 2, 8, 5, 6, 2, 3, 8, 2, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;9, 5, 6, 9, 6, 0, 0, 6, 2, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;1, 5, 8, 1, 8, 0, 5, 6, 8, 3, 8, 2, 6, 2, 8, -1&#125;,</span><br><span class="line">&#123;1, 5, 6, 2, 1, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;1, 3, 6, 1, 6, 10, 3, 8, 6, 5, 6, 9, 8, 9, 6, -1&#125;,</span><br><span class="line">&#123;10, 1, 0, 10, 0, 6, 9, 5, 0, 5, 6, 0, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;0, 3, 8, 5, 6, 10, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;10, 5, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;11, 5, 10, 7, 5, 11, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;11, 5, 10, 11, 7, 5, 8, 3, 0, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;5, 11, 7, 5, 10, 11, 1, 9, 0, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;10, 7, 5, 10, 11, 7, 9, 8, 1, 8, 3, 1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;11, 1, 2, 11, 7, 1, 7, 5, 1, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;0, 8, 3, 1, 2, 7, 1, 7, 5, 7, 2, 11, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;9, 7, 5, 9, 2, 7, 9, 0, 2, 2, 11, 7, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;7, 5, 2, 7, 2, 11, 5, 9, 2, 3, 2, 8, 9, 8, 2, -1&#125;,</span><br><span class="line">&#123;2, 5, 10, 2, 3, 5, 3, 7, 5, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;8, 2, 0, 8, 5, 2, 8, 7, 5, 10, 2, 5, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;9, 0, 1, 5, 10, 3, 5, 3, 7, 3, 10, 2, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;9, 8, 2, 9, 2, 1, 8, 7, 2, 10, 2, 5, 7, 5, 2, -1&#125;,</span><br><span class="line">&#123;1, 3, 5, 3, 7, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;0, 8, 7, 0, 7, 1, 1, 7, 5, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;9, 0, 3, 9, 3, 5, 5, 3, 7, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;9, 8, 7, 5, 9, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;5, 8, 4, 5, 10, 8, 10, 11, 8, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;5, 0, 4, 5, 11, 0, 5, 10, 11, 11, 3, 0, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;0, 1, 9, 8, 4, 10, 8, 10, 11, 10, 4, 5, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;10, 11, 4, 10, 4, 5, 11, 3, 4, 9, 4, 1, 3, 1, 4, -1&#125;,</span><br><span class="line">&#123;2, 5, 1, 2, 8, 5, 2, 11, 8, 4, 5, 8, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;0, 4, 11, 0, 11, 3, 4, 5, 11, 2, 11, 1, 5, 1, 11, -1&#125;,</span><br><span class="line">&#123;0, 2, 5, 0, 5, 9, 2, 11, 5, 4, 5, 8, 11, 8, 5, -1&#125;,</span><br><span class="line">&#123;9, 4, 5, 2, 11, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;2, 5, 10, 3, 5, 2, 3, 4, 5, 3, 8, 4, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;5, 10, 2, 5, 2, 4, 4, 2, 0, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;3, 10, 2, 3, 5, 10, 3, 8, 5, 4, 5, 8, 0, 1, 9, -1&#125;,</span><br><span class="line">&#123;5, 10, 2, 5, 2, 4, 1, 9, 2, 9, 4, 2, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;8, 4, 5, 8, 5, 3, 3, 5, 1, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;0, 4, 5, 1, 0, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;8, 4, 5, 8, 5, 3, 9, 0, 5, 0, 3, 5, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;9, 4, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;4, 11, 7, 4, 9, 11, 9, 10, 11, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;0, 8, 3, 4, 9, 7, 9, 11, 7, 9, 10, 11, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;1, 10, 11, 1, 11, 4, 1, 4, 0, 7, 4, 11, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;3, 1, 4, 3, 4, 8, 1, 10, 4, 7, 4, 11, 10, 11, 4, -1&#125;,</span><br><span class="line">&#123;4, 11, 7, 9, 11, 4, 9, 2, 11, 9, 1, 2, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;9, 7, 4, 9, 11, 7, 9, 1, 11, 2, 11, 1, 0, 8, 3, -1&#125;,</span><br><span class="line">&#123;11, 7, 4, 11, 4, 2, 2, 4, 0, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;11, 7, 4, 11, 4, 2, 8, 3, 4, 3, 2, 4, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;2, 9, 10, 2, 7, 9, 2, 3, 7, 7, 4, 9, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;9, 10, 7, 9, 7, 4, 10, 2, 7, 8, 7, 0, 2, 0, 7, -1&#125;,</span><br><span class="line">&#123;3, 7, 10, 3, 10, 2, 7, 4, 10, 1, 10, 0, 4, 0, 10, -1&#125;,</span><br><span class="line">&#123;1, 10, 2, 8, 7, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;4, 9, 1, 4, 1, 7, 7, 1, 3, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;4, 9, 1, 4, 1, 7, 0, 8, 1, 8, 7, 1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;4, 0, 3, 7, 4, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;4, 8, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;9, 10, 8, 10, 11, 8, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;3, 0, 9, 3, 9, 11, 11, 9, 10, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;0, 1, 10, 0, 10, 8, 8, 10, 11, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;3, 1, 10, 11, 3, 10, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;1, 2, 11, 1, 11, 9, 9, 11, 8, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;3, 0, 9, 3, 9, 11, 1, 2, 9, 2, 11, 9, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;0, 2, 11, 8, 0, 11, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;3, 2, 11, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;2, 3, 8, 2, 8, 10, 10, 8, 9, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;9, 10, 2, 0, 9, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;2, 3, 8, 2, 8, 10, 0, 1, 8, 1, 10, 8, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;1, 10, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;1, 3, 8, 9, 1, 8, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;0, 9, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;0, 3, 8, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1&#125;,</span><br><span class="line">&#123;-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1&#125;&#125;;</span><br><span class="line"></span><br><span class="line">   /*</span><br><span class="line">      Determine the index into the edge table which</span><br><span class="line">      tells us which vertices are inside of the surface</span><br><span class="line">   */</span><br><span class="line">   cubeindex = 0;</span><br><span class="line">   if (grid.val[0] &lt; isolevel) cubeindex |= 1;</span><br><span class="line">   if (grid.val[1] &lt; isolevel) cubeindex |= 2;</span><br><span class="line">   if (grid.val[2] &lt; isolevel) cubeindex |= 4;</span><br><span class="line">   if (grid.val[3] &lt; isolevel) cubeindex |= 8;</span><br><span class="line">   if (grid.val[4] &lt; isolevel) cubeindex |= 16;</span><br><span class="line">   if (grid.val[5] &lt; isolevel) cubeindex |= 32;</span><br><span class="line">   if (grid.val[6] &lt; isolevel) cubeindex |= 64;</span><br><span class="line">   if (grid.val[7] &lt; isolevel) cubeindex |= 128;</span><br><span class="line"></span><br><span class="line">   /* Cube is entirely in/out of the surface */</span><br><span class="line">   if (edgeTable[cubeindex] == 0)</span><br><span class="line">      return(0);</span><br><span class="line"></span><br><span class="line">   /* Find the vertices where the surface intersects the cube */</span><br><span class="line">   if (edgeTable[cubeindex] &amp; 1)</span><br><span class="line">      vertlist[0] =</span><br><span class="line">         VertexInterp(isolevel,grid.p[0],grid.p[1],grid.val[0],grid.val[1]);</span><br><span class="line">   if (edgeTable[cubeindex] &amp; 2)</span><br><span class="line">      vertlist[1] =</span><br><span class="line">         VertexInterp(isolevel,grid.p[1],grid.p[2],grid.val[1],grid.val[2]);</span><br><span class="line">   if (edgeTable[cubeindex] &amp; 4)</span><br><span class="line">      vertlist[2] =</span><br><span class="line">         VertexInterp(isolevel,grid.p[2],grid.p[3],grid.val[2],grid.val[3]);</span><br><span class="line">   if (edgeTable[cubeindex] &amp; 8)</span><br><span class="line">      vertlist[3] =</span><br><span class="line">         VertexInterp(isolevel,grid.p[3],grid.p[0],grid.val[3],grid.val[0]);</span><br><span class="line">   if (edgeTable[cubeindex] &amp; 16)</span><br><span class="line">      vertlist[4] =</span><br><span class="line">         VertexInterp(isolevel,grid.p[4],grid.p[5],grid.val[4],grid.val[5]);</span><br><span class="line">   if (edgeTable[cubeindex] &amp; 32)</span><br><span class="line">      vertlist[5] =</span><br><span class="line">         VertexInterp(isolevel,grid.p[5],grid.p[6],grid.val[5],grid.val[6]);</span><br><span class="line">   if (edgeTable[cubeindex] &amp; 64)</span><br><span class="line">      vertlist[6] =</span><br><span class="line">         VertexInterp(isolevel,grid.p[6],grid.p[7],grid.val[6],grid.val[7]);</span><br><span class="line">   if (edgeTable[cubeindex] &amp; 128)</span><br><span class="line">      vertlist[7] =</span><br><span class="line">         VertexInterp(isolevel,grid.p[7],grid.p[4],grid.val[7],grid.val[4]);</span><br><span class="line">   if (edgeTable[cubeindex] &amp; 256)</span><br><span class="line">      vertlist[8] =</span><br><span class="line">         VertexInterp(isolevel,grid.p[0],grid.p[4],grid.val[0],grid.val[4]);</span><br><span class="line">   if (edgeTable[cubeindex] &amp; 512)</span><br><span class="line">      vertlist[9] =</span><br><span class="line">         VertexInterp(isolevel,grid.p[1],grid.p[5],grid.val[1],grid.val[5]);</span><br><span class="line">   if (edgeTable[cubeindex] &amp; 1024)</span><br><span class="line">      vertlist[10] =</span><br><span class="line">         VertexInterp(isolevel,grid.p[2],grid.p[6],grid.val[2],grid.val[6]);</span><br><span class="line">   if (edgeTable[cubeindex] &amp; 2048)</span><br><span class="line">      vertlist[11] =</span><br><span class="line">         VertexInterp(isolevel,grid.p[3],grid.p[7],grid.val[3],grid.val[7]);</span><br><span class="line"></span><br><span class="line">   /* Create the triangle */</span><br><span class="line">   ntriang = 0;</span><br><span class="line">   for (i=0;triTable[cubeindex][i]!=-1;i+=3) &#123;</span><br><span class="line">      triangles[ntriang].p[0] = vertlist[triTable[cubeindex][i  ]];</span><br><span class="line">      triangles[ntriang].p[1] = vertlist[triTable[cubeindex][i+1]];</span><br><span class="line">      triangles[ntriang].p[2] = vertlist[triTable[cubeindex][i+2]];</span><br><span class="line">      ntriang++;</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">   return(ntriang);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">/*</span><br><span class="line">   Linearly interpolate the position where an isosurface cuts</span><br><span class="line">   an edge between two vertices, each with their own scalar value</span><br><span class="line">*/</span><br><span class="line">XYZ VertexInterp(isolevel,p1,p2,valp1,valp2)</span><br><span class="line">double isolevel;</span><br><span class="line">XYZ p1,p2;</span><br><span class="line">double valp1,valp2;</span><br><span class="line">&#123;</span><br><span class="line">   double mu;</span><br><span class="line">   XYZ p;</span><br><span class="line"></span><br><span class="line">   if (ABS(isolevel-valp1) &lt; 0.00001)</span><br><span class="line">      return(p1);</span><br><span class="line">   if (ABS(isolevel-valp2) &lt; 0.00001)</span><br><span class="line">      return(p2);</span><br><span class="line">   if (ABS(valp1-valp2) &lt; 0.00001)</span><br><span class="line">      return(p1);</span><br><span class="line">   mu = (isolevel - valp1) / (valp2 - valp1);</span><br><span class="line">   p.x = p1.x + mu * (p2.x - p1.x);</span><br><span class="line">   p.y = p1.y + mu * (p2.y - p1.y);</span><br><span class="line">   p.z = p1.z + mu * (p2.z - p1.z);</span><br><span class="line"></span><br><span class="line">   return(p);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="Deep-Marching-Cubes"><a href="#Deep-Marching-Cubes" class="headerlink" title="Deep Marching Cubes"></a>Deep Marching Cubes</h3><p> 作者认为传统的<code>Marching Cubes</code>的有两点缺点：</p>
<ul>
<li>由$(1)$可以看出，<code>Marching Cubes</code>方法是不可导的，不能直接嵌入到已有的深度学习方法中，进行端到端的训练。</li>
<li><code>Marching Cubes</code> 在求解时的<code>Marching</code>过程仅仅涉及到单个方格，即使可以求导，其梯度也不能扩散到其他表面。</li>
</ul>
<p>因此作者在本文提出一个<code>可导</code>的<code>marching cubes</code>方法，并且通过设置合理的$loss functions$来解决第二个问题。</p>
<h4 id="Differentiable-Marching-Cubes"><a href="#Differentiable-Marching-Cubes" class="headerlink" title="Differentiable Marching Cubes"></a>Differentiable Marching Cubes</h4><p><img src="/images/paper/dmc/arch.png"></p>
<p>网络的输入为<code>point clouds</code>，经过Encoder-Decoder结构得到$O \in \mathbb R^{N \times N \times N \times 1}$ (Occuapancy Value)和$X \in \mathbb R^{N \times N \times N \times 6}$(vertex coordinates，文中的vertex displacements)。其中$O \in [0,1]$就表示对每个点是在表面(surface)的概率值。那么我们可以合理假设每个点对于是否是occupied的概率分布为：<br>$$p_n(t) &#x3D; (o_n)^t(1-O_n)^{1-t} \tag{2}$$</p>
<p>那么对于Cell属于的概率分布为：</p>
<p>$$p_n(T) &#x3D; \prod \limits_{m \in {0,1}^3} o_{n+m}^{t_m}(1-o_{n+m})^{1-t_m} \tag{3}$$</p>
<p>这里解释一下(3)的含义：</p>
<p>在传统<code>Marching cubes</code>定义了一个Cube中8个点在是否是occupied状态下，总共$2^8$中不同的拓扑构（有重复）。以2D情况假设某个Cube的网络输出occupied概率情况为：<code>0.3 0.2 0 0.15 0.6 0 0.4 0.2</code>,那么non-occupied的情况为：<code>0.7 0.8 1 0.85 0.4 1 0.6 0.8</code>。以256种情况中某一种为例：<code>0 1 0 1 1 0 0 1</code>。将么套用公式三可以到$.7 \times .2 \times 1. \times .15 \times .6 \times 1. \times .6 \times .2 &#x3D; 0.001512$ 。将上述步骤重复$2^8&#x3D;256$次可以得到一个tensor表征每个cube关于全部256种拓扑结构的概率。<br>具体<a href="https://github.com/yiyiliao/deep_marching_cubes/blob/6fce0b26d110a6c839b6d46ea2ab67b5bdb470b2/marching_cube/model/cffi/src/occupancy_to_topology.c#L302">代码</a>：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">for(int i=0; i&lt;W; i++)&#123;</span><br><span class="line">    for (int j=0; j&lt;H; j++)&#123;</span><br><span class="line">      for (int k=0; k&lt;D; k++)&#123;</span><br><span class="line">	// read both positive probability and negative probability from the occupancy map</span><br><span class="line">        float p_occ[2][8];</span><br><span class="line">        for (int v=0; v&lt;8; v++)&#123;</span><br><span class="line">	  p_occ[0][v] = THFloatTensor_get3d(occupancy, i+vertexTable[v][0], j+vertexTable[v][1], k+vertexTable[v][2]); </span><br><span class="line">	  p_occ[1][v] = 1-p_occ[0][v]; </span><br><span class="line">	&#125;</span><br><span class="line">	// get the probability of each topology type from the occupancy status of the corners</span><br><span class="line">	for (int t=0; t&lt;T; t++)&#123;</span><br><span class="line">	    int topology_ind = t;</span><br><span class="line">            float p_accumu = 1.0;</span><br><span class="line">            for (int v=0; v&lt;8; v++)&#123;</span><br><span class="line">                p_accumu = p_accumu*p_occ[occTable[topology_ind][v]][v]; </span><br><span class="line">	    &#125;</span><br><span class="line">            THFloatTensor_set2d(topology, i*H*D+j*D+k, t, p_accumu);</span><br><span class="line"></span><br><span class="line">	&#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>

<h4 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h4><p>传统的<code>Marching Cubes</code>通过一个Cube8个角上的<code>Occupancy value</code> 和 <code>isovalue</code>来估算拓扑结构。由于设计到的插值公式不可导，作者将拓扑结构的获取和插值公式得到的坐标分开预测，也就是$O$(occupancy value)和$X$(vertex displacement), 这样就避免了插值公式不可导的问题。</p>
<p>作者还有一点很好的地方，就是假设点的概率值符合<code>伯努利分布</code>,这样就可以得到一个cube关于所有拓扑结构的所有概率值，计算loss的时候，是用所有的拓扑结构共享同一个vertex displacement来得到误差。这种对所有情况都预测一个概率值当做权重的思想比较常见（例：pixel2mesh++, CMR)。</p>
]]></content>
      <categories>
        <category>论文阅读</category>
        <category>刚性物体重建</category>
      </categories>
      <tags>
        <tag>Marching Cubes</tag>
      </tags>
  </entry>
  <entry>
    <title>&lt;论文阅读&gt;(三)Paperset:how to Extract Geometric Features From Spatial Layout of Points</title>
    <url>/2019/06/06/a24b1b46/</url>
    <content><![CDATA[<h2 id="Paper-set-how-to-extract-geometric-features-from-spatial-layout-of-points"><a href="#Paper-set-how-to-extract-geometric-features-from-spatial-layout-of-points" class="headerlink" title="&lt;论文阅读&gt;Paper set: how to extract geometric features from spatial layout of points"></a>&lt;论文阅读&gt;Paper set: how to extract geometric features from spatial layout of points</h2><ul>
<li>   [1]<a href="https://arxiv.org/pdf/1801.07829.pdf">TOG2018 Dynamic Graph CNN for Learning on Point Clouds</a></li>
<li>   [2]<a href="https://arxiv.org/pdf/1712.06760.pdf">CVPR2018Mining Point Cloud Local Structures by Kernel Correlation and Graph Pooling</a></li>
<li>   [3]<a href="https://arxiv.org/pdf/1811.11424.pdf">AAAI2019MeshNet: Mesh Neural Network for 3D Shape Representation</a></li>
<li>   [4]<a href="http://ivg.au.tsinghua.edu.cn/people/Yueqi_Duan/CVPR19_Structural%20Relational%20Reasoning%20of%20Point%20Clouds.pdf">CVPR2019Structural Relational Reasoning of Point Clouds</a></li>
<li>   [5]<a href="https://arxiv.org/pdf/1904.07601.pdf">CVPR2019Relation-Shape Convolutional Neural Network for Point Cloud Analysis</a></li>
</ul>
<h3 id="Dynamic-Graph-CNN-for-Learning-on-Point-Clouds"><a href="#Dynamic-Graph-CNN-for-Learning-on-Point-Clouds" class="headerlink" title="Dynamic Graph CNN for Learning on Point Clouds"></a>Dynamic Graph CNN for Learning on Point Clouds</h3><h4 id="Description"><a href="#Description" class="headerlink" title="Description:####"></a>Description:####</h4><p>作者认为<a href="">Pointnet</a>和<a href="">Pointnet++</a>均只是探究了点云局部的独立的，本身的几何结构（Pointnet尽管是将一个完整点云分割为若干子点云来分别计算几何结构，但其还是处于<strong>local sacle</strong>的程度），并没有得到自己与其他点，其他子点云之间的关系。作者利用图神经网络在处理不规则数据上的优势，在抽取<strong>点云</strong>中各个点之间的几何关系，从而弥补了之前方法的不足</p>
<p><img src="/images/paper/paperAna_3/DGCNN_overview.jpg"></p>
<h4 id="Contribution"><a href="#Contribution" class="headerlink" title="Contribution:####"></a>Contribution:####</h4><p>作者提出了一种可以在点云处理中使用的操作：EdgeConv。并且通过大量的实验证明了改操作可以更好的在提取点云局部几何特征的同时保持排列不变性。</p>
<h4 id="Method"><a href="#Method" class="headerlink" title="Method:####"></a>Method:####</h4><p>作者在relate work-&gt;Geometric Deep learning中提到<code>A key difficulty,however,is that the Laplacian eigenbasis is domain-dependent;thus, a filter learned on one shape may not generalize to others.</code> 就是对于图卷积网络来说，基于频域的卷积其泛化性不如在空域中的卷积。</p>
<p><img src="/images/paper/paperAna_3/EdgeConv.jpg"></p>
<ul>
<li>EdgeConv</li>
</ul>
<p>假设点云点数为N,同时每个点上的特征维度为F,那么就有$X &#x3D; {x_{1},…,x_{n}} \subseteq R^{F}$ 。对于每个点上的特征向量的计算，选取在特征空间上与<code>中心点</code>最近的K近邻点(k-nearest neighbor) 表示为$\mathcal G &#x3D; (\mathcal V, \varepsilon)$ 其中$\mathcal V&#x3D;{1,…,n }$代表点，$\varepsilon$表示<code>中心点</code>与其K近邻的边。那么<code>EdgeConv</code>的公式可以表示为：</p>
<p>$ x_{i}^{‘} &#x3D; \square h_{\theta} (x_{i},x_{j})$ &emsp;&emsp;$s.t. j:(i,j) \in \varepsilon$  $x_{i}$表示在i th点上的特征向量</p>
<p>其中$\square$ 代表channel-wise的对称aggregation操作，例如叠加或求最大值（to keep permutaion invariance)，<strong>每层EdgeConv对每个点$x_{i}$都会更新其特征向量<br>本文采用的<code>Max</code> Aggregation方法</strong></p>
<ul>
<li><p>Choice of $h_{\theta}$</p>
<ul>
<li>$h_{\theta}(x_{i},x_{j}) &#x3D; \theta_{j}x_{j}$ 这就相当于普通的CNN卷积了，$x_{i}$就相当于卷积核中间的那个点，$x_{j}$是其周围的点，$\theta$是可学习参数</li>
<li>$h_{\theta}(x_{i},x_{j}) &#x3D;h_{\theta}(x_{i})$ 这就是<code>Pointnet</code>的处理方式，只独立的考虑一个点</li>
<li>$h_{\theta}(x_{i},x_{j}) &#x3D;h_{\theta}(x_{i}-x_{j})$ 该方法作者认为只考虑了编码局部信息，失去了全局形状结构</li>
<li>$h_{\theta}(x_{i},x_{j}) &#x3D;h_{\theta}(x_{i},x_{i}-x_{j})$ 弥补了上一个方法的不足，也是本文所采取的方法</li>
</ul>
</li>
<li><p>Dynamic graph update</p>
</li>
</ul>
<p>在每一层EdgeConv之后，作者都会计算一个根据新得到的每个点的特征向量，计算一次KNN,并用这个新的KNN Graph来计算下一层的特征向量。</p>
<ul>
<li>Implementation</li>
</ul>
<p><img src="/images/paper/paperAna_3/DGCNN_Net_Arc.jpg"></p>
<p>注意EdgeConv层的维度</p>
<ul>
<li>Experiment</li>
</ul>
<p>首先当然是取得了state-of-art的成绩。有趣的，作者发现对于近邻K的选取，不是越大越好，对于不同的任务，都有一个峰值K使得效果最好，作者认为过大的K会使得欧式距离不能很好的估计测地距离（geodesic distace)会摧毁几何信息。同时作者发现K的选取跟点的密度有关</p>
<hr>
<h3 id="Mining-Point-Cloud-Local-Structures-by-Kernel-Correlation-and-Graph-Pooling"><a href="#Mining-Point-Cloud-Local-Structures-by-Kernel-Correlation-and-Graph-Pooling" class="headerlink" title="Mining Point Cloud Local Structures by Kernel Correlation and Graph Pooling"></a>Mining Point Cloud Local Structures by Kernel Correlation and Graph Pooling</h3><h4 id="Description-1"><a href="#Description-1" class="headerlink" title="Description:###"></a>Description:###</h4><p>这篇文章与[1]是同一时期的论文，但是在ModelNet40上的分类和ShapeNet上的分割都略微不如[1],但其思想是值得借鉴的。</p>
<p>作者利用在04年ECCV上的一篇关于<code>point cloud registration</code>工作上的技术<code>kernel Correlation</code>来对局部几何信息进行编码，可以理解为2D CNN中卷积核(kernel)的一种特殊的3D变种，其会对具有不同结构信息的点产生不同程度的响应(response)。同时作者也提出了一种利用K nearest neighbor graphs(KNNG)的新的特征聚合方法（feature aggregation)来利用高维结构特征推断集合信息。</p>
<h4 id="Contribution-1"><a href="#Contribution-1" class="headerlink" title="Contribution:####"></a>Contribution:####</h4><p>作者提出了借用<code>kernel correlation</code>的思想来简化求解local structural feature</p>
<h4 id="Method-1"><a href="#Method-1" class="headerlink" title="Method:####"></a>Method:####</h4><p><img src="/images/paper/paperAna_3/KCNet_arc.jpg"></p>
<ul>
<li><p>Local Geometric Properties</p>
<ul>
<li>Surface Normal: 作者在论文中提到可以用PCA求解的minimum variance direction作为局部的法向量，原话是:<code>surface normal can be estimated by principal component analysis on data covariance matrix of neighboring points as the minimum variance direction</code></li>
<li>Covariance Matrix(协方差矩阵): 作为二阶局部描述子，它能提供比normal更加多的信息量。但是作者认为<code>normal</code>与<code>Covariance Matrix</code>作为手工设定的特征，其描述局部结构特征的能力有限，因为不同形状的几何结构可能产生相似的<code>normal</code>或者<code>covariance matrix</code>，这就给后续工作带来巨大的噪音。</li>
<li>Kernel Correlation: <code>Kernel Correlation</code>可以帮助用来判断两个<code>Point cloud</code>之间的相似度（similarity)。在<code>point cloud registraion</code>当中，一个<code>point cloud</code>作为reference,另一个作为source。source要不断的进行刚性&#x2F;非刚性变换以使得<code>kernel correlation</code>的响应达到最大。也就是说，<strong>响应大的时候，两者的几何结构是非常相似的</strong>，那么这种性质就可以用来构造卷积核。</li>
</ul>
</li>
<li><p>Learning on Local Geometric Structure</p>
</li>
</ul>
<p><code>point cloud registration</code> 中的<code>kernel corelation</code>是固定一个template(reference),试图找到一个变换（transformation)使得source+transformation的结果与refrence的响应最大。而本文作者对此进行了改进，在整个训练过程中，template(reference）不再被固定，而是通过反传误差，不断学习到一个合适的reference(这里可以看成不断调整初始reference中点的位置），从而使reference与source的响应达到一个水准，这个水准能与网络其余结构一起产生预期的预测效果。论文原话是：</p>
<pre><code> Under this setting, the learning process can be viewed as finding a
 set of reference/template points encoding the most effective and
 useful local geometric structures that lead to the best learning 
 performance jointly with other parameters in the network.
</code></pre>
<p><code>kernel corelation</code>的计算公式：</p>
<p>$KC(\mathcal k,x_{i} ) &#x3D; \cfrac{1}{\mathcal N(i)}\sum\limits_{m&#x3D;1}^{M}\sum\limits_{n \in \mathcal N(i)}K_{\sigma}(\mathcal k_{m},x_{n}-x_{i}) \tag {1} $</p>
<p>$\mathcal k_{m}$表示kernel中的m个可学习的点，$\mathcal N(i)$ 表示anchor point $x_{i}$的周围K近邻，而$K_{\sigma}(*,*)$表示核函数，也就是公式$(2)$所示。公式$(1)$大体就是对于某个<code>corelation kernel</code>来说，其中每个点$\mathcal k_{m}$都会与$\mathcal N(i)$中包括的点一起作为公式$(1)$的输入，也就是会计算m*k次。<br>$K_{\sigma}(k,\delta) &#x3D; exp(-\cfrac{||k-\delta||^2}{2\delta^2}) \tag {2}$</p>
<p>分子表示欧式距离，分母$\delta$表示核的宽度，它控制点之间距离的影响（这里我也不是太懂）。文中的$\delta$被设置为<code>the average neighbor distance in the neighborhood graphs over all training point clouds</code>。</p>
<p>可以设置$L$个<code>kernel corelation</code>,这个$L$与卷积网络中的output channel类似。</p>
<ul>
<li>Learning on Local Feature Structure</li>
</ul>
<p>核心思想就是每个点预期近邻点的几何结构是一致，将各个点与其自身的近邻点做特征向量的aggregation有利于使得网络具有更好的效果和鲁棒性。作者采用了<code>average pooling</code>和<code>max pooling</code>， 其中<code>max pooling</code>为</p>
<p>$\mathcal Y(i,k) &#x3D; \max\limits_{n \in \mathcal N(i)} X(n,k) \tag{3}$ </p>
<p>k表示第i个点的特征向量的第k个维度，特征向量维度与<code>kernel corelation</code>的核数量一致</p>
<p><code>average pooling</code>为：<br>$Y&#x3D;D^{-1}WX \tag{4}$<br>$W$为邻接矩阵，$D$为度矩阵(degree matrix)</p>
<p>本文采用的是Max pooling作为Aggregation方法</p>
<ul>
<li>Experiment:</li>
</ul>
<p>作者通过Ablation study从<code>Effectiveness of Kernel Correlation</code>,<code>Symmetric Functions</code>,<code>Effectiveness of Local Structures</code>三个方面证明了本文所提方法的有效性：</p>
<p><img src="/images/paper/paperAna_3/KCnet_exp.jpg"></p>
<p>**但我觉得存在一个问题:**在<code>Effectiveness of Kernel Correlation</code>试验中，每个点的<code>Normal</code>是使用PCA方法求出的，然后再与坐标Catenate.那么所求的<code>Normal</code>与真实的值相差多少呢?这个误差是否会影响实验结果呢？如果改用更加准确的<code>Normal</code>求解方法，是否能提高，甚至超过<code>Kernel Correlation</code>方法呢？</p>
<h4 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion:####"></a>Conclusion:####</h4><p>这篇工作的根本目的在于探究一种较<code>PointNet++</code>更为简单的局部几何计算子，从而在节省算力的同时，还能提高准确度。但是其本质上是以一种更加简单的方式回答<strong>what type of the point</strong>，其没有解决点与点之间是什么关系，换句话说，<code>PointNet++</code>与<code>KC-Net</code>的本质与[1]中的<code>DG-CNN</code>是不同的，这可能也是造成他们效果差异的原因。</p>
<hr>
<h3 id="MeshNet-Mesh-Neural-Network-for-3D-Shape-Representation"><a href="#MeshNet-Mesh-Neural-Network-for-3D-Shape-Representation" class="headerlink" title="MeshNet: Mesh Neural Network for 3D Shape Representation"></a>MeshNet: Mesh Neural Network for 3D Shape Representation</h3><h4 id="Description-2"><a href="#Description-2" class="headerlink" title="Description:####"></a>Description:####</h4><p><img src="/images/paper/paperAna_3/MeshNet_Arc.jpg"></p>
<p>本文提出一种基于<strong>Mesh</strong>的3D shape特征抽取方法,直接将对于Mesh-based 3D shape的分类准确率从68.3%提升到91.9%。作者将单独的一个<code>Face</code>视为一个<code>Unit</code>,这样做可以消除Mesh固有的irregular，因为每一个face有且只有3个面与其相邻（作者这里用的是no more than，我认为不对)。其次，作者将一个Face的Feature分为<code>spatial feature</code>和<code>structural feature</code>,这样做有利于是Face Feature具有更加明确的指向性，使网络更容易学习到有用的Feature</p>
<h4 id="Method-2"><a href="#Method-2" class="headerlink" title="Method:####"></a>Method:####</h4><ul>
<li><p>Input:  作者将<code>Face-unit</code>进行了如下分解：</p>
<ul>
<li><p>Face Information:</p>
<ul>
<li>Center:coordinate of center point</li>
<li>Corner:<strong>vectors</strong> from the center point to three vertices</li>
<li>Normal: the unit normal vector</li>
</ul>
</li>
<li><p>Neighbor Information:</p>
<ul>
<li>Neighbor Index: indexes of the connected faces(filled with the index of itself if the face connects with less than three faces) 如果面片形成的是一个闭集，那么必然是一个面片有三个相邻面的</li>
</ul>
</li>
</ul>
</li>
<li><p>Spatial and Structural Descriptor</p>
</li>
</ul>
<p>spatial descriptor: 输入只是Center坐标，简单的经过MLP得到结果</p>
<p>Structural descriptor:face rotate convolution</p>
<p>![](&#x2F;images&#x2F;paper&#x2F;paperAna_3&#x2F;face_rotate convolution.jpg)</p>
<p>$g(\cfrac{1}{3}(f(v_{1},v_{2})+f(v_{2},v_{3})+f(v_{3},v_{1})) \tag{1}$</p>
<p>$f(*,*) : \mathbb R^3 * \mathbb R^3 \rightarrow \mathbb R^{K_1}$</p>
<p>$g(*,*) : \mathbb K^1 \rightarrow \mathbb K^2$可以是任何合法函数（大多都是MLP)</p>
<p>作者将这个操作类比到卷积操作，$f(*,*)$看作卷积核，每次对两个向量做卷积，然后用旋转代替平移，步长为1。$K_1$表示<code>output channel</code>。这个$\cfrac{1}{3}$可以当做对称函数(average pooling)用来消除disorder，保证了permutation invariance。</p>
<p>Structural descriptor: face kernel correlation:</p>
<p>作者利用[2]的<code>kernel corelation</code>将其改为针对<code>face-unit</code>的形式，利用面片的<code>normal</code>代替[2]中点的坐标。由于所有的<code>normal</code>都是单位向量所以作者用$(\theta,\phi)$ 来代替单位向量$(x,y,z)$ 所以有</p>
<p>$\begin{cases}<br>         &amp; x&#x3D;sin \theta cos \phi \\<br>         &amp; y&#x3D;sin \theta sin \phi \\<br>         &amp; z&#x3D;cos \phi \tag{2} \\<br>\end{cases}$</p>
<p>其中：$\theta \in [0,\pi], \phi \in [0,2\pi)$(其实就是仰角和旋转角)</p>
<p>$KC(\mathcal k,x_{i} ) &#x3D; \cfrac{1}{\mathcal |N(i)| \mathcal |M_k|)}\sum\limits_{n \in \mathcal N_i}\sum\limits_{m \in \mathcal M_k}K_{\sigma}(n,m) \tag {3} $</p>
<p>$K_{\sigma}(n,m) &#x3D; exp(-\cfrac{||n-m||^2}{2\delta^2}) \tag {4}$</p>
<p>这些都与[2]中的含义一致</p>
<ul>
<li>Mesh Convolution</li>
</ul>
<p><img src="/images/paper/paperAna_3/meshconv.jpg"></p>
<p>如图所示，作者将<code>spatial Feature</code>，<code>structral Feature</code>和<code>Neighbor Index</code>，作为输入送进<code>Combination</code>和<code>Aggregation</code>中，得到新的<code>spatial Feature</code>和<code>structral Feature</code>。 作者在文中提到，之所以不将<code>spatial Feature</code>一起送进<code>Aggregation</code>是因为不想让<code>structral Feature</code>受到点所在空间信息的影响，就如2维卷积的过程中，不会显示的告知卷积核该像素的绝对坐标一样。</p>
<p>图中标识了三种Aggregation方法：<code>Concatenation</code>,<code>Max pooling</code>和<code>Average pooling</code> 作者认为Average pooling是很多强响应被忽略了，从而损失了很多的有用信息。实验表明Concatenation效果最好。</p>
<p><img src="/images/paper/paperAna_3/meshnet_exp.jpg"></p>
<h4 id="Conclusion-1"><a href="#Conclusion-1" class="headerlink" title="Conclusion:####"></a>Conclusion:####</h4><ul>
<li>将Feature拆分为多个更加明确的子特征，可能有助于网络学习</li>
<li>本文有个缺点就是没有考虑显示的考虑面片之间的结构关系，每个面片的特征都只与其本身有关，但不排除在之后了MLP层之后学习到了。</li>
</ul>
<p><img src="/images/paper/paperAna_3/meshnet_exp2.jpg"></p>
<p>结果显示在移除了MeshConv之后，准确度下降的比重不是最大的</p>
<hr>
<h3 id="Structural-Relational-Reasoning-of-Point-Clouds"><a href="#Structural-Relational-Reasoning-of-Point-Clouds" class="headerlink" title="Structural Relational Reasoning of Point Clouds"></a>Structural Relational Reasoning of Point Clouds</h3><h4 id="Description-3"><a href="#Description-3" class="headerlink" title="Description####"></a>Description####</h4><p>作者首先阐述了<code>Pointnet++</code>的缺点，与[1]中提到的一致–只是探究了局部的结构特征，没有探究这些局部之间的结构也就是依赖关系。但是与[1]不同的是，本文所提出的<code>structural relation network(SRN)</code>探究的是局部与局部的依赖关系(structural<br>dependencies of local regions)，而[1]是以点为单位的。作者以人类识别物体为例，认为对物体局部之间关系的认知对于理解物体本身具有很大作用</p>
<h4 id="Method-3"><a href="#Method-3" class="headerlink" title="Method####"></a>Method####</h4><p><img src="/images/paper/paperAna_3/SRN.jpg"></p>
<p>$P_i$代表子点云,$u_i \in \mathbb R^d$代表该子点云的局部几何特征，$v_i \in \mathbb R^3$表示该子点云的平均位置用来表示位置信息。作者认为$u_i$对发现重复的局部模式(repetitive local patterns)有帮助，而$u_i$对发现各个局部之间的连接关系(linkage relations)起到关键作用。所有$P_i$的结构关系特征表示为：</p>
<p>$y_i &#x3D; f(\sum \limits_{\forall j}h(g_u(u_i,u_j),g_v(v_i,v_j)) \tag{1}$</p>
<p>$j$表示除了$i$以外的所有子点云。<strong>在实现方面，$g_u(·，·),g_v(·，·)$都是由多层感知机(MLP)实现,$f(·，·),h(·，·)$都是由1 $\times$ 1卷积实现</strong>。由上面那张图可以看出每个$u_i$都会与其他的所有$u_j$做一次concatenating操作（应该是在channel维度进行拼接）</p>
<p><img src="/images/paper/paperAna_3/srn_arc.jpg"></p>
<p><strong>注意到标黄部分，采用了不同比例的局部特征</strong>,作者认为<code>SRN</code>对于不同的子点云获取方法都是鲁棒的。同时红框表示文中提到的<code>residual connection</code>$y$是作为对$u$的补充(complement)</p>
<h4 id="Experiment"><a href="#Experiment" class="headerlink" title="Experiment####"></a>Experiment####</h4><p>为了证明<code>SRN</code>对3D Shape的局部关系学习具有很好的泛化性，作者在<code>ModelNet40（3D objects)</code>和<code>Scannet(indoor scenes)</code>上做了跨库实验</p>
<p><img src="/images/paper/paperAna_3/srn_exp.jpg"></p>
<p>作者提取分布在两个库上训练的网络所产生的特征向量(feature)之后用线性SVM做分类</p>
<p><img src="/images/paper/paperAna_3/srn_exp2.jpg"></p>
<p>作者为了进一步阐述<code>SRN</code>对特征提取的帮助，利用<code>t-SNE</code>(一种对高维数据降维可视化的方法）将所提取的特征进行可视化。发现大多数类别的类间差异都很小。</p>
<hr>
<h3 id="Relation-Shape-Convolutional-Neural-Network-for-Point-Cloud-Analysis"><a href="#Relation-Shape-Convolutional-Neural-Network-for-Point-Cloud-Analysis" class="headerlink" title="Relation-Shape Convolutional Neural Network for Point Cloud Analysis"></a>Relation-Shape Convolutional Neural Network for Point Cloud Analysis</h3><h4 id="Description-4"><a href="#Description-4" class="headerlink" title="Description:####"></a>Description:####</h4><p>作者依旧是从探究点与点之间的关系来入手，作者认为从点学习特征具有三点挑战：</p>
<ul>
<li>需要具备排列不变性(permutation invariant)</li>
<li>对于刚性形变鲁棒，也就是即使点的绝对位置发生改变，只要其结构未变，其特征应该是一致的</li>
<li>效果好</li>
</ul>
<h4 id="Method-4"><a href="#Method-4" class="headerlink" title="Method####"></a>Method####</h4><p><img src="/images/paper/paperAna_3/RS_CNN.jpg"></p>
<p>$x_i$表示采样点,$x_j \in \mathcal N(x_i)$表示周围邻域点，则该$x_i$上的特征向量$f_{P_{sub}}$可以用来表示这个邻域的结构</p>
<p>$f_{P_{sub}} &#x3D; \sigma(\mathcal A(\lbrace \tau(f_{x_j}), \forall x_j \rbrace)), d_{ij} &lt;r  \forall x_j \in \mathcal N(x_i) \tag{1}$ </p>
<p>$\tau(f_{x_j}) &#x3D; w_{ij} · f_{x_j} &#x3D; \mathcal M(h_{ij} · f_{x_j}) \tag{2}$</p>
<p>$d_{ij}$是$x_i,x_j$之间的欧式距离。对于上面这个公式，论文的解释是:<em>Here $f_{P_{sub}}$ is obtained by first transforming the features of all the points in $\mathcal N(i)$ with function $\tau$ , and then aggregating them with function $\mathcal A$ followed by a nonlinear activator $\sigma$.</em></p>
<p>公式(1)相对于论文[1]多了一个$\tau$函数，其余操作一致，$\mathcal A$也是<code>max pooling</code> $\mathcal M$为<strong>三</strong>层<code>MLP</code>作者之后在试验中证明了3层是较好的选择</p>
<h5 id="Conclusion-2"><a href="#Conclusion-2" class="headerlink" title="Conclusion####"></a>Conclusion####</h5><p>这篇文章是被录用为CVPR2019的oral.但是其最核心的思想我认为跟[1]是差不多的，作者在文中也用一句话评价了两者的区别<code>DGCNN captures similar local shapes by learning point relation in a high-dimensional feature space, yet this relation could be unreliable in some cases.</code> 我刚看到简直吐血，真·不要碧莲。我认为之所以能被接受为oral原因如下：</p>
<ul>
<li>优秀的写作，论文从问题到解决办法的提出一气呵成，非常漂亮，很多地方的写作技巧都很微妙，比如上面这句。</li>
<li>实验做得很充分，几乎论证了所有文中提出的tricks。同时效果确实有不小的提升。</li>
<li>具体用到的tricks如下：<ul>
<li>利用了<code>hierarchical architecture</code>,在相同的权重下，对不同数量的neighborhoods进行学习，这与[4]是一致的，但文中没有提出这点</li>
<li>$\tau$函数的提出，新学习到的特征向量与老的特征向量做一次点乘,这与<a href="https://arxiv.org/pdf/1901.11461.pdf">ICML2019GEOMetrics: Exploiting Geometric Structure for Graph-Encoded Objects</a>类似。</li>
<li>相对[1]对每个点求其邻域的特征向量，本文对每个选取的领域求特征</li>
<li>论文采取的对邻域的选取方法也与其他不相同<img src="/images/paper/paperAna_3/rscnn_exp1.jpg">可以看到，在scale&#x3D;1的情况下，用<code>K-NN</code>选取邻域只有90.5%的准确率，而转为<code>random-PIB</code>之后就提升到了92.2%，这与<code>DGCNN</code>对每个点都求一个结构特征所得到的准确率是一致，但计算量却大大减少了</li>
</ul>
</li>
</ul>
<p>很可惜，对于核心方法的修改，作者没有给出消融实验的结果，不能看出新增的$\tau$函数对效果的提升有什么帮助。同时对于输入<code>h</code>是否会变也没有给出明确的说明，就符号一致性来说，是不会改变的,[1]中是会改变的</p>
]]></content>
      <categories>
        <category>论文阅读</category>
        <category>特征抽取</category>
      </categories>
      <tags>
        <tag>点云</tag>
        <tag>网格</tag>
      </tags>
  </entry>
  <entry>
    <title>&lt;论文阅读&gt;(八)Occupancy Networks Learning 3D Reconstruction in Function Sapce</title>
    <url>/2019/12/21/b040bbb5/</url>
    <content><![CDATA[<h2 id="Occupancy-Networks-Learning-3D-Reconstruction-in-Function-Sapce"><a href="#Occupancy-Networks-Learning-3D-Reconstruction-in-Function-Sapce" class="headerlink" title="&lt;论文阅读&gt;Occupancy Networks: Learning 3D Reconstruction in Function Sapce"></a>&lt;论文阅读&gt;Occupancy Networks: Learning 3D Reconstruction in Function Sapce</h2><p><a href="https://arxiv.org/pdf/1812.03828.pdf">论文链接</a></p>
<p><a href="https://github.com/autonomousvision/occupancy_networks">github</a></p>
<h3 id="Contribution"><a href="#Contribution" class="headerlink" title="Contribution###"></a>Contribution###</h3><ul>
<li>作者在文中提出了一种新的3D表征方法，并证明了该表征方法可以用于高效的三维重建工作。</li>
<li>作者提出了Multiresolution IsoSurface Extraction (MISE)用以从函数空间中恢复高精度的三维模型以较低的计算代价。</li>
</ul>
<h3 id="Backgroud"><a href="#Backgroud" class="headerlink" title="Backgroud###"></a>Backgroud###</h3><p>作者认为主流的3D表征方法有着一下的不足：</p>
<h4 id="Voxel"><a href="#Voxel" class="headerlink" title="Voxel###"></a>Voxel###</h4><p>Voxel是用规则的立方体来表示三维形状的。若想要提高Voxel的精度，所耗费的计算量是以三次方速度增长的，尽管有像Octree这种方法来减少计算量，但精度还是限制了$256^3$上边。</p>
<h4 id="Point-Cloud"><a href="#Point-Cloud" class="headerlink" title="Point Cloud####"></a>Point Cloud####</h4><p>利用点来表示三维形状，与Voxel相比可以大幅度提高精度。但是由于缺少点与点之间的连接关系，就看上去就没有那么的直观。同时缩放性也较差。</p>
<h4 id="Mesh"><a href="#Mesh" class="headerlink" title="Mesh###"></a>Mesh###</h4><p>通过增加点与点之间的连接关系，弥补了点云的不足。但是其拓扑结构不能改变，而如今基于Mesh表示三维重建工作，都是通过预测一个初始形状的deformation来进行三维重建，这就使得所预测的三维形状必须具有相同的拓扑结构（比方说一个空心圆圈和一个实心圆饼的拓扑结构就不一致）</p>
<h3 id="Method"><a href="#Method" class="headerlink" title="Method"></a>Method</h3><p>网络通过输入一个$p(x,y,z) \in \mathbb R^3$和一张图片或者点云或者体素$x \in \cal X$得到$p$点是否在物体内部的一个概率值<code>probability of occupancy</code>。</p>
<p>对于不同的类型的输入，作者使用不同的编码器来编码特征。</p>
<ul>
<li>图片 -&gt; Resnet 18</li>
<li>点云 -&gt; PointNet encoder</li>
<li>体素 -&gt; 3D convolutional neural network</li>
</ul>
<p>$f_{\theta}: \mathbb R^3 \times \cal X \rightarrow [0,1] \tag{1}$</p>
<p>从作者开源的代码来看，网络的<a href="https://github.com/autonomousvision/occupancy_networks/blob/master/im2mesh/onet/models/decoder.py#L45">decoder</a>是一个输出维度为1的全连接层，我们将这个输出记为<code>logits</code>。在计算loss的时候，这个<code>logits</code>就与真实的<code>occupancy value</code>进行比较。</p>
<p>但是在评测IoU或者进行可视化的时候，就要用<code>sigmoid(logits)</code>来求得一个介于[0,1]之间的概率值，最后利用marching cubes进行可视化。</p>
<p>损失函数的定义也十分简单，就是一个交叉熵函数:</p>
<p>$\cal L_{\cal B}(\theta) &#x3D; \frac{1}{|\cal B|}\sum\limits^{|\cal B|}\limits_{i&#x3D;1}\sum\limits^{K}\limits_{j&#x3D;1}\cal L(f_{\theta}(p_{ij},x_{i}),o_{ij}) \tag{2}$</p>
<p>其中$o_{ij}$表示真实的<code>occupancy value</code></p>
<h3 id="Occupancy-Network-Architecture"><a href="#Occupancy-Network-Architecture" class="headerlink" title="Occupancy Network Architecture"></a>Occupancy Network Architecture</h3><p><img src="/images/paper/onet/architecture.jpg"></p>
<p>作者没有直接将encoder出来的特征向量<code>c</code>与输入的三维(x,y,z)坐标进行concat然后直接送入MLP进行映射，而是通过<code>c</code>来计算出batchnorm是denormalization所需要的<code>scale</code>和<code>bias</code>，以这种方式来影响最后<code>pred-occupancy value</code>的预测。作者在试验中也给出是否使用Conditional batch normalization的对比结果。</p>
<h3 id="KL散度"><a href="#KL散度" class="headerlink" title="KL散度###"></a>KL散度###</h3><p>作者在文中提到:</p>
<blockquote>
<p>Our 3D representation can also be used for learning probabilistic latent variable models</p>
</blockquote>
<p>作者首先利用两个<a href="https://github.com/autonomousvision/occupancy_networks/blob/master/im2mesh/onet/models/encoder_latent.py">全连接</a>来回归<code>mean</code>和<code>log(std)</code>（回归$\log(std)$是为了防止std为非正数）。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mean, logstd = encoder_latent(p, occ, c)</span><br><span class="line">   # q_z 是一个正态分布</span><br><span class="line">   q_z = dist.Normal(mean, torch.exp(logstd))</span><br><span class="line">   # 随机采样一个z</span><br><span class="line">   z = q_z.rsample()</span><br><span class="line">   # 计算kl散度，使得编码mean, logstd的编码器尽量靠近正态分布，以保证张成空间的</span><br><span class="line">   # 多样性。假设不加这个散度，为了让decoder每次生成的形状越来越好，那么每次送入</span><br><span class="line">   # 的值都最好一致，那么logstd会逐渐变得很小，使得分布的标准差很小接近0。这样每</span><br><span class="line">   # 次采样的结果z都近乎一致， 使得latent space并不能真的代表潜在空间。</span><br><span class="line">   kl = dist.kl_divergence(q_z, p0_z).sum(dim=-1)</span><br><span class="line">   </span><br><span class="line">   # logits即为网络最终预测值，要与真实occupancy value进行比较。</span><br><span class="line">   # 评估重建效果时，将sigmoid(logits)送入marching cubes进行重建 </span><br><span class="line">   logits = decode(p, z, c)</span><br></pre></td></tr></table></figure>

<p>由以上代码可知，最终重建的结果收到两个输入的影响,<code>z</code> 和 <code>c</code>。其中<code>z</code>是从表示<code>c</code>的分布中采样得到的，可以控制一定的形变。</p>
<p><img src="/images/paper/onet/latent_space.jpg"></p>
<p>可以看到，通过改变采样的<code>z</code>可以得到不同的形状。</p>
<h3 id="Multiresolution-IsoSurface-Extraction-MISE"><a href="#Multiresolution-IsoSurface-Extraction-MISE" class="headerlink" title="Multiresolution IsoSurface Extraction (MISE)"></a>Multiresolution IsoSurface Extraction (MISE)</h3><p>假如我们已经学习到了一个函数空间$f_{\theta}$, 最直接的方式的采样的到具有$256^3$个点的grid, 然后得到每个点的<code>pre-occupancy value</code>，然后送入marching cube进行重建，但是这样大大限制了重建的精度。感觉上作者是借鉴的<code>Octree</code>的思想，逐步求解，最后达到预定分辨率。</p>
<p><img src="/images/paper/onet/mise.jpg"><img src="/images/paper/onet/mise_capture.jpg"></p>
<h3 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments###"></a>Experiments###</h3><h4 id="Upper-bound"><a href="#Upper-bound" class="headerlink" title="Upper bound"></a>Upper bound</h4><p>作者首先评估了在函数空间中表示一个三维物体的可能性和其准确值，该准确值可以作为一个upper-bound来比较接下来的实验结果。由于是找到一个upper-bound，所以这个实验的训练个测试都是在训练集上进行的。实验步骤如下：</p>
<p>一： 将训练集中的所有图片（4746张）映射为一个长度为512维的特征向量，表征为latent space中的一个点，在训练过程中，图片-&gt;特征向量的映射关系保持不变。<br>二： 用一个decoder将512维的特征向量转换为一个1维的<code>pred-occupancy value</code>, 然后进行重建。</p>
<p><img src="/images/paper/onet/exp1.jpg"></p>
<p>可以看到，本文所提出的表征方法，其重建精读（IoU）并不会随着分辨率的提高有太大的波动，始终保持在一个很高的水平(0.89)。同时，其网络参数也不会发生变化。反观基于Voxel的方法，虽然重建精度随着分辨率的提高有较大提升，但是其网络参数的增加量却是cubic。</p>
<h4 id="Completion-and-Super-Resolution"><a href="#Completion-and-Super-Resolution" class="headerlink" title="Completion and Super-Resolution"></a>Completion and Super-Resolution</h4><p>正如前面提到的，网络Encoder的输入并不一定要是图片，还可以体素(Voxel), 点云(point cloud)。除了对图片所进行的单图重建任务（有3D监督）外，还对点云的补全和体素的超分都做了相应的实验。</p>
<h4 id="Ablation-Study"><a href="#Ablation-Study" class="headerlink" title="Ablation Study"></a>Ablation Study</h4><p><img src="/images/paper/onet/Ablation.jpg"></p>
<p>这里我们更关心的是第三行<code>No CBN</code>的对比结果。如果不使用<code>Conditional Batch Normalization</code>可以看到结果下降了比较大的幅度。具体到结构上的改变是，对于BN, 作者先是用一个全连接将输入的特征向量<code>c</code>映射为一个定好的长度(设为F1), 接着作者将待预测的点p(x,y,z)映射为相同的长度(F1) 然后两者相加后，在送入一维卷积+BN， 最后得到<code>pred-occupancy value</code>。</p>
<h3 id="疑问"><a href="#疑问" class="headerlink" title="疑问###"></a>疑问###</h3><p><strong>Q</strong>:真实的<code>occupancy value</code>是如何取得的，在<a href="https://github.com/autonomousvision/occupancy_networks/blob/master/im2mesh/onet/training.py">源码1</a>和<a href="https://github.com/autonomousvision/occupancy_networks/blob/master/im2mesh/onet/training.py#L168">源码2</a>可以看到评估和计算loss用到的网络输入确实是差一个<code>sigmoid</code>函数。但是真实的<code>occ</code>是如果求解的？</p>
<p><strong>A</strong>: 在<a href="">补充材料</a>中，作者表示一个点真实的<code>occupancy value</code>的获取与其穿越的面片数有关。具体来讲，做一条与z轴平行且以p点为起点的直线，记为A, 若A穿过的面片数为偶数，则其在物体外部。反之，若A穿过面片数位奇数，则其在物体内部。</p>
<p><strong>Q</strong> 论文中提到点的法向量可以通过求导得到，如何操作？</p>
<blockquote>
<p>In addition, our approach also allows to efficiently extract normals for all vertices of our output mesh by simply backpropagating through the occupancy network.</p>
</blockquote>
<p><strong>Q</strong> 其实对于特征融合，像作者在Ablation Study这样，将两个没有很强关联的特征直接进行相加，然后卷积得到结果的情况是比较少见的。更多的是特征之间的Concat, 或者像<a href="https://arxiv.org/abs/1901.11461">GEOMetrics</a>这篇文章一样，保留一部分。比较失望作者没有考虑到这个很明显的问题。</p>
]]></content>
      <categories>
        <category>论文阅读</category>
        <category>刚性物体重建</category>
      </categories>
      <tags>
        <tag>Marching Cubes</tag>
        <tag>函数空间</tag>
        <tag>KL散度</tag>
      </tags>
  </entry>
  <entry>
    <title>&lt;论文阅读&gt;(六)Three-D Safari Learning to Estimate Zebra Pose, Shape, and Texture From Images “In the Wild”</title>
    <url>/2019/08/23/8f9285bb/</url>
    <content><![CDATA[<h2 id="六-Three-D-Safari-Learning-to-Estimate-Zebra-Pose-Shape-and-Texture-from-Images-“In-the-Wild”"><a href="#六-Three-D-Safari-Learning-to-Estimate-Zebra-Pose-Shape-and-Texture-from-Images-“In-the-Wild”" class="headerlink" title="&lt;论文阅读&gt;(六)Three-D Safari: Learning to Estimate Zebra Pose, Shape, and Texture from Images “In the Wild”"></a>&lt;论文阅读&gt;(六)Three-D Safari: Learning to Estimate Zebra Pose, Shape, and Texture from Images “In the Wild”</h2><p><a href="https://128.84.21.199/pdf/1908.07201.pdf">论文链接</a></p>
<p><a href="https://github.com/silviazuffi/smalst">Github</a></p>
<h3 id="Contribution"><a href="#Contribution" class="headerlink" title="Contribution###"></a>Contribution###</h3><ul>
<li>提出了一个基于已有统计模型的，构造合成数据集的方法</li>
<li>针对四足动物有更复杂的形状问题，改进了已有纹理预测的方法</li>
<li>为了进一步对不同实例的改进，提出了<code>per-instance optimization</code></li>
</ul>
<h3 id="Method"><a href="#Method" class="headerlink" title="Method"></a>Method</h3><p><img src="/images/paper/smalst/net.jpg"></p>
<ul>
<li>Net Architecture</li>
</ul>
<p>输入图片经过Encoder(主要是ResNet-18)，输出为一个特征向量，接着送入三个分支网络。由于网络最后会生成一个一个<code>full texture map</code>，作者基于此对于每个实例做了进一步优化（<code>per-instance optimization</code>）。</p>
<ul>
<li>digital dataset</li>
</ul>
<p>这篇论文是基于作者之前的两篇工作<code>SMAL</code>和<code>SMALR</code>。其中前者是利用一组动物玩具扫描进行统计建模得到一个统计模型，也就是上图的<code>SMAL horse template</code>。之后在根据一系列优化函数进行给定输入图像的优化，三维模型可以建模为：</p>
<p>$v &#x3D; M(\beta,\theta,\gamma) \tag{1}$</p>
<p>$v_{shape}(\beta) &#x3D; v_{horse} + B_s\beta \tag{2}$</p>
<p>其中$\beta$为一组基$B_s$的系数，表示为动物形状，$\theta$为pose参数，$\gamma$为相机参数。后者较于前者，输入由单张图片变为对于同一个动物的（可以是）不同相机角度，不同姿态的若干张图片。作者首先利用<code>SMAL</code>对输入的多张图片进行拟合，得到对应的三维模型$v_i &#x3D; M(\hat \beta_i,\hat \theta_i , \hat \gamma_i)$。由于不同照片所对应的是同一动物，所有用以描述形状的$\hat \beta_i$应该是一致的，所以可以任选一个。接着，作者对上面所获得的三维模型进行进一步的优化，以期获得待重建动物独有的形状特征，例如犀牛的角。</p>
<p>$v_{shape}(dv^{SMALR}) &#x3D; v_{horse} + B_s \hat \beta + dv^{SMALR} \tag{3}$</p>
<p>其中$dv^{SAMLR}$就可以看作待重建动物独有的形状特征。</p>
<p>作者利用有限的，真实的动物图片，通过<code>SMALR</code>合成了10个不同的三维模型。然后这个10个不同的模型，再加以不同的，合理的相机参数$\gamma$，pose参数$\theta$，形状参数$\beta$,然后投影在不同的二维背景上，以获得合成数据。这些数据用来作为网络的训练集，而测试集和验证集均为真实的图片。因此，对于每一组训练数据，都包含了：1、一张RGB图片，2、Texture map $T_{gt}$，3、texture uv-flow $uv_{gt}$4、剪影(sihouette) $\mathcal S_{gt}$，5 、pose参数 $\theta_{gt}$，6、相机参数 $\gamma_{gt}$，7、形状参数 $\beta_{gt}$，8、vertex displacements $dv_{gt}^{SMALR}$，9、特征点 $K_{2D,gt}$。为了更好的预测作者将9和7结合在一起得到10、$dv_{gt} &#x3D; B_s\beta_{gt} + dv_{gt}^{SMALR}$</p>
<ul>
<li>uv-flow predictor</li>
</ul>
<p><img src="/images/paper/smalst/texture.jpg"></p>
<p>大体思路与<a href="https://hideoninternet.github.io/2019/03/08/ed6ad9d5/">CMR</a>一致，不同的是，作者认为，由于四足动物有着更大的articulated model,导致了在空间上具有不连续性（我估计可能是四肢之间具有较大空当的意思）。这就是个原本的纹理预测方法效果较差。作者的方法就是将其分成四个子块，同四个不同的编码，解码器来预测。但具体是如何做的，不清楚。</p>
<p>或者换种角度看待，这个问题.<a href="https://hideoninternet.github.io/2019/03/08/ed6ad9d5/">CMR</a> 中初始模型是由一个单位球体得来的，这使得从中心到各个点的连线上不会存在第三个点。而对与这个工作中的统计模型，即使把点单位化，从中心到各个点的连线上也可能会存在第三个点，从而导致UV展开后的坐标一致，不利于网络预测。</p>
<ul>
<li>shape prediction</li>
</ul>
<p>$dv &#x3D; Wf_s + b \tag{4}$</p>
<p>其中$b$是偏置项，$W$被初始化为<code>SMAL</code>的$B_s$，为了获得更好的三维模型，$B_s$会随着迭代进行优化。</p>
<p>$L_{train} &#x3D; L_{mask}(S_{gt},S) + L_{kp2D}(K_{2D,gt},K_{2D}) + L_{cam}(f_{gt},f)+L_{img}(I{input},I,S_{gt})+L_{pose}(\theta_{gt},\theta)+L_{trans}(\gamma_{gt},\gamma)+L_{shape}(dv_{gt},dv)+L_{uv}(uv_{gt},uv)+L_{tex}(T_{gt},T)+L_{dt}(uv,S_{gt}) \tag{6}$</p>
<ul>
<li>per-instance optimization</li>
</ul>
<blockquote>
<p>Given an input image, we run the regression network and then perform a per-instance optimization where we keep the network layers fixed and optimize over the feature space variables. In this way we eploit the correlation between variables learned by the network.</p>
</blockquote>
<p>由于不是很确定这个方法是如何对特征空间进行优化的和优化的先后顺序是怎样的，所以就不下结论了，等开源之后，再补回来。这里就记录一下关于这个方法的一些<strong>可能</strong>的意义。</p>
<p>网络的输入为<code>input image</code>,将其输出的三维模型投影回二维平面的图片记为<code>prediction</code>(与网络结构图一致)。作者的意思就是将<code>prediction</code>加上具有一定意义的<code>background</code>之后（记为<code>back-prediction</code>），再跟<code>input image</code>进行比较。其中优化函数就包括了<code>perceptual loss</code>。</p>
<ul>
<li>per-instance optimization有何用</li>
</ul>
<p>由于<code>Encoder</code>所编码的<code>features</code>包含了很多的噪声，而这些噪声会干扰接下来三个分支网络的结果预测。如果去除这些噪声，毫无疑问，会有利于参数的预测。我们可以将一幅图片分为前景和背景两个部分,从而可以将<code>perceptual loss</code>的评价方法分为前景损失和背景损失两种。在<code>per-instance optimization</code>中，由于网络所有层的参数都是固定的，导致了<code>back-prediction</code>和<code>input image</code>的背景都是一致的，那么为了降低损失，网络就势必要尽可能提高两者在前景上的相似度，从而就去除了<code>features</code>中的噪音。</p>
<ul>
<li>为什么要加background model</li>
</ul>
<p>文中说的很清楚，如果在不加background model，那么在测试时，就要求输入图片一定具有所对应的剪影，否者单单有<code>prediction</code>是没法跟<code>input image</code>进行<code>peceptual loss</code>上的比较。而background model,如文中所提，就是预测一个平均的背景像素值，来代替真实的背景值。文中提到这个模型使用构造<code>SMALR</code>模型所用的图片来训练的</p>
<ul>
<li>为什么需要预测背景的平均值</li>
</ul>
<p>尽管这是一个说服力很弱的猜想，但是记录一下。</p>
<p><img src="/images/paper/smalst/back_model_label.png"></p>
<p>横轴可以看作难易度，纵轴可以看作背景的相似度。back-model的作用就可以看作为左侧橙色的线，而要预测剪影的话，就可以看作右侧黄色的线。尽管back-model的效果较弱，但其所需的成本较剪影预测要少很多，同时获得的效果也可以达到预期的效果。</p>
<h3 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h3>]]></content>
      <categories>
        <category>论文阅读</category>
        <category>三维动物重建</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>SMAL</tag>
      </tags>
  </entry>
  <entry>
    <title>&lt;论文阅读&gt;(四)Canonical Surface Mapping via Geometric Cycle Consistency</title>
    <url>/2019/08/09/6021dd11/</url>
    <content><![CDATA[<h2 id="Canonical-Surface-Mapping-via-Geometric-Cycle-Consistency"><a href="#Canonical-Surface-Mapping-via-Geometric-Cycle-Consistency" class="headerlink" title="&lt;论文阅读&gt;Canonical Surface Mapping via Geometric Cycle Consistency"></a>&lt;论文阅读&gt;Canonical Surface Mapping via Geometric Cycle Consistency</h2><p><img src="/images/paper/CSM/example.jpg"></p>
<p><a href="https://arxiv.org/abs/1907.10043"><strong>论文链接</strong></a></p>
<p><a href="https://github.com/nileshkulkarni/csm"><strong>Github链接</strong></a></p>
<h3 id="Contribution"><a href="#Contribution" class="headerlink" title="Contribution"></a>Contribution</h3><ul>
<li>利用三维Template做为中介，弱化了实现稠密的，准确的多张图片对其所需的监督条件。</li>
<li>已有的图片到图片，图片到三维模型的映射关系的形成工作，不外乎依赖于人工手动标记对应点或者按照某些形变规则，将形变施加于图片A获得图片B,从而获得了A,B之间的对应关系。这些方法对于光照，角度等变量的鲁棒性较弱。</li>
</ul>
<h3 id="Method"><a href="#Method" class="headerlink" title="Method"></a>Method</h3><ul>
<li>Preliminaries</li>
</ul>
<p>作者利用两个参数将三维template平面化，$\overrightarrow u(u,v)$ 其中$u \in (0,1) v \in (0,1)$ 并且定义$ \phi(\overrightarrow u) $为恢复三维$(x,y,z)$的操作。<br>作者定义$\mathcal C \equiv f_\theta(I)$ 其中$f_\theta(I)$表示网络参数，作者将网络的预测行为抽象定义为$\mathcal C$</p>
<ul>
<li>Geometric Cycle Consistency Loss</li>
</ul>
<p>$ \mathcal L_{cyc} &#x3D; \sum_{p\in I_f} ||\overline p - p ||_{2}^{2} \quad;\quad \overline p &#x3D; \pi(\phi(\mathcal {C}[p])) \tag{1}$</p>
<p>上面这个就是作者提出的一致性Loss,很好理解，就是像素$p$先经过网络映射在三维template上，接着投影回原图，两者之间的距离要尽可能小</p>
<ul>
<li>Incorporating Visibility Constraints</li>
</ul>
<p>由于相机视角的原因，任何物体都会存在一个自遮挡的问题，而这个问题在预测图片稠密映射时就会产生一定的干扰。比方说，从正面看过去，一只鸟类的喙很有可能与其尾巴处于一条线上，所以当投影至二维像平面式，尾巴上某点就会被喙给遮挡。在这种情况下，如果映射关系预测网络将图片上的喙映射在三维template的尾巴上，最后投影回像平面计算$\mathcal L_{cyc} $的时候，依旧Loss会很小。所以作者就提出了：</p>
<p>$\mathcal L_{vis} &#x3D; \sum_{p \in I_f}max(0,z_p - D_{\pi}[\overline p]) \tag{2}$</p>
<p>其中$D_{\pi}[\overline p]$是三维template在对应相机参数下的深度图。</p>
<ul>
<li>Mask Re-projection Loss &amp; Multi-Hypothesis Pose Prediction</li>
</ul>
<p>作者为了彻底摆脱对基准相机参数的需求，又新增了一个网络$g_{\theta^{‘}}$ 这个网络是用来预测相机，并且为了避免<code>局部最小解(local minima)</code>，作者利用预测多个相机参数来达到这个目的。最后，作者使用一个约束来指导相机参数$\pi$的预测</p>
<p>$ \mathcal L_{mask} &#x3D; ||f_{render}(S,\pi) - I_f||^2 \tag{3}$</p>
<p>其中$f_{render}$是在预测相机参数下，三维template投影至二维的Mask。 正如上面提到，作者会一次性预测多个相机参数，所以有${ (\pi_i,c_i)} \equiv g_{\theta’}(I) \quad i&#x3D;1..8 $,其中$c_{i}$表示每个预测结果的概率是多少 。</p>
<p>最后，总的约束函数为：<br>$\mathcal L_{tot} &#x3D; \mathcal L_{div}(g_{\theta’}(I)) + \sum_{i&#x3D;1}^{N_c}c_i(\mathcal L_{cyc}^i + \mathcal L_{vis}^i + \mathcal L_{mask}^i) \tag{4}$</p>
<p><img src="/images/paper/CSM/net.jpg"></p>
<p>网络结构如图所示，对于2D-3D的映射关系预测，作者是利用一个U-Net结构（红色标注），输出为$B*4*H*W$的特征图，其中<code>[:,:3,:,:]</code>表示的是预测的三维坐标。<code>[:,3,:,:]</code>表示的是预测的<code>mask</code>。$H,W$分布代表输入图像的长和宽。$g_{\theta’}$表示相机参数预测网络，具体上，作者首先用<code>ResNet18</code>提取图片特征，接着送入<code>FC</code>层预测相关相机参数。作者在相机参数的预测网络上，有很多设定还是十分有趣的，有兴趣可以找来看下。</p>
<ul>
<li>大致映射</li>
</ul>
<p>之所以论文里提到<code>approximate</code>这个词呢，是因为，从代码上来看，$f_{\theta’}$的输出$B<em>H</em>W*4$中关于<code>2D pixel to 3D vertex</code>的映射并不一定是在template mesh上，对于网络输出的一对UV坐标(u,v)，作者首先是找到离这对坐标最近的面片是哪一个，接着计算该点关于这个面片的重心坐标(barycentric coordinate),最后根据重心坐标和面片三个顶点的位置坐标，得到最终的3D坐标，同时也确保了这个坐标在template mesh上。可以想象一个四面体（A-BCD），网络预测的3D坐标可能是A点，那么作者就是找到A点在BCD上的对应点。</p>
<h3 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h3><p><img src="/images/paper/CSM/exp1.jpg"><br><img src="/images/paper/CSM/exp2.jpg"></p>
<p>咋一看结果挺好，但是不知道作者为什么没有把CMR带基准相机参数的评测结果放出来，从消融实验的结果来看，在不利用预测相机参数的情况下，CSM结果并没有比不使用预测相机参数的CMR好太多，甚至在<code>cars</code>类别上的评分还低些</p>
]]></content>
      <categories>
        <category>论文阅读</category>
        <category>Surface Mapping</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>CSM</tag>
      </tags>
  </entry>
</search>
